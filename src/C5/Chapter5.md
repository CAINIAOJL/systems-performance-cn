# Chapter 5: 应用
性能最好在最接近执行工作的地方进行调整：在应用程序中。这些包括数据库、Web 服务器、应用程序服务器、负载均衡器、文件服务器等。以下章节从应用程序消耗的资源（CPU、内存、文件系统、磁盘和网络）的角度介绍应用程序。本章介绍应用程序级别。

应用程序本身可能会变得极其复杂，尤其是在涉及许多组件的分布式环境中。应用程序内部的研究通常是应用程序开发人员的领域，可以包括使用第三方工具进行内省。对于研究系统性能的用户，应用程序性能分析包括配置应用程序以最好地利用系统资源、描述应用程序如何使用系统以及分析常见病症。

本章的学习目标是： 
■ 熟悉性能改进技术，包括多线程编程、哈希表和非阻塞 I/O。
■ 了解常见的锁定和同步原语。
■ 了解不同编程语言带来的挑战。
■ 遵循线程状态分析方法。
■ 执行 CPU 和 off-CPU 分析。
■ 执行 syscall 分析，包括跟踪进程执行。 
■ 注意堆栈跟踪问题：缺少符号和堆栈

本章讨论应用程序基础知识、应用程序性能基础知识、编程语言和编译器、通用应用程序性能分析策略以及基于系统的应用程序可观测性工具。

# 5.1 应用程序基础知识
在深入了解应用程序性能之前，您应该熟悉应用程序的角色、其基本特征及其在行业中的生态系统。这构成了您可以了解应用程序活动的上下文。它还为您提供了了解常见性能问题和优化的机会，并为进一步学习提供了途径。要了解此上下文，请尝试回答以下问题：
■ Function：应用程序的作用是什么？它是数据库服务器、Web 服务器、负载均衡器、文件服务器还是对象存储？
■ Operation：应用程序处理哪些请求，或者它执行哪些作？数据库提供查询（和命令），Web 服务器提供 HTTP 请求，等等。这可以用速率来衡量，以衡量负载和进行容量规划。
■ Performance requirements：运行应用程序的公司是否具有服务级别目标 （SLO）（例如，99.9% 的请求延迟< 100 毫秒）？
■ CPU mode：应用程序是作为用户级软件还是内核级软件实现的？大多数应用程序是用户级的，作为一个或多个进程执行，但有些应用程序是作为内核服务（例如 NFS）实现的，BPF 程序也是内核级的。
■ Configuration：应用程序是如何配置的，为什么？此信息可以在配置文件中或通过管理工具找到。检查是否更改了任何与性能相关的可调参数，包括缓冲区大小、缓存大小、并行度（进程或线程）和其他选项。
■ Host：什么托管应用程序？服务器还是云实例？CPU、内存拓扑、存储设备等有哪些？它们的极限是什么？指标：是否提供应用程序指标，例如作速率？它们可能由捆绑工具或第三方工具提供，也可能通过 API 请求提供，或者通过处理作日志提供。
■ 日志：应用程序创建哪些作日志？可以启用哪些日志？日志中提供了哪些性能指标，包括延迟？例如，MySQL 支持慢速查询日志，为慢于特定阈值的每个查询提供有价值的性能详细信息。
■ Version：应用程序是最新版本吗？最新版本的发行说明中是否指出了性能修复或改进？
■ Bugs：应用程序是否有 bug 数据库？您的应用程序版本有哪些 “performance” 错误？如果您当前遇到性能问题，请搜索 bug 数据库，查看以前是否发生过类似情况、如何调查以及涉及的其他内容。
■ Source code：应用程序是否开源？如果是这样，则可以研究由分析器和跟踪器识别的代码路径，从而有可能提高性能。您可以自己修改应用程序代码以提高性能，并将您的改进提交到上游以包含在官方应用程序中。
■ Community：是否有共享性能结果的应用程序社区？社区可能包括论坛、博客、Internet 中继聊天 （IRC） 频道、其他聊天频道（例如 Slack）、聚会和会议。聚会和会议经常在网上发布幻灯片和视频，这些都是多年后的有用资源。他们也可能有一名社区管理员来分享社区更新和新闻。
■ Books：有没有关于应用程序和/或其性能的书籍？它们是好书吗（例如，由专家撰写、实用/可作、充分利用读者的时间、与时俱进等）？
■ Experts：谁是应用程序公认的性能专家？了解他们的名字可以帮助您找到他们编写的材料。
无论来源如何，您都希望从较高层次上了解应用程序 — 它做什么、如何运行以及如何执行。如果您能找到一个非常有用的资源，那就是说明应用程序内部的功能图。

接下来的部分介绍其他应用程序基础知识：设置目标、优化常见情况、可观察性和大 O 表示法

# #5.1.1 目标
性能目标为您的性能分析工作提供方向，并帮助您选择要执行的活动。如果没有明确的目标，性能分析就有可能变成随机的 “钓鱼探险”。

对于应用程序性能，您可以从应用程序执行的作（如前所述）和性能目标开始。目标可能是：

■ 延迟：应用程序响应时间短或一致 
■ 吞吐量：高应用程序运行速率或数据传输速率 
■ 资源利用率：给定应用程序工作负载的效率 
■ 价格：提高性能/价格比，降低计算成本

如果可以使用可能来自业务或服务质量要求的指标来量化这些，那就更好了。示例包括：

■ 平均应用程序请求延迟为 5 毫秒 
■ 95% 的请求以 100 毫秒或更短的延迟完成 
■ 消除延迟异常值：超过 1,000 毫秒的请求为零 
■ 给定大小的每台服务器每秒至少 10,000 个应用程序请求的最大吞吐量
■ 每秒 10,000 个应用程序请求的平均磁盘利用率低于 50%

选择目标后，您可以处理该目标的限制器。对于延迟，限制器可以是磁盘或网络 I/O;对于吞吐量，它可能是 CPU 使用率。本章和其他章节中的策略将帮助您识别它们。

对于基于吞吐量的目标，请注意，并非所有作在性能或成本方面都相同。如果目标是一定的作速率，则指定作类型可能也很重要。这可能是基于预期或测量工作负载的分配。

第 5.2 节 应用程序性能技术介绍了提高应用程序性能的常用方法。其中一些可能对一个目标有意义，但对另一个目标没有意义;对于检查 PLE，选择更大的 I/O 大小可能会以延迟为代价提高吞吐量。在确定哪些主题最适用时，请记住您追求的目标

# Apdex
一些公司使用目标应用程序性能指数（ApDex 或 Apdex）作为目标和监控指标。它可以更好地传达客户体验，并首先对客户事件进行分类，以确定它们是“令人满意”、“可容忍”还是“令人沮丧”。然后使用 [Apdex 20] 计算 Apdex：
    Apdex = (satisfactory + 0.5 × tolerable + 0 × frustrating) / total events
生成的 Apdex 范围从 0（没有满意的客户）到 1（所有满意的客户）。

# #5.1.2 优化常见情况
软件内部可能很复杂，具有许多不同的代码路径和行为。如果您浏览源代码，这一点可能尤其明显：应用程序通常是数万行代码，而作系统内核则有数十万行以上代码。随机选择要优化的区域可能涉及大量工作，但收益不大。

有效提高应用程序性能的一种方法是找到生产工作负载的最常见代码路径，并从改进它开始。如果应用程序受 CPU 限制，则可能意味着代码路径经常位于 CPU 上。如果应用程序受 I/O 限制，则应查看经常导致 I/O 的代码路径。这些可以通过对应用程序进行分析和分析来确定，包括研究堆栈跟踪和火焰图，如后面的章节所述。应用程序可观测性工具也可能提供更高级别的上下文来理解常见情况。

# #5.1.3 观测性
正如我在本书的许多章节中重申的那样，最大的性能胜利可能来自消除不必要的工作。

当根据性能选择应用程序时，这一事实有时会被忽视。如果基准测试显示应用程序 A 比应用程序 B 快 10%，那么选择应用程序 A 可能很诱人。但是，如果应用程序 A 是不透明的，而应用程序 B 提供了一组丰富的可观测性工具，那么从长远来看，应用程序 B 很可能是更好的选择。这些可观测性工具可以查看和消除不必要的工作，并更好地理解和调整主动工作。通过增强的可观察性获得的性能优势可能会使最初 10% 的性能差异相形见绌。语言和运行时的选择也是如此：例如选择 Java 或 C，它们已经成熟并且具有许多可观测性工具，而不是选择一种新的语言

# #5.1.4 大 O 表示法
大 O 表示法通常作为计算机科学科目教授，用于分析算法的复杂性，并对它们在输入数据集缩放时的性能进行建模。O 是指函数的阶数，描述其增长率。这种表示法有助于程序员在开发应用程序时选择更高效、性能更高的算法 [Knuth 76][Knuth 97]。

表 5.1 中列出了常见的大 O 表示法和算法示例

该表示法允许程序员估计不同算法的加速，从而确定哪些代码区域将导致最大的改进。例如，对于搜索包含 100 个项目的排序数组，线性搜索和二叉搜索之间的差异是 21 倍 （100/ log（100））。

这些算法的性能如图 5.1 所示，显示了它们扩展的趋势

此分类有助于系统性能分析师了解某些算法在大规模上的性能会非常差。当应用程序被推送为比以往更多的用户或数据对象提供服务时，可能会出现性能问题，此时 O（n^2） 等算法可能开始变得病态。解决方法可能是让开发人员使用更高效的算法或以不同的方式对群体进行分区。

Big O 表示法确实忽略了每种算法产生的一些恒定计算成本。对于 n （输入数据大小）较小的情况下，这些成本可能占主导地位。

# 5.2 应用性能技术
本节介绍一些可以提高应用程序性能的常用技术：选择 I/O 大小、缓存、缓冲、轮询、并发和并行性、非阻塞 I/O 和处理器绑定。请参阅应用程序文档，了解其中的哪些，以及任何其他特定于应用程序的功能。

# #5.2.1 选择 I/O 大小
与执行 I/O 相关的成本可能包括初始化缓冲区、进行系统调用、模式或上下文切换、分配内核元数据、检查进程权限和限制、将地址映射到设备、执行内核和驱动程序代码以交付 I/O，以及最后释放元数据和缓冲区。“初始化税”适用于小型和大型 I/O。为了提高效率，每个 I/O 传输的数据越多越好。

增加 I/O 大小是应用程序用于提高吞吐量的常见策略。考虑到任何固定的每 I/O 成本，将 128 KB 作为单个 I/O 传输通常比传输 128 × 1 KB I/O 要高效得多。特别是旋转磁盘 I/O，由于寻道时间的原因，历来每个 I/O 的成本很高。

当应用程序不需要更大的 I/O 大小时，有一个缺点。执行 8 KB 随机读取的数据库在 128 KB 的磁盘 I/O 大小下可能会运行得更慢，因为浪费了 120 KB 的数据传输。这引入了 I/O 延迟，可以通过选择更接近应用程序请求的较小 I/O 大小来降低延迟。不必要的较大 I/O 大小也会浪费缓存空间

# #5.2.2 缓存
操作系统使用高速缓存来提高文件系统读取性能和内存分配性能;应用程序通常出于类似的原因使用缓存。通常执行的作的结果可以存储在本地缓存中以备将来使用，而不是总是执行昂贵的作。数据库缓冲区缓存就是一个示例，它存储来自通常执行的数据库查询的数据。

部署应用程序时的常见任务是确定提供了哪些缓存，或者可以启用哪些缓存，然后配置它们的大小以适应系统

虽然缓存可以提高读取性能，但它们的存储通常用作缓冲区来提高写入性能。

# #5.2.3 缓冲
为了提高写入性能，数据可以在发送到下一级别之前合并到缓冲区中。这会增加 I/O 大小和作效率。根据写入的类型，它还可能增加写入延迟，因为对缓冲区的第一次写入在发送之前会等待后续写入

Ring Buffer（或循环 Buffer）是一种固定的 buffer，可用于组件之间的连续传输，这些组件异步作用于 buffer。它可以使用 start 和 end 指针实现，每个组件都可以在附加或删除数据时移动这些指针。

# #5.2.4 轮询
轮询是一种技术，在这种技术中，系统通过在循环中检查事件的状态来等待事件发生，并在检查之间暂停。当要做的工作很少时，轮询存在一些潜在的性能问题：

■ 重复检查的昂贵 CPU 开销 
■ 事件发生和下一次轮询检查之间的高延迟

如果这是性能问题，应用程序可能能够更改其行为以侦听要发生的事件，从而立即通知应用程序并执行所需的例程

# poll() System Call
有一个 poll（2） 系统调用来检查文件描述符的状态，它的功能与轮询类似，尽管它是基于事件的，因此它不会受到轮询的性能成本。poll（2） 接口支持将多个文件描述符作为一个数组，这要求应用程序在事件发生时扫描数组以查找相关的文件描述符。此扫描是 O（n）（请参阅 第 5.1.4 节 大 O 表示法），其开销可能会成为大规模的性能问题。Linux 上的替代方案是 epoll（2），它可以避免扫描，因此是 O（1）。在 BSD 上，等效项是 kqueue（2）。

# #5.2.5 并发和并行
分时系统（包括所有源自 Unix 的系统）提供程序并发性：加载和开始执行多个可运行程序的能力。虽然它们的运行时可能重叠，但它们不一定在同一时刻在 CPU 上执行。这些程序中的每一个都可能是一个申请流程。

要利用多处理器系统，应用程序必须同时在多个 CPU 上执行。这就是并行性，应用程序可以通过使用多个进程（多进程）或多个线程（多线程）来实现，每个线程都执行自己的任务。由于 Chapter 6， CPUs， Section 6.3.13， Multiprocess， Multithreading中解释的原因，多线程（或等效任务）效率更高，因此是首选方法。

除了增加 CPU 工作的吞吐量外，多个线程（或进程）是允许并发执行 I/O 的一种方法，因为其他线程可以在 I/O 上阻塞的线程等待时执行。（另一种方式是异步 I/O）。

使用多进程或多线程架构意味着允许内核通过 CPU 调度器决定运行谁，并且需要支付上下文切换开销。另一种方法是让用户模式应用程序实现自己的计划机制和程序模型，以便它可以在同一 OS 线程中为不同的应用程序请求 （或程序） 提供服务。机制包括：

■ 纤程：也称为轻量级线程，这些是线程的用户模式版本，其中每个纤程代表一个可调度的程序。应用程序可以使用自己的调度逻辑来选择要运行的纤程。例如，这些可用于分配一个纤程来处理每个应用程序请求，与对 OS 线程执行相同作相比，开销更少。例如，Microsoft Windows 支持 fibers.2 
■ 协程：协程比纤程更轻量级，是一个子例程，可以由用户模式应用程序调度，提供并发机制。
■ 基于事件的并发：程序被分解为一系列事件处理程序，并且可以从队列中规划和执行可运行的事件。例如，可以通过为每个应用程序请求分配元数据来使用这些元数据，该请求由事件处理程序引用。例如，Node.js运行时使用单个事件工作线程（这可能会成为瓶颈，因为它只能在一个 CPU 上执行）。

对于所有这些机制，I/O 仍必须由内核处理，因此 OS 线程切换通常是不可避免的。3 此外，为了实现并行性，必须使用多个 OS 线程，以便可以跨多个 CPU 调度它们。

某些运行时同时使用协程进行轻量级并发，使用多个 OS 线程进行并行。一个例子是 Golang 运行时，它在 OS 线程池上使用 goroutines（协程）。为了提高性能，当一个 goroutine 进行阻塞调用时，Golang 的调度器会自动将阻塞线程上的其他 goroutine 移动到其他线程来运行 [Golang 20]

多线程编程的三种常见模型是： 
■ 服务线程池：为网络请求提供服务的线程池，其中每个线程一次为一个客户端连接提供服务。
■ CPU 线程池：每个 CPU 创建一个线程。这通常用于长时间的批处理，例如视频编码。
■ 分阶段事件驱动架构 （SEDA）：应用程序请求被分解为多个阶段，这些阶段可由一个或多个线程的池处理

由于多线程编程与进程共享相同的地址空间，因此线程可以直接读取和写入相同的内存，而无需更昂贵的接口（例如用于多进程编程的进程间通信 [IPC]）。为了完整性，使用了同步原语，这样数据就不会被多个线程同时读写而损坏

# 同步基元
同步原语管理对内存的访问以确保完整性，并且可以模拟调节交叉路口访问的红绿灯。而且，与交通信号灯一样，它们可能会停止交通流，从而导致等待时间（延迟）。三种常用的应用程序类型是：

■ 互斥锁 （MUTually Exclusive） 锁：只有锁的持有者可以作。其他 Block 并在 CPU 之外等待。
■ 旋转锁：旋转锁允许支架运行，而其他旋转锁则以紧密的循环方式在 CPU 上旋转，检查锁是否被释放。虽然这些可以提供低延迟访问（被阻塞的线程永远不会离开 CPU，并在锁可用后准备好在几个周期内运行），但它们也会在线程旋转、等待时浪费 CPU 资源。
■ RW 锁：读取器/写入器锁通过允许多个读取器或仅允许一个写入器而不允许读取器来确保完整性。
■ 信号量：这是一种变量类型，可以计数以允许给定数量的并行作，也可以是二进制以允许仅允许一个（实际上是互斥锁）

互斥锁可以由库或内核实现为自旋锁和互斥锁的混合体，如果持有者当前在另一个 CPU 上运行，则自旋，如果持有者当前在另一个 CPU 上运行（或达到自旋阈值），则阻塞。它们最初于 2009 年在 Linux 上实现 [Zijlstra 09]，现在根据锁的状态有三条路径（如 Documentation/locking/ mutex-design.rst [Molnar 20] 中所述）：

1. fastpath：尝试使用 cmpxchg 指令获取锁以设置所有者。仅当未持有锁时，此作才会成功。
2. midpath：也称为乐观旋转，当锁持有者也在运行时，它在 CPU 上旋转，希望它很快被释放并且可以在不阻塞的情况下被获取。
3. slowpath：这会阻止并取消调度线程，以便稍后在锁可用时唤醒。

Linux read-copy-update （RCU） 机制是另一种大量用于内核代码的同步机制。它允许读取作而无需获取锁，从而提高了其他锁类型的性能。使用 RCU 时，写入会创建受保护数据的副本并更新副本，而正在进行的读取仍可访问原始数据。它可以检测何时不再有任何读取器（基于每个 CPU 的各种条件），然后用更新的副本 [Linux 20e] 替换原始副本。

调查涉及锁的性能问题可能非常耗时，并且通常需要熟悉应用程序源代码。这通常是开发人员的一项活动

# 哈希表
锁的哈希表可用于为大量数据结构使用最佳数量的锁。虽然这里总结了哈希表，但这是一个假定具有编程背景的高级主题。

想象一下以下两种方法： 
■ 所有数据结构的单个全局互斥锁。虽然此解决方案很简单，但并发访问在等待时会遇到锁争用和延迟。需要该锁的多个线程将序列化 - 按顺序执行，而不是并发执行。
■ 每个数据结构的互斥锁。虽然这将争用减少到真正需要的时候 — 对同一数据结构的并发访问— 但锁会产生存储开销，并且每个数据结构的锁的创建和销毁都会产生 CPU 开销。

锁的哈希表是一种介于两者之间的解决方案，适用于预期锁争用较少的情况。创建固定数量的锁，并使用哈希算法来选择将哪个锁用于哪个数据结构。这避免了数据结构的创建和销毁成本，也避免了只有一个锁的问题。

图 5.2 中所示的示例哈希表有四个条目，称为 buckets，每个条目都包含自己的锁。

此示例还显示了一种解决哈希冲突的方法，其中两个或多个输入数据结构对同一个存储桶进行哈希处理。在这里，创建了一个数据结构链，将它们全部存储在同一个桶下，哈希函数将再次找到它们。如果这些哈希链变得太长并且按顺序遍历，则可能会出现性能问题，因为它们仅受一个锁保护，该锁可以开始具有较长的保持时间。可以选择哈希函数和表大小，目标是将数据结构均匀分布在多个存储桶中，以将哈希链长度保持在最小。应检查生产工作负载的哈希链长度，以防哈希算法未按预期工作，而是创建性能不佳的长哈希链。

理想情况下，哈希表存储桶的数量应等于或大于 CPU 计数，以实现最大并行度。哈希算法可以很简单，只需获取数据结构地址的低位4，并将其用作 2 的幂次方锁数组的索引。这种简单的算法也很快，可以快速定位数据结构

对于内存中的相邻锁数组，当锁位于同一缓存行内时，可能会出现性能问题。两个 CPU 更新同一 cache 行中的不同锁将遇到 cache cohering 开销，每个 CPU 都会使另一个 cache 中的缓存行失效。这种情况称为错误共享，通常通过使用未使用的字节填充锁来解决，以便内存中的每个缓存行中只存在一个锁

# #5.2.6 非阻塞I/O
第 3 章 “作系统”中所示的 Unix 进程生命周期显示了在 I/O 期间阻塞并进入睡眠状态的进程。此模型存在几个性能问题：

■ 每个 I/O作在被阻塞时都会消耗一个线程（或进程）。为了支持许多并发 I/O，应用程序必须创建许多线程（通常每个客户端一个），这些线程具有与线程创建和销毁相关的成本，以及保留它们所需的堆栈空间。
■ 对于频繁的短期 I/O，频繁上下文切换的开销可能会消耗 CPU 资源并增加应用程序延迟。

非阻塞 I/O 模型异步发出 I/O，而不会阻塞当前线程，然后该线程可以执行其他工作。这是 Node.js [Node.js 20] 的一个关键特性，这是一个服务器端的 JavaScript 应用程序环境，它指导以非阻塞方式开发代码。

有许多机制可以执行非阻塞或异步 I/O，包括： 
■ open（2）：通过 O_ASYNC 标志。当文件描述符上可以进行 I/O 时，将使用信号通知进程。
■ io_submit（2）：Linux 异步 I/O （AIO）。
■ sendfile（2）：这会将数据从一个文件描述符复制到另一个文件描述符，将 I/O 推迟到内核而不是用户级 I/O
■ io_uring_enter（2）：Linux io_uring 允许使用在用户和内核空间之间共享的环形缓冲区提交异步 I/O [Axboe 19]。

请查看您的作系统文档，了解其他方法。

# #5.2.7 处理器绑定
对于 NUMA 环境，进程或线程在单个 CPU 上保持运行并在执行 I/O 后与以前相同的 CPU 上运行可能是有利的。这可以提高应用程序的内存局部性，减少内存 I/O 的周期并提高应用程序的整体性能。操作系统很清楚这一点，并且设计为将应用程序线程保持在同一 CPU 上（CPU 关联性）。这些主题在第 7 章 内存 中介绍。

某些应用程序通过将自身绑定到 CPU 来强制此行为。这可以显著提高某些系统的性能。当绑定与其他 CPU 绑定（例如设备中断映射到 CPU）发生冲突时，它还会降低性能。

当有其他租户或应用程序在同一系统运行时，请特别小心 CPU 绑定的风险。这是我在 OS 虚拟化（容器）环境中遇到的一个问题，在这种环境中，应用程序可以看到所有 CPU，然后绑定到一些 CPU，前提是它是服务器上唯一的应用程序。当服务器由同样绑定的其他租户应用程序共享时，多个租户可能会在不知不觉中绑定到相同的 CPU，从而导致 CPU 争用和调度程序延迟，即使其他 CPU 处于空闲状态。

在应用程序的生命周期内，主机系统也可能会发生变化，未更新的绑定可能会损害而不是帮助性能，例如，当它们不必要地跨多个套接字绑定到 CPU 时

# #5.2.8 性能咒语
有关提高应用程序性能的更多技术，请参阅第 2 章中的 Performance Mantras 方法。总结：
1. 不要这样做。
2. 做，但不要再做一次。
3. 少做。
4. 稍后再做。
5. 趁他们不注意的时候做。
6. 同时进行。
7. 做更便宜的事情。

第一项 “Don't do it” 是消除不必要的工作。有关此方法的更多详细信息，请参见第 2 章 方法论， 第 2.5.20 节 性能咒语。

# 5.3 编程语言
编程语言可以编译或解释，也可以通过虚拟机执行。许多语言将 “性能优化” 列为功能，但严格来说，这些通常是执行语言的软件的功能，而不是语言本身的功能。例如，Java HotSpot 虚拟机软件包括一个即时 （JIT） 编译器，用于动态提高性能。

Interpreters 和 Language Virtual Machine 还通过自己的特定工具提供不同级别的性能观察能力支持。对于系统性能分析师来说，使用这些工具进行基本分析可以带来一些快速的胜利。例如，垃圾回收 （GC） 可能会识别出高 CPU 使用率，然后通过一些常用的可调参数进行修复。或者它可能是由代码路径引起的，该代码路径可以在 bug 数据库中找到已知 bug 并通过升级软件版本来修复（这种情况经常发生）。

以下各节介绍每种编程语言类型的基本性能特征。有关单个语言性能的更多信息，请查找有关该语言的文本。

# #5.3.1 编译语言
编译采用程序并在运行时之前生成机器指令，这些指令存储在称为二进制文件的二进制可执行文件中，这些文件通常在 Linux 和其他 Unix 衍生产品上使用可执行和链接格式 （ELF），在 Windows 上使用 mat 的可移植可执行 （PE）。这些可以随时运行，而无需再次编译。编译语言包括 C、C 和 assembly。某些语言可能同时具有解释器和编译器。

编译后的代码通常是高性能的，因为它在 CPU 执行之前不需要进一步转换。编译代码的一个常见示例是 Linux 内核，它主要用 C 语言编写，一些关键路径用汇编语言编写。

编译语言的性能分析通常很简单，因为执行的机器代码通常与原始程序紧密映射（尽管这取决于编译优化）。在编译过程中，可以生成一个符号表，将地址映射到程序函数和目标文件名称。然后，可以将 CPU 执行的后续分析和跟踪直接映射到这些程序名称，从而允许分析人员研究程序执行情况。堆栈跟踪及其包含的数字地址也可以映射并转换为函数名称，以提供代码路径祖先。

编译器可以通过使用编译器优化（优化 CPU 指令的选择和放置的例程）来提高性能。

# 编译器优化
gcc（1） 编译器提供七个级别的优化：0、1、2、3、s、fast 和 g。这些数字是一个范围，其中 0 使用最少的优化，3 使用最多的优化。还有 “s” 用于优化大小，“g” 用于调试，“fast” 用于使用所有优化加上无视标准合规性的额外功能。您可以查询 gcc（1） 来显示它对不同级别使用了哪些优化。例如：

# $ gcc -Q -O3 --help=optimizers
 The following options control optimizations:
  -O<number> 
  -Ofast 
  -Og 
  -Os 
  -faggressive-loop-optimizations         [enabled]
  -falign-functions                       [disabled]
  -falign-jumps                           [disabled]
  -falign-label                           [enabled]
  -falign-loops                           [disabled]
  -fassociative-math                      [disabled]
  -fasynchronous-unwind-tables            [enabled]
   -fauto-inc-dec                          [enabled]
  -fbranch-count-reg                      [enabled]
  -fbranch-probabilities                  [disabled]
  -fbranch-target-load-optimize           [disabled]
 [...]
  -fomit-frame-pointer                    [enabled]
 [...]

gcc 版本 7.4.0 的完整列表包括大约 230 个选项，其中一些选项甚至在 –O0 时也被启用。作为这些选项之一的作用的一个例子，gcc（1） 手册页中描述了 -fomit-frame-pointer 选项，在这个列表中看到：

不要将 frame 指针保留在不需要 frame pointer 的 register 中。这样可以避免保存、设置和恢复帧指针的说明;它还在许多函数中提供了一个额外的 register 。它还导致无法在某些计算机上进行调试。

这是一个权衡示例：省略帧指针通常会中断分析堆栈跟踪的分析器的作。

考虑到堆栈分析器的有用性，此选项可能会在以后无法再轻易找到的性能胜利方面做出很大牺牲，这可能远远超过此选项最初提供的性能提升。在这种情况下，一种解决方案是使用 -fno-omit frame-pointer 进行编译以避免这种优化。6 另一个推荐的选项是 -g，以包含 debuginfo，以帮助以后进行调试。如果需要，可以稍后删除或剥离 Debuginfo

如果出现性能问题，可能很容易简单地使用降低的优化级别（例如从 –O3 到 –O2）重新编译应用程序，以期满足任何调试需求。事实证明这并不简单：对编译器输出的更改可能非常庞大且重要，并且可能会影响您最初尝试分析的问题的行为。

# #5.3.2 解释语言
解释型语言通过在运行时将程序转换为作来执行程序，这一过程会增加执行开销。解释型语言不需要表现出高性能，并且用于其他因素更重要的情况，例如易于编程和调试。Shell 脚本是解释型语言的一个示例

除非提供可观测性工具，否则解释型语言的性能分析可能很困难。CPU 性能分析可以显示解释器的作（包括解析、翻译和执行作），但它可能不显示原始程序函数名称，留下基本程序上下文一个谜。这种解释器分析可能并非完全没有结果，因为解释器本身可能存在性能问题，即使它正在执行的代码看起来设计得很好。

根据解释器的不同，程序上下文可能可用作解释器函数的参数，这可以通过动态插桩来查看。另一种方法是在了解程序布局的情况下检查进程的内存（例如，使用 Linux process_vm_readv（2） 系统调用）。

通常，只需添加 print 语句和时间戳即可研究这些程序。更严格的性能分析并不常见，因为解释型语言通常不会首先为高性能应用程序选择

# #5.3.3 虚拟机
语言虚拟机（也称为进程虚拟机）是模拟计算机的软件。一些编程语言（包括 Java 和 Erlang）通常使用虚拟机 （VM） 执行，这些虚拟机为它们提供了独立于平台的编程环境。应用程序被编译为虚拟机指令集（字节码），然后由虚拟机执行。这允许编译对象的可移植性，前提是有虚拟机可用于在目标平台上运行它们

字节码可以由语言虚拟机以不同的方式执行。Java HotSpot 虚拟机支持通过解释执行，还支持 JIT 编译，JIT 编译将字节码编译为机器码，以便处理器直接执行。这提供了编译代码的性能优势，以及虚拟机的可移植性。

虚拟机通常是最难观察的语言类型。当程序在 CPU 上执行时，可能已经通过了多个编译或解释阶段，并且有关原始程序的信息可能不容易获得。性能分析通常侧重于语言虚拟机提供的工具集，其中许多工具集提供 USDT 探测，以及第三方工具。

# #5.3.4 垃圾回收
某些语言使用自动内存管理，其中分配的内存不需要显式释放，将其留给异步垃圾回收进程。虽然这使得程序更容易编写，但也可能有缺点

■ 内存增长：对应用程序内存使用的控制较少，当对象未自动识别为符合释放条件时，内存使用可能会增加。如果应用程序变得太大，它可能会达到自己的限制或遇到系统分页（Linux 交换），从而严重损害性能。
■ CPU 成本：GC 通常会间歇性运行，并涉及搜索或扫描内存中的对象。这会消耗 CPU 资源，从而减少应用程序在短时间内可用的资源。随着应用程序内存的增长，GC 的 CPU 消耗也可能增加。在某些情况下，这可能会达到 GC 持续消耗整个 CPU 的程度。
■ 延迟异常值：在 GC 执行时，应用程序执行可能会暂停，从而导致偶尔出现被 GC 中断的高延迟应用程序响应8这取决于 GC 类型：停止世界、增量或并发。

GC 是性能调优的常见目标，用于降低 CPU 成本和延迟异常值的出现。例如，Java VM 提供了许多可调参数来设置 GC 类型、GC 线程数、最大堆大小、目标堆释放比率等。

如果调优无效，则问题可能是应用程序创建过多的垃圾或泄漏引用。这些问题需要应用程序开发人员解决。一种方法是尽可能分配较少的对象，以减少 GC 负载。显示对象分配及其代码路径的可观测性工具可用于查找潜在的消除目标。

# 5.4 方法论
本节介绍应用程序分析和调整的方法。用于分析的工具要么在此处介绍，要么从其他章节中引用。表 5.2 总结了这些方法

请参阅第 2 章 方法，了解其中的一些方法以及其他通用方法：对于应用程序，特别考虑 CPU 分析、工作负载特征和向下钻取分析。另请参阅以下章节，了解系统资源和虚拟化的分析。

这些方法可以单独遵循或组合使用。我的建议是按照表中列出的顺序尝试它们。

除此之外，还要为特定应用程序和开发它的编程语言寻找自定义分析技术。这些可能会考虑应用程序的逻辑行为，包括已知问题，并导致一些快速的性能胜利。

# #5.4.1 CPU 分析
CPU 性能分析是应用程序性能分析的一项基本活动，第 6 章 “CPU”中从第 6.5.4 节 性能分析开始对此进行了解释。本节总结了 CPU 专业归档和 CPU 火焰图，并介绍了如何将 CPU 分析用于某些 CPU 外分析。

Linux 有许多 CPU 分析器，包括 perf（1） 和 profile（8），第 5.5 节 可观测性工具中总结了这些分析器，这两个分析器都使用了定时采样。这些分析器在内核模式下运行，可以捕获内核和用户堆栈，从而生成混合模式配置文件。这提供了 CPU 使用率的 （几乎） 完全可见性。

应用程序和运行时有时会提供自己的性能分析器，该分析器在用户模式下运行，无法显示内核 CPU 使用率。这些基于用户的分析器可能具有 CPU 时间的偏差概念，因为它们可能不知道内核何时取消了应用程序调度，并且没有考虑它。我总是从基于内核的分析器（perf（1） 和 profile（8）））开始，并使用基于用户的分析器作为最后的手段

基于样本的分析器会生成许多样本：Netflix 的典型 CPU 配置文件会在 32 个 CPU 上以 49 赫兹的频率收集堆栈跟踪，持续 30 秒：这总共会产生 47040 个样本。为了理解这些内容，分析器通常提供不同的方法来汇总或可视化它们。采样堆栈跟踪的常用可视化称为火焰图，这是我发明的。

# CPU 火焰图
第 1 章显示了 CPU 火焰图，不同的示例摘录如图 2.15 所示。图 5.3 示例包括一个 ext4 注解，供以后参考。这些是混合模式火焰图，同时显示用户堆栈和内核堆栈。

在火焰图中，每个矩形都是堆栈跟踪中的一个帧，y 轴显示代码流：自上而下显示当前函数，然后显示其祖先。框架宽度与其在配置文件中的存在有关，并且 x 轴排序没有意义（它是按字母顺序排序）。您寻找大型 “plateaus” 或 “towers” — 这是大部分 CPU 时间花费的地方。有关火焰图的更多详细信息，请参见第 6 章 CPU， 第 6.7.3 节 火焰图

在图 5.3 中，crc32_z（） 是 CPU 上最多的函数，占据了该摘录的大约 40%（中心平台）。左边的塔式塔显示进入内核的 syscall write（2） 路径，总共跨越了大约 30% 的 CPU 时间。快速浏览一下，我们已经确定了这两个可能的低级优化目标。浏览代码路径祖先（向下）可以显示高级目标：在这种情况下，所有 CPU 使用率都来自 MYSQL_BIN_LOG：：commit（） 函数。

我不知道 crc32_z（） 或 MYSQL_BIN_LOG：：commit（） 是做什么的（尽管我大概能猜到）。CPU 配置文件公开了应用程序的内部工作原理，除非您是应用程序开发人员，否则您不需要知道这些函数中的任何一个是什么。您需要研究它们以开发可行的性能改进。

例如，我在互联网上搜索了 MYSQL_BIN_LOG：：commit（） 并很快找到了描述 MySQL 二进制日志记录的文章，用于数据库恢复和复制，以及如何调整或完全禁用它。快速搜索 crc32_z（） 显示它是来自 zlib 的校验和 ming 函数。也许有更新更快的 zlib 版本？处理器是否具有优化的 CRC 指令，并且 zlib 是否使用它？MySQL 是否需要计算 CRC，或者可以关闭它吗？有关这种思维方式的更多信息，请参见第 2 章 方法论， 第 2.5.20 节 性能咒语

第 5.5.1 节 perf 总结了使用 perf（1） 生成 CPU 火焰图的说明。

# 非CPU 占用空间
CPU 配置文件可以显示的不仅仅是 CPU 使用率。您可以查找其他 CPU 不足问题类型的证据。例如，磁盘 I/O 在某种程度上可以通过其用于文件系统访问和块 I/O 初始化的 CPU 使用率来查看。这就像找到一只熊的脚印：你看不到熊，但你发现它存在。

通过浏览 CPU 火焰图，您可能会找到文件系统 I/O、磁盘 I/O、网络 I/O、锁争用等的证据。图 5.3 突出显示了 ext4 文件系统 I/O 作为示例。如果您浏览了足够多的火焰图，您将熟悉要查找的函数名称：“tcp_*”表示内核 TCP 函数，“blk_*”表示内核块 I/O 函数，等等。以下是一些适用于 Linux 系统的热门搜索词

■ “ext4” （或 “btrfs”， “xfs”， “zfs”）：查找文件系统作。
■ “blk”：查找块 I/O 
■ “tcp”：查找网络 I/O 
■ “utex”：显示锁争用（“mutex” 或 “futex”）。
■ “alloc” 或 “object”：显示执行内存分配的代码路径。

此方法仅识别这些活动的存在，而不识别其规模。CPU 火焰图显示 CPU 使用率的大小，而不是在 CPU 之外阻塞所花费的时间。要直接测量 CPU 时间，您可以使用接下来介绍的 CPU 非 CPU 分析，尽管它通常需要更大的开销来测量。

# #5.4.2 非 CPU 分析
Off-CPU 分析是对当前未在 CPU 上运行的线程的研究：此状态称为 off-CPU。它包括线程阻塞的所有原因：磁盘 I/O、网络 I/O、锁控制、显式休眠、调度程序抢占等。对这些原因及其导致的性能问题的分析通常涉及各种工具。Off-CPU 分析是一种分析所有这些方法，并且可以由单个 Off-CPU 分析工具提供支持。

Off-CPU 分析可以通过不同的方式执行，包括：
■ 采样：收集基于计时器的 CPU 外线程样本，或者简单地收集所有线程（称为挂钟采样）。
■ 调度程序跟踪：检测内核 CPU 调度程序以计算线程处于 CPU 状态的持续时间，并使用 CPU 异常堆栈跟踪记录这些时间。当线程处于 CPU 关闭状态时，堆栈跟踪不会更改（因为它没有运行来更改它），因此只需为每个阻塞事件读取一次堆栈跟踪。
■ 应用程序检测：某些应用程序具有内置检测，用于通常阻止代码路径，例如磁盘 I/O。此类检测可能包括特定于应用程序的上下文。虽然方便和有用，但这种方法通常对 CPU 关闭事件（调度程序抢占、页面错误等）视而不见。

前两种方法更可取，因为它们适用于所有应用程序，并且可以查看所有 CPU 关闭事件;但是，它们会带来很大的开销。在 8 个 CPU 系统上，以 49 赫兹进行采样的成本应该可以忽略不计，但非 CPU 采样必须对线程池而不是 CPU 池进行采样。同一个系统可能有 10,000 个线程，其中大部分是空闲的，因此对它们进行采样会使开销增加 1,000x9（想象一下对 10,000 个 CPU 的系统进行 CPU 分析）。计划程序跟踪也可能会产生大量开销，因为同一系统每秒可能有 100,000 个或更多计划程序事件。

调度器跟踪是现在常用的技术，基于我自己的工具，比如 offcputime（8）（第 5.5.3 节，offcputime）。我使用的一种优化是仅记录超过极短持续时间的 CPU 非 CPU 事件，从而减少样本数量。我还使用 BPF 在内核上下文中聚合堆栈，而不是将所有样本发送到用户空间，从而进一步减少开销。尽管这些技术很有帮助，但您应该在生产环境中小心 CPU 外的 rofiling，并在使用前评估测试环境中的开销。

# Off-CPU Time 火焰图
关闭 CPU 配置文件可以可视化为关闭 CPU 时间火焰图。图 5.4 显示了一个 30 秒的系统范围的 off-CPU 配置文件，其中我放大了以显示 MySQL 服务器线程处理命令（查询）。

大部分 off-CPU 时间都在 fsync（） 代码路径和 ext4 文件系统中。鼠标指针位于一个函数 Prepared_statement：：execute（） 上，以演示信息行底部显示该函数的 off-CPU 时间：总共 3.97 秒。解释类似于 CPU 火焰图：寻找最宽的塔，然后首先调查这些塔。

通过使用 CPU 开端和离点火焰图，您可以通过代码路径全面了解开 CPU 和离场时间：这是一个强大的工具。我通常将它们显示为单独的火焰图。可以将它们组合成一个火焰图，我称之为热/冷火焰图。它效果不佳：CPU 时间被压缩成一个薄塔，因为热/冷火焰图的大部分都在显示等待时间。这是因为 CPU 外线程计数可能比正在运行的 CPU 上线程计数大两个数量级，从而导致保持/冷火焰图包含 99% 的 CPU 外时间，这（除非被筛选）主要是等待时间。

# 等待时间
除了收集 CPU 外配置文件的开销外，另一个问题是解释它们：它们可能受等待时间控制。这是线程等待工作所花费的时间。图 5.5 显示了相同的 off-CPU time 火焰图，但没有放大到一个有趣的线程。

此火焰图中的大多数时间现在都位于类似的 pthread_cond_wait（） 和 futex（） 代码路径中：这些是等待工作的线程。线程函数可以在火焰图中看到：从右到左，有 srv_worker_thread（）、srv_purge_coordinator_thread（）、srv_monitor_thread（） 等。

有几种方法可以找到重要的 CPU 关闭时间：
■ 放大 （或按） 应用程序请求处理函数进行筛选，因为我们最关心在处理应用程序请求期间的 CPU 关闭时间。对于 MySQL 服务器，这是 do_command（） 函数。搜索 do_command（） 然后放大，会产生与图 5.4 类似的火焰图。虽然这种方法很有效，但您需要知道在特定应用程序中要搜索什么函数。
■ 在收集期间使用内核筛选器以排除不感兴趣的线程状态。有效性取决于内核;在 Linux 上，TASK_UNINTERRUPTIBLE 上的匹配侧重于许多有趣的 CPU 非 CPU 事件，但也排除了一些事件。

您有时会发现阻止应用程序的代码路径正在等待其他内容，例如锁。要进一步深入研究，您需要知道为什么锁的持有者需要这么长时间才能释放它。除了 Section 5.4.7， Static Performance Tuning 中描述的锁分析之外，一种通用的技术是检测 waker 事件。这是一个高级活动：请参阅 BPF 性能工具 [Gregg 19] 的第 14 章，以及密件抄送中的 wakeuptime（8） 和 offwaketime（8） 工具。

第 5.5.3 节 offcputime 显示了使用密件抄送中的 offcputime（8） 生成 off-CPU 火焰图的说明。除了 scheduler 事件之外，syscall 事件是研究应用程序的另一个有用目标。

# #5.4.3 系统调用分析
系统调用 （syscall） 可用于研究基于资源的性能问题。目的是找出 syscall 时间花费在何处，包括 syscall 的类型以及调用它的原因。

系统调用分析的目标包括：
■ 新进程跟踪：通过跟踪 execve（2） 系统调用，您可以记录新进程的执行情况，并分析短期进程的问题。参见 第 5.5.5 节 execsnoop 中的 execsnoop（8） 工具。
■ I/O 分析：跟踪 read（2）/write（2）/send（2）/recv（2） 及其变体，并研究它们的 I/O 大小、标志和代码路径，将有助于识别次优 I/O 的问题，例如大量小 I/O。请参见部分 5.5.7 bpftrace 中的 bpftrace 工具。
■ 内核时间分析：当系统显示大量内核 CPU 时间（通常报告为“%sys”）时，检测系统调用可以找到原因。参见 第 5.5.6 节 syscount 中的 syscount（8） 工具。系统调用解释了大部分但不是全部内核 CPU 时间;异常包括页面错误、异步内核线程和中断。

系统调用是一个文档齐全的 API（手册页），使它们成为易于研究的事件源。它们也与应用程序同步调用，这意味着从 syscall 收集堆栈跟踪将显示负责的应用程序代码路径。此类堆栈跟踪可以可视化为火焰图

# #5.4.4 USE方法
如第 2 章 方法中介绍并在后面的章节中应用，USE 方法检查所有硬件资源的利用率、饱和度和错误。许多应用程序性能问题都可以通过这种方式解决，通过显示资源已成为瓶颈。

USE 方法也可以应用于软件资源。如果您可以找到显示应用程序内部组件的功能图，请考虑每个软件资源的利用率、饱和度和错误指标，看看有什么意义。

例如，应用程序可以使用工作线程池来处理请求，并使用等待轮到它们的请求队列。将其视为资源，然后可以按以下方式定义三个指标：

■ 利用率：在一段时间内忙于处理请求的平均线程数，占总线程数的百分比。例如，50% 意味着平均有一半的线程忙于处理请求。
■ 饱和度：间隔内请求队列的平均长度。这显示有多少请求已备份等待 worker 线程。
■ 错误：请求因任何原因被拒绝或失败。

然后，您的任务是找到如何测量这些指标。它们可能已由应用程序在某处提供，或者可能需要使用其他工具（如动态跟踪）进行添加或测量。

像这个例子一样的排队系统也可以使用排队理论来研究（参见第 2 章 方法论）

对于不同的示例，请考虑文件描述符。系统可能会施加限制，使这些资源成为有限的资源。这三个指标可能如下：
■ 利用率：正在使用的文件描述符的数量，占限制的百分比 
■ 饱和度：取决于作系统行为：如果线程阻塞等待文件描述符，这可能是等待此资源的阻塞线程数 
■ 错误：分配错误，例如 EFILE，“打开的文件太多”

对应用程序的组件重复此练习，并跳过任何没有意义的指标。此过程可以帮助您制定一个简短的清单，以便在继续使用其他方法之前检查应用程序运行状况。

# #5.4.5 线程安全分析
这是我针对每个性能问题使用的第一种方法，但它也是 Linux 上的高级活动。目标是在高级别确定应用程序线程在何处花费时间，从而立即解决某些问题，并指导对其他问题的调查。您可以通过将每个应用程序的线程时间划分为许多有意义的状态来实现此目的。

至少有两种线程状态：on-CPU 和 off-CPU。您可以使用标准指标和工具（例如 top（1））确定线程是否处于 on-CPU 状态，并根据需要进行 CPU pro 归档或 off-CPU 分析（参见第 5.4.1 节 CPU 分析和 5.4.2 off-CPU 分析）。此方法在州数较多时更有效。

# 九个状态
这是我选择的 9 个线程状态的列表，它们提供了比前面的两个状态（on-CPU 和 off-CPU）更好的分析起点
■ 用户：用户模式下的 On-CPU 
■ 内核：内核模式下的 On-CPU 
■ Runnable：和 off-CPU 等待开启 CPU
■ 交换（匿名分页）：可运行，但被阻止匿名分页 
■ 磁盘 I/O：等待块设备 I/O：读/写、数据/文本分页 
■ 网络 I/O：等待网络设备 I/O： 等待网络设备 I/O： 套接字读/写 
■ Sleeping：自愿休眠 
■ Lock：等待获取同步锁（等待其他人） 
■ Idle：等待工作

这个九态模型如图 5.6 所示。

通过减少除 idle 之外的每种状态的时间，可以提高应用程序请求的性能。在其他条件相同的情况下，这意味着应用程序请求的延迟较低，并且应用程序可以处理更多负载。

一旦确定了线程在哪些状态下花费了时间，就可以进一步调查它们：
■ 用户或内核：分析可以确定哪些代码路径正在消耗 CPU，包括花在锁上旋转的时间。请参见部分 5.4.1， CPU 性能分析。 ■ Runnable：处于此状态的时间意味着应用程序需要更多的 CPU 资源。检查整个系统的 CPU 负载，以及应用程序存在的任何 CPU 限制（例如，资源控制）。
■ 交换 （匿名分页） ：缺少应用程序的可用主内存可能会导致交换延迟。检查整个系统的内存使用情况以及存在的任何内存限制。有关详细信息，请参见第 7 章 内存。
■ 磁盘：此状态包括直接磁盘 I/O 和页面错误。要进行分析，请参见部分 5.4.3， 系统调用分析、第 8 章 “文件系统”和第 9 章 “磁盘”。工作负载特征描述可以帮助解决许多磁盘 I/O 问题;检查文件名、I/O 大小和 I/O 类型。
■ 网络：此状态适用于在网络 I/O（发送/接收）期间阻塞的时间，但不侦听新连接（即空闲时间）。要进行分析，请参见部分 5.4.3， 系统调用分析;Section 5.5.7， bpftrace 和 I/O 性能分析标题;以及第 10 章 网络。工作负载特征化对于网络 I/O 问题也很有用;检查主机名、Proto 列和吞吐量。
■ 休眠：分析休眠的原因（代码路径）和持续时间
■ 锁定：识别锁、固定锁的线程以及支架持有锁这么久的原因。原因可能是持有人被另一把锁挡住了，这需要进一步展开。这是一项高级活动，通常由对应用程序及其锁定层次结构有深入了解的软件开发人员执行。我开发了一个 BCC 工具来帮助进行这种类型的分析：offwaketime（8） （包含在 BCC 中），它显示阻塞堆栈跟踪以及唤醒器。

由于应用程序通常等待工作的方式，您经常会发现网络 I/O 和锁定状态中的时间实际上是空闲时间。应用程序工作线程可以通过等待网络 I/O 来响应下一个请求（例如，HTTP 保持连接状态）或通过等待条件变量（锁定状态）被唤醒以处理工作来实现空闲。

下面总结了如何在 Linux 上测量这些线程状态。

# Linux
图 5.7 显示了基于内核线程状态的 Linux 线程状态模型。

内核线程状态基于内核task_struct状态成员：Runnable TASK_ RUNNING，Disk 为 TASK_UNINTERRUPTIBLE，Sleep 为 TASK_INTERRUPTIBLE。这些状态由包括 ps（1） 和 top（1） 在内的工具使用单字母代码显示：分别使用 R、D 和 S。（还有更多状态，例如 stopped by a debugger，我在这里没有包括。

虽然这为进一步分析提供了一些线索，但它远未将时间划分为前面描述的九种状态。需要更多信息：例如，Runnable 可以使用 /proc 或 getrusage（2） 统计信息分为用户时间和内核时间

其他内核通常提供更多状态，因此此方法更易于应用。我最初在 Solaris 内核上开发并使用了这种方法，其灵感来自其微状态记帐功能，该功能以八种不同的状态记录线程时间：用户、系统、陷阱、文本错误、数据错误、锁定、睡眠和运行队列（调度程序延迟）。这些与我的理想状态不匹配，但是一个更好的起点。

我将讨论我在 Linux 上使用的三种方法：基于线索的分析、脱离 CPU 的分析和直接测量。

# 基于线索
您可以先使用常见的作系统工具，比如 pidstat（1） 和 vmstat（8），来建议线程状态时间可以花在何处。感兴趣的工具和列包括：

■ User：pidstat（1） “%usr” （此状态直接测量） 
■ Kernel：pidstat（1） “%system” （此状态直接测量） 
■ Runnable： vmstat（8） “r” （系统范围） 
■ Swapping：vmstat（8） “si” 和 “so” （系统范围） 
■ Disk I/O： pidstat（1） -d “iodelay” （包括交换状态） 
■ Network I/O： sar（1） -n DEV “rxkB/s” 和 “txkB/s” （系统范围） 
■ Sleeping： 不容易获得 
■ Lock： perf（1） top （可以直接识别旋转锁定时间） 
■ Idle： 不容易获得

其中一些统计数据是系统范围的。如果您通过 vmstat（8） 发现存在系统范围的交换速率，您可以使用更深入的工具来调查该状态，以确认应用程序受到影响。以下各节和章节介绍了这些工具。

# 脱离CPU分析
由于许多状态都是 CPU 关闭的（除了 User 和 Kernel 之外的所有内容），因此您可以应用 CPU 关闭分析来确定线程状态。请参见部分 5.4.2， CPU 故障分析。

# 直接测量
按线程状态准确测量线程时间，如下所示：

# 用户：用户模式 CPU 可以从许多工具以及 /proc/PID/stat 和 getrusage（2） 中获得。pidstat（1） 将此报告为 %usr。
# 内核：内核模式 CPU 也在 /proc/PID/stat 和 getrusage（2） 中。pidstat（1） 将此报告为 %system。
# Runnable：由内核 schedstats 功能以纳秒为单位进行跟踪，并通过 /proc/PID/schedstat 公开。它也可以使用跟踪工具进行测量，但代价是一些开销，包括 perf（1） sched 子命令和 BCC runqlat（8），两者都在第 6 章 CPU 中介绍。
# 交换：以纳秒为单位的时间交换（匿名分页）可以通过延迟核算来测量，在第 4 章 可观测性工具， 第 4.3.3 节 延迟核算中介绍，其中包括一个示例工具：getdelays.c。跟踪工具还可用于检测交换 ping 延迟。
# 磁盘： pidstat（1） -d 显示 “iodelay” 作为进程因块 I/O 和交换而延迟的时钟周期数;如果没有系统范围的交换（如 vmstat（8） 报告的那样），您可以得出任何 ioDelay 都是 I/O 状态的结论。延迟记帐和其他记帐功能，如果启用，也会提供 iotop（8） 使用的块 I/O 时间。你也可以使用跟踪工具，比如 BCC 的 biotop（8）。
# 网络：可以使用 BCC 和 bpftrace 等跟踪工具来调查网络 I/O，包括用于 TCP 网络 I/O 的 tcptop（8） 工具。该应用程序还可能具有用于跟踪 I/O（网络和磁盘）时间的检测
# 休眠：可以使用跟踪器和事件（包括 syscalls：sys_enter_nanosleep 跟踪点）来检查进入自愿睡眠的时间。我的 naptime.bt 工具跟踪这些休眠并打印 PID 和持续时间 [Gregg 19][Gregg 20b]。
# 锁定：可以使用跟踪工具来研究锁定时间，包括来自 BCC 的 klockstat（8） 以及 bpf-perf-tools-book 存储库中的 pmlock.bt 和 pmheld.bt 用于 pthread 互斥锁，以及用于内核互斥锁的 mlock.bt 和 mheld.bt。
# Idle：跟踪工具可用于检测处理等待工作的应用程序代码路径。

有时，应用程序可能看起来完全处于休眠状态：它们在 CPU 之外保持阻塞状态，没有 I/O 或其他事件的速率。要确定应用程序线程所处的状态，可能需要使用调试器（如 pstack（1） 或 gdb（1））来检查线程堆栈跟踪，或从 /proc/PID/stack 文件中读取它们。请注意，像这样的调试器可能会暂停目标应用程序并导致它们自己的性能问题：在生产中尝试它们之前，请了解如何使用它们及其风险。

# #5.4.6 锁分析
对于多线程应用程序，锁可能会成为瓶颈，从而抑制并行性和可伸缩性。单线程应用程序可以被内核锁（例如，文件系统锁）禁止。可以通过以下方式分析锁：

■ 检查争用 
■ 检查保持时间过长

第一个选项确定现在是否存在问题。过长的保持时间不一定是一个直接的问题，但在未来随着并行负载的增加，它们可能会成为问题。对于每个锁，请尝试识别锁的名称（如果存在）和导致使用它的代码路径。

虽然有专门用于锁分析的工具，但有时可以仅从 CPU 分析中解决问题。对于自旋锁，争用显示为 CPU 使用率，可以使用堆栈跟踪的 CPU 分析轻松识别。对于自适应互斥锁，争用通常涉及一些自旋，这也可以通过堆栈跟踪的 CPU 分析来识别。在这种情况下，请注意 CPU 配置文件仅提供故事的一部分，因为线程可能在等待锁时阻塞和休眠。请参见部分 5.4.1， CPU 性能分析。

有关 Linux 上的特定锁定分析工具，请参见部分 5.5.7 bpftrace。

# #5.4.7 静态性能调优
静态性能优化侧重于已配置环境的问题。对于应用程序性能，请检查静态配置的以下方面
■ 正在运行的应用程序版本是什么，它的依赖关系是什么？有更新的版本吗？他们的发行说明是否提到了性能改进？
■ 是否存在已知的性能问题？有没有列出它们的 bug 数据库？
■ 应用程序是如何配置的？
■ 如果它的配置或调整与默认值不同，原因是什么？（是基于测量和分析，还是猜测? 
■ 应用程序是否使用对象缓存？它的尺寸如何？
■ 应用程序是否并发运行？它是如何配置的（例如，线程池大小调整）？
■ 应用程序是否在特殊模式下运行？（例如，调试模式可能已启用并降低了性能，或者应用程序可能是调试版本而不是发布版本。
■ 应用程序使用哪些系统库？它们是什么版本？
■ 应用程序使用什么内存分配器？
■ 应用程序是否配置为对其堆使用大页面？
■ 应用程序是否已编译？编译器的哪个版本？哪些编译器选项和优化？64 位？
■ 本机代码是否包含高级说明？（应该吗？（例如，包括 Intel SSE 的 SIMD/矢量指令。
■ 应用程序是否遇到了错误，现在是否处于降级模式？或者它是否配置错误并始终以降级模式运行？
■ 是否有针对 CPU、内存、文件系统、磁盘或网络使用情况的系统施加的限制或资源控制？（这些在云计算中很常见。

回答这些问题可能会揭示被忽视的配置选择

# #5.4.8 分布式跟踪
在分布式环境中，应用程序可能由在不同系统上运行的服务组成。虽然每个服务都可以像研究自己的微型应用程序一样进行研究，但也有必要将分布式应用程序作为一个整体进行研究。这需要新的方法和工具，并且通常使用分布式跟踪来执行。

分布式跟踪涉及记录每个服务请求的相关信息，然后组合此信息以进行研究。然后，跨多个服务的每个应用程序请求都可以分解为其依赖项请求，并且可以识别导致高应用程序延迟或错误的服务

收集的信息可能包括：
■ 应用程序请求的唯一标识符（外部请求 ID） 
■ 有关其在依赖项层次结构中的位置的信息 
■ 开始和结束时间 
■ 错误状态

分布式跟踪的一个挑战是生成的日志数据量：每个应用程序请求都有多个条目。一种解决方案是执行基于头部的采样，在请求的开始 （“head”） 时，决定是否对其进行采样 （“trace”） ：例如，跟踪每万个请求中的一个。这足以分析大部分请求的性能，但由于数据有限，可能会使分析间歇性错误或异常值变得困难。一些分布式跟踪程序是基于尾部的，其中首先捕获所有事件，然后决定保留哪些事件，可能基于延迟和错误。

一旦确定了有问题的服务，就可以使用其他方法和工具对其进行更详细的分析。

# 5.5 观测工具
本节介绍适用于基于 Linux 的作系统的应用程序性能可观测性工具。有关使用它们时要遵循的策略，请参阅上一节。

表 5.3 中列出了本节中的工具，并描述了本章如何使用这些工具

这些作从 CPU 分析工具开始，然后是跟踪工具。许多跟踪工具都是基于 BPF 的，并使用 BCC 和 bpftrace 前端（第 15 章）;它们是：profile（8）、offcputime（8）、execsnoop（8） 和 syscount（8）。有关其功能的完整参考，请参阅每个工具的文档，包括其手册页。

此外，请查找此表中未列出的特定于应用程序的性能工具。后面的章节介绍了面向资源的工具：CPU、内存、磁盘等，这些工具也对应用程序分析很有用。

以下许多工具都会收集应用程序堆栈跟踪。如果您发现堆栈跟踪包含 “[unknown]” 帧或看起来非常短，请参见第 5.6 节 陷阱，其中描述了常见的问题并总结了修复这些问题的方法。

# #5.5.1 perf 
perf（1） 是标准的 Linux 分析器，一个具有多种用途的多功能工具。它在第 13 章 perf 中进行了解释。由于 CPU 分析对于应用程序分析至关重要，因此这里包含了使用 perf（1） 的 CPU 分析的摘要。第 6 章 CPU 更详细地介绍了 CPU 分析和火焰图。

# CPU 性能分析
下面使用 perf（1） 以 49 赫兹（-F 49：每秒采样数）的速度对所有 CPU （-a） 的堆栈跟踪 （-g） 进行 30 秒的采样，然后列出样本：

 # perf record -F 49 -a -g -- sleep 30
 [ perf record: Woken up 1 times to write data ]
 [ perf record: Captured and wrote 0.560 MB perf.data (2940 samples) ]
 # perf script
 mysqld 10441 [000] 64918.205722:   10101010 cpu-clock:pppH: 
        5587b59bf2f0 row_mysql_store_col_in_innobase_format+0x270 (/usr/sbin/mysqld)
        5587b59c3951 [unknown] (/usr/sbin/mysqld)
        5587b58803b3 ha_innobase::write_row+0x1d3 (/usr/sbin/mysqld)
        5587b47e10c8 handler::ha_write_row+0x1a8 (/usr/sbin/mysqld)
        5587b49ec13d write_record+0x64d (/usr/sbin/mysqld)
        5587b49ed219 Sql_cmd_insert_values::execute_inner+0x7f9 (/usr/sbin/mysqld)
        5587b45dfd06 Sql_cmd_dml::execute+0x426 (/usr/sbin/mysqld)
        5587b458c3ed mysql_execute_command+0xb0d (/usr/sbin/mysqld)
        5587b4591067 mysql_parse+0x377 (/usr/sbin/mysqld)
        5587b459388d dispatch_command+0x22cd (/usr/sbin/mysqld)
        5587b45943b4 do_command+0x1a4 (/usr/sbin/mysqld)
        5587b46b22c0 [unknown] (/usr/sbin/mysqld)
        5587b5cfff0a [unknown] (/usr/sbin/mysqld)
        7fbdf66a9669 start_thread+0xd9 (/usr/lib/x86_64-linux-gnu/libpthread-2.30.so)
 [...]

此配置文件中有 2,940 个堆栈样本;此处仅包含一个堆栈。perf（1） script 子命令将每个堆栈样本打印到以前录制的配置文件（perf.data 文件）中。perf（1） 还有一个 report 子命令，用于将配置文件汇总为代码路径层次结构。该配置文件还可以可视化为 CPU 火焰图。

# CPU 火焰图
Netflix 已自动执行 CPU 火焰图，因此运营商和开发人员可以从基于浏览器的 UI 中请求它们。它们可以完全使用开源软件构建，包括以下命令中的 GitHub 存储库。对于前面显示的图 5.3 CPU 火焰图，命令为：

# perf record -F 49 -a -g -- sleep 10; perf script --header > out.stacks
 # git clone https://github.com/brendangregg/FlameGraph; cd FlameGraph
 # ./stackcollapse-perf.pl < ../out.stacks | ./flamegraph.pl --hash > out.svg

然后，可以在 Web 浏览器中加载 out.svg 文件。flamegraph.pl 为不同的语言提供了自定义调色板：例如，对于 Java 应用程序，请尝试 --color=java。对所有选项运行 flamegraph.pl -h。

# 系统调用跟踪
默认情况下，perf（1） trace 子命令跟踪系统调用，它是 perf（1） 的 strace（1） 版本（第 5.5.4 节，strace）。例如，跟踪 MySQL 服务器进程：

 # perf trace -p $(pgrep mysqld)
         ? (         ): mysqld/10120  ... [continued]: futex())
 = -1 ETIMEDOUT (Connection timed out)
     0.014 ( 0.002 ms): mysqld/10120 futex(uaddr: 0x7fbddc37ed48, op: WAKE|
 PRIVATE_FLAG, val: 1)           = 0
     0.023 (10.103 ms): mysqld/10120 futex(uaddr: 0x7fbddc37ed98, op: WAIT_BITSET|
 PRIVATE_FLAG, utime: 0x7fbdc9cfcbc0, val3: MATCH_ANY) = -1 ETIMEDOUT (Connection 
timed out)
 [...]

它只包含了几行输出，显示了各种 MySQL 线程等待工作时的 futex（2） 调用（这些在图 5.5 中的 off-CPU 时间火焰图中占据主导地位）。

perf（1） 的优点是它使用每个 CPU 的缓冲区来减少开销，使其比当前 strace（1） 的实现使用起来要安全得多。它还可以在系统范围内跟踪，而 strace（1） 仅限于一组进程（通常是单个进程），并且可以跟踪 syscall 以外的事件。但是，perf（1） 没有 strace（1） 那么多的 syscall 参数转换;以下是 strace（1） 中的一行用于比较：

 [pid 10120] futex(0x7fbddc37ed98, FUTEX_WAIT_BITSET_PRIVATE, 0, {tv_sec=445110, 
tv_nsec=427289364}, FUTEX_BITSET_MATCH_ANY) = -1 ETIMEDOUT (Connection timed out)

strace（1） 版本扩展了 utime 结构体。perf（1） 跟踪使用 BPF 改进参数 “beautification” 的工作正在进行中。作为最终目标，perf（1） trace 最终可以替代 strace（1）。（有关 strace（1） 的更多信息，请参见第 5.5.4 节 strace。

# 内核时间分析
由于 perf（1） 跟踪显示系统调用中的时间，它有助于解释监控工具通常显示的系统 CPU 时间，尽管从摘要开始比逐个事件输出更容易。perf（1） trace 用 -s 总结系统调用：

# perf trace -s -p $(pgrep mysqld)
 mysqld (14169), 225186 events, 99.1%
   syscall            calls    total       min       avg       max      stddev
                               (msec)    (msec)    (msec)    (msec)        (%)
   --------------- -------- --------- --------- --------- ---------     -----
   sendto             27239   267.904     0.002     0.010     0.109      0.28%
   recvfrom           69861   212.213     0.001     0.003     0.069      0.23%
   ppoll              15478   201.183     0.002     0.013     0.412      0.75%
 [...]

输出显示每个线程的 syscall 计数和计时

前面显示 futex（2） 调用的输出在单独使用时不是很有趣，在任何繁忙的应用程序上运行 perf（1） trace 都会产生雪崩般的输出。首先从这个摘要开始，然后使用带有过滤器的 perf（1） trace 来只检查感兴趣的 syscall 类型。

# I/O 分析
I/O 系统调用特别有趣，在前面的输出中可以看到一些调用。使用过滤器 （-e） 跟踪 sendto（2） 调用：

 # perf trace -e sendto -p $(pgrep mysqld) 
     0.000 ( 0.015 ms): mysqld/14097 sendto(fd: 37<socket:[833323]>, buff: 
0x7fbdac072040, len: 12664, flags: DONTWAIT) = 12664
     0.451 ( 0.019 ms): mysqld/14097 sendto(fd: 37<socket:[833323]>, buff: 
0x7fbdac072040, len: 12664, flags: DONTWAIT) = 12664
     0.624 ( 0.011 ms): mysqld/14097 sendto(fd: 37<socket:[833323]>, buff: 
0x7fbdac072040, len: 11, flags: DONTWAIT) = 11
     0.788 ( 0.010 ms): mysqld/14097 sendto(fd: 37<socket:[833323]>, buff: 
0x7fbdac072040, len: 11, flags: DONTWAIT) = 11
 [...]

输出显示两个 12664 字节的发送，后跟两个 11 字节的发送，所有发送都带有 DONTWAIT 标志。如果我看到大量小发送，我可能会想，是否可以通过合并它们或避免 DONTWAIT 标志来提高性能

虽然 perf（1） trace 可用于某些 I/O 分析，但我经常希望进一步深入研究这些参数并以自定义方式对其进行总结。例如，此 sendto（2） 跟踪显示文件描述符 （37） 和套接字编号 （833323），但我更愿意看到套接字类型、IP 地址和端口。对于此类自定义跟踪，您可以在第 5.5.7 节 bpftrace 中切换到 bpftrace。

# #5.5.2 profile
profile（8）11 是来自 BCC 的基于定时器的 CPU 分析器（第 15 章）。它使用 BPF 通过在内核上下文中聚合堆栈跟踪来减少开销，并且仅将唯一的堆栈及其计数传递给用户空间。

以下 profile（8） 示例在所有 CPU 上以 49 赫兹的频率采样 10 秒：

 # profile -F 49 10
 Sampling at 49 Hertz of all threads by user + kernel stack for 10 secs.
 [...]
    SELECT_LEX::prepare(THD*)
    Sql_cmd_select::prepare_inner(THD*)
    Sql_cmd_dml::prepare(THD*)
    Sql_cmd_dml::execute(THD*)
    mysql_execute_command(THD*, bool)
    Prepared_statement::execute(String*, bool)
    Prepared_statement::execute_loop(String*, bool)
    mysqld_stmt_execute(THD*, Prepared_statement*, bool, unsigned long, PS_PARAM*)
    dispatch_command(THD*, COM_DATA const*, enum_server_command)
    do_command(THD*)
    [unknown]
    [unknown]
    start_thread
    -                mysqld (10106)
        13
 [...]

此输出中仅包含一个堆栈跟踪，显示 SELECT_LEX：:prepare（）在具有该祖先的 CPU 上采样了 13 次。

profile（8） 在第 6 章 CPU， 第 6.6.14 节 配置文件中进一步讨论，其中列出了它的各种选项，并包括从其输出生成 CPU 火焰图的说明。

# #5.5.3 offcputime
offcputime（8）是一个 BCC 和 bpftrace 工具（第 15 章），用于总结被阻塞的线程和 CPU off-CPU 所花费的时间，并显示堆栈跟踪来解释原因。它支持 CPU 外分析（第 5.4.2 节 CPU 外分析）。offcputime（8） 是 profile（8） 的对应物：它们之间显示了系统上线程所花费的全部时间。

下面显示了来自 BCC 的 offcputime（8），跟踪了 5 秒

# offcputime 5
 Tracing off-CPU time (us) of all threads by user + kernel stack for 5 secs.
 [...]
    finish_task_switch
    schedule
    jbd2_log_wait_commit
    jbd2_complete_transaction
    ext4_sync_file
    vfs_fsync_range
    do_fsync
    __x64_sys_fdatasync
    do_syscall_64
    entry_SYSCALL_64_after_hwframe
    fdatasync
    IO_CACHE_ostream::sync()
    MYSQL_BIN_LOG::sync_binlog_file(bool)
    MYSQL_BIN_LOG::ordered_commit(THD*, bool, bool)
    MYSQL_BIN_LOG::commit(THD*, bool)
    ha_commit_trans(THD*, bool, bool)
    trans_commit(THD*, bool)
    mysql_execute_command(THD*, bool)
    Prepared_statement::execute(String*, bool)
    Prepared_statement::execute_loop(String*, bool)
    mysqld_stmt_execute(THD*, Prepared_statement*, bool, unsigned long, PS_PARAM*)
    dispatch_command(THD*, COM_DATA const*, enum_server_command)
    do_command(THD*)
    [unknown]
    [unknown]
    start_thread
    -                mysqld (10441)
        352107
 [...]

输出显示唯一的堆栈跟踪及其在 CPU 之外花费的时间（以微秒为单位）。此特定堆栈通过代码路径通过 MYSQL_BIN_ LOG：：sync_binlog_file（） 显示 ext4 文件系统同步操作，在此跟踪期间总计 352 毫秒。

为了提高效率，offcputime（8） 在内核上下文中聚合这些堆栈，并且只向用户空间发出唯一的堆栈。它还仅记录超过 1 秒（默认为 1 微秒）的 CPU off-CPU 持续时间的堆栈跟踪，可以使用 -m 选项进行调整。

还有一个 -M 选项用于设置记录堆栈的最长时间。为什么我们要排除持续时间长的堆栈？这可能是筛选出不感兴趣的堆栈的有效方法：线程等待工作并在循环中阻塞一秒或多秒。尝试使用 -M 900000 来排除超过 900 毫秒的持续时间。

# Off-CPU Time 火焰图
尽管只显示了唯一的堆栈，但上一个示例的完整输出仍然超过 200,000 行。为了理解它，可以将其可视化为非 CPU 时间火焰图。图 5.4 显示了一个例子。生成这些命令的命令类似于 profile（8） 中的命令：

 # git clone https://github.com/brendangregg/FlameGraph; cd FlameGraph
 # offcputime -f 5 | ./flamegraph.pl --bgcolors=blue \
    --title="Off-CPU Time Flame Graph"> out.svg

这次，我将背景颜色设置为蓝色，以直观地提醒您，这是一个 CPU 之外的火焰图，而不是常用的 CPU 火焰图

# #5.5.4 strace
strace（1） 命令是 Linux 系统调用 tracer。13 它可以跟踪系统调用，为每个系统调用打印一行摘要，还可以对系统调用进行计数并打印报告。

例如，按 PID 1884 跟踪系统调用：
# $ strace -ttt -T -p 1884
 1356982510.395542 close(3)              = 0 <0.000267>
 1356982510.396064 close(4)              = 0 <0.000293>
 1356982510.396617 ioctl(255, TIOCGPGRP, [1975]) = 0 <0.000019>
 1356982510.396980 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0 <0.000024>
 1356982510.397288 rt_sigprocmask(SIG_BLOCK, [CHLD], [], 8) = 0 <0.000014>
 1356982510.397365 wait4(-1, [{WIFEXITED(s) && WEXITSTATUS(s) == 0}], WSTOPPED|
 WCONTINUED, NULL) = 1975 <0.018187>
 [...]

此调用中的选项包括（有关所有选项，请参见 strace（1） 手册页）：

■ -ttt：打印自纪元以来的第一列，以秒为单位，分辨率为微秒。
■ -T：打印最后一个字段 （<time>），即系统调用的持续时间，以秒为单位，分辨率为微秒。
■ -p PID：跟踪此进程 ID。还可以指定一个命令，以便 strace（1） 启动并跟踪它。

这里没有使用的其他选项包括 -f 来跟随子线程，以及 -o filename 来将 strace（1） 输出写入给定的文件名。

在输出中可以看到 strace（1） 的一个功能 — 将 syscall 参数转换为人类可读的形式。这对于理解 ioctl（2） 调用特别有用。

-c 选项可用于汇总系统调用活动。以下示例还调用和跟踪命令 （dd（1）），而不是附加到 PID：

# $ strace -c dd if=/dev/zero of=/dev/null bs=1k count=5000k
 5120000+0 records in
 5120000+0 records out
 5242880000 bytes (5.2 GB) copied, 140.722 s, 37.3 MB/s
 % time     seconds  usecs/call     calls    errors syscall------ ----------- ----------- --------- --------- ---------------
 51.46    0.008030           0   5120005           read
 48.54    0.007574           0   5120003           write
  0.00    0.000000           0        20        13 open
 [...]------ ----------- ----------- --------- --------- ---------------
100.00    0.015604              10240092        19 total

输出以 dd（1） 中的三行开头，后跟 strace（1） 摘要。这些列是：

■ time：显示系统 CPU 时间花费位置的百分比 
■ seconds：总系统 CPU 时间（以秒为单位） 
■ usecs/call：每次调用的平均系统 CPU 时间（以微秒为单位）
■ calls：系统调用次数 
■ syscall：系统调用名称

# strace 开销
警告： 当前版本的 strace（1） 通过 Linux 的 ptrace（2） 接口使用基于断点的跟踪。这将为所有系统调用的输入和返回设置断点（即使 -e 选项仅用于选择部分）。这是侵入性的，具有高系统调用率的应用程序可能会发现其性能恶化了一个数量级。为了说明这一点，下面是没有 strace（1） 的相同 dd（1） 命令：

# $ dd if=/dev/zero of=/dev/null bs=1k count=5000k
 5120000+0 records in
 5120000+0 records out
 5242880000 bytes (5.2 GB) copied, 1.91247 s, 2.7 GB/s

dd（1） 在最后一行包含吞吐量统计数据：通过比较它们，我们可以得出结论，strace（1） 使 dd（1） 慢了 73 倍。这是一个特别严重的情况，因为 dd（1） 执行高速率的系统调用。

根据应用程序要求，这种跟踪样式可以在短时间内使用，以确定正在调用的 syscall 类型。如果开销不是这样的问题，strace（1） 将非常有用。其他跟踪程序（包括 perf（1）、Ftrace、BCC 和 bpftrace）通过使用缓冲跟踪大大减少了跟踪开销，其中事件被写入共享的内核环缓冲区，用户级跟踪程序会定期读取缓冲区。这减少了用户上下文和内核上下文之间的上下文切换，从而降低了开销。

strace（1） 的未来版本可能会通过成为 perf（1） trace 子命令的别名（在前面的第 5.5.1 节 perf 中描述）来解决其开销问题。其他基于 BPF 的 Linux 性能更高的 syscall 跟踪器包括：Intel 的 vltrace [Intel 18]，以及 Microsoft 的 Windows ProcMon 工具的 Linux 版本 [Microsoft 20]

# #5.5.5 execsnoop
execsnoop（8）14 是一个 BCC 和 bpftrace 工具，用于跟踪系统范围内的新流程执行。它可以发现消耗 CPU 资源的短期进程的问题，还可用于调试软件执行，包括应用程序启动脚本。

BCC 版本的示例输出：
# execsnoop
 PCOMM            PID    PPID   RET ARGS
 oltp_read_write  13044  18184    0 /usr/share/sysbench/oltp_read_write.lua --db
driver=mysql --mysql-password=... --table-size=100000 run
 oltp_read_write  13047  18184    0 /usr/share/sysbench/oltp_read_write.lua --db
driver=mysql --mysql-password=... --table-size=100000 run
 sh               13050  13049    0 /bin/sh -c command -v debian-sa1 > /dev/null && 
debian-sa1 1 1 -S XALL
 debian-sa1       13051  13050    0 /usr/lib/sysstat/debian-sa1 1 1 -S XALL
 sa1              13051  13050    0 /usr/lib/sysstat/sa1 1 1 -S XALL
 sadc             13051  13050    0 /usr/lib/sysstat/sadc -F -L -S DISK 1 1 -S XALL 
/var/log/sysstat
 [...]

我在我的数据库系统上运行了这个程序，以防它发现任何有趣的东西，它确实做到了：前两行显示读/写微基准测试仍在运行，在循环中启动oltp_read_write命令 — 我不小心让它运行了好几天！由于数据库正在处理不同的工作负载，因此从显示 CPU 和磁盘负载的其他系统指标中并不明显。oltp_read_write后面的行显示 sar（1） 正在收集系统指标。

execsnoop（8） 通过跟踪 execve（2） 系统调用来工作，并为每个调用打印一行摘要。该工具支持一些选项，包括 -t 表示时间戳。

第 1 章展示了 execsnoop（8） 的另一个例子。我还发布了一个 threadsnoop（8） 工具，用于 bpftrace 通过 libpthread pthread_create（） 来跟踪线程的创建。

# #5.5.6 syscount
syscount（8）15 是一个 BCC 和 bpftrace 工具，用于计算系统范围的系统调用。

BCC 版本的示例输出

 # syscount
 Tracing syscalls, printing top 10... Ctrl+C to quit.
 ^C[05:01:28]
 SYSCALL                   COUNT
 recvfrom                 114746
 sendto                    57395
 ppoll                     28654
 futex                       953
 io_getevents                 55
 bpf                          33
 rt_sigprocmask               12
 epoll_wait                   11
 select                        7
 nanosleep                     6
 Detaching...

这表明最频繁的系统调用是 recvfrom（2），它在跟踪时被调用了 114,746 次。您可以使用其他跟踪工具进一步探索，以检查 syscall 参数、延迟和调用堆栈跟踪。例如，您可以将 perf（1） 跟踪与 -e recvfrom 过滤器一起使用，或者使用 bpftrace 来检测 syscalls：sys_enter_recvfrom 跟踪点。参见第 13 章至第 15 章中的示踪剂。

syscount（8） 也可以使用 -P 按进程计数

 # syscount -P
 Tracing syscalls, printing top 10... Ctrl+C to quit.
 ^C[05:03:49]
 PID    COMM               COUNT
 10106  mysqld            155463
 13202  oltp_read_only.    61779
 9618   sshd                  36
 344    multipathd            13
 13204  syscount-bpfcc        12
 519    accounts-daemon        5

输出显示进程和 syscall 计数。

# #5.5.7 bpftrace
bpftrace 是一种基于 BPF 的跟踪器，它提供了一种高级编程语言，允许创建强大的单行代码和简短脚本。它非常适合根据其他工具的线索进行自定义应用程序分析。

bpftrace 在第 15 章中进行了解释。本节介绍一些应用程序分析示例。

# 信号追踪
此 bpftrace 单行代码跟踪进程信号（通过 kill（2） syscall），显示源 PID 和进程名称，以及目标 PID 和信号编号：

 # bpftrace -e 't:syscalls:sys_enter_kill { time("%H:%M:%S ");
    printf("%s (PID %d) send a SIG %d to PID %d\n",
    comm, pid, args->sig, args->pid); }'
 Attaching 1 probe...
 09:07:59 bash (PID 9723) send a SIG 2 to PID 9723
 09:08:00 systemd-journal (PID 214) send a SIG 0 to PID 501
 09:08:00 systemd-journal (PID 214) send a SIG 0 to PID 550
 09:08:00 systemd-journal (PID 214) send a SIG 0 to PID 392
 ...

输出显示 bash shell 向自身发送信号 2 （Ctrl-C），然后 systemd-journal 向其他 PID 发送信号 0。信号 0 不执行任何作：它通常用于根据 syscall 返回值检查另一个进程是否仍然存在。

此单行代码可用于调试奇怪的应用程序问题，例如提前终止。包含时间戳，用于对监控软件中的性能问题进行交叉检查。跟踪信号也可以作为 BCC 和 bpftrace 中的独立 killsnoop（8） 工具使用。

# I/O 分析
bpftrace 可用于以多种方式分析 I/O：检查大小、延迟、返回值和堆栈跟踪。16 例如，recvfrom（2） syscall 在前面的示例中经常被调用，可以使用 bpftrace 进一步检查。

将 recvfrom（2） 缓冲区大小显示为直方图：

 # bpftrace -e 't:syscalls:sys_enter_recvfrom { @bytes = hist(args->size); }'
 Attaching 1 probe...
 ^C
 @bytes: 
 [4, 8)             40142 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
 [8, 16)             1218 |@                                                   |
 [16, 32)           17042 |@@@@@@@@@@@@@@@@@@@@@@                              |
 [32, 64)               0 |                                                    |
 [64, 128)              0 |                                                    |
 [128, 256)             0 |                                                    |
 [256, 512)             0 |                                                    |
 [512, 1K)              0 |                                                    |
 [1K, 2K)               0 |                                                    |
 [2K, 4K)               0 |                                                    |
 [4K, 8K)               0 |                                                    |
 [8K, 16K)              0 |                                                    |
 [16K, 32K)         19477 |@@@@@@@@@@@@@@@@@@@@@@@@@                           |

输出显示，大约一半的大小非常小，介于 4 到 7 字节之间，最大的大小在 16 到 32 KB 之间。通过跟踪 syscall exit tracepoint 将此缓冲区大小的 histogram 与接收到的实际字节进行比较也可能很有用： 

 # bpftrace -e 't:syscalls:sys_exit_recvfrom { @bytes = hist(args->ret); }'

较大的不匹配可能表明应用程序正在分配所需的更大缓冲区。（请注意，此退出单行代码将在直方图中包含 syscall 错误，大小为 -1。

如果接收到的大小还显示一些小 I/O 和一些大 I/O，这也可能会影响 syscall 的延迟，较大的 I/O 需要更长的时间。要测量 recvfrom（2） 延迟，可以同时跟踪 syscall 的开始和结束，如下面的 bpftrace 程序所示。语法在第 15 章 BPF， 第 15.2.4 节 编程中进行了解释，该语法以内核函数的类似延迟直方图结尾。

 # bpftrace -e 't:syscalls:sys_enter_recvfrom { @ts[tid] = nsecs; }
    t:syscalls:sys_exit_recvfrom /@ts[tid]/ {
    @usecs = hist((nsecs - @ts[tid]) / 1000); delete(@ts[tid]); }'
 Attaching 2 probes...
 ^C
 @usecs: 
 [0]                23280 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                       |
 [1]                40468 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
 [2, 4)               144 |                                                    |
 [4, 8)             31612 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@            |
 [8, 16)               98 |                                                    |
 [16, 32)              98 |                                                    |
 [32, 64)           20297 |@@@@@@@@@@@@@@@@@@@@@@@@@@                          |
 [64, 128)           5365 |@@@@@@                                              |
 [128, 256)          5871 |@@@@@@@                                             |
 [256, 512)           384 |                                                    |
 [512, 1K)             16 |                                                    |
 [1K, 2K)              14 |                                                    |
 [2K, 4K)               8 |                                                    |
 [4K, 8K)               0 |                                                    |
 [8K, 16K)              1 |                                                    |

输出显示 recvfrom（2） 通常小于 8 微秒，较慢的模式在 32 到 256 微秒之间。存在一些延迟异常值，最慢的达到 8 到 16 毫秒的范围。

您可以继续进一步向下钻取。例如，输出映射声明 （@usecs = ...） 可以更改为

■ @usecs[args->ret]：按 syscall 返回值进行细分，显示每个返回值的直方图。由于返回值是接收的字节数，或者 -1 表示错误，因此此细分将确认较大的 I/O 大小是否会导致更高的延迟。
■ @usecs[ustack]：按用户堆栈跟踪细分，显示每个代码路径的延迟直方图

我还会考虑在第一个跟踪点之后添加一个过滤器，以便仅显示 MySQL 服务器，而不显示其他进程：

# bpftrace -e 't:syscalls:sys_enter_recvfrom /comm == "mysqld"/ { ...

您还可以添加筛选条件以仅匹配延迟异常值或慢速模式。

# Lock Tracing
bpftrace 可用于以多种方式调查应用程序锁争用。对于典型的 pthread 互斥锁，可以使用 uprobe 来跟踪 pthread 库函数：pthread_mutex_ lock（） 等;tracepoints 可用于跟踪管理锁阻塞的 futex（2） 系统调用。

我之前开发了 pmlock（8） 和 pmheld（8） bpftrace 工具，用于检测 pthread 库函数，并将它们作为开源 [Gregg 20b] 发布（另请参阅 [Gregg 19] 的第 13 章）。例如，跟踪 pthread_mutex_lock（） 函数 duration：

# pmlock.bt $(pgrep mysqld)
 Attaching 4 probes...
 Tracing libpthread mutex lock latency, Ctrl-C to end.
 ^C
 [...]
 @lock_latency_ns[0x7f37280019f0, 
    pthread_mutex_lock+36
    THD::set_query(st_mysql_const_lex_string const&)+94
    Prepared_statement::execute(String*, bool)+336
    Prepared_statement::execute_loop(String*, bool, unsigned char*, unsigned char*...
    mysqld_stmt_execute(THD*, unsigned long, unsigned long, unsigned char*, unsign...
 , mysqld]: 
 [1K, 2K)              47 |                                                    |
 [2K, 4K)             945 |@@@@@@@@                                            |
 [4K, 8K)            3290 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                      |
 [8K, 16K)           5702 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|

此输出已被截断，以仅显示打印的众多堆栈中的一个。此堆栈显示锁地址0x7f37280019f0是通过 THD：：setquery（） 代码路径获取的，并且获取通常在 8 到 16 微秒范围内

为什么这个锁花了这么长时间？pmheld.bt 通过跟踪锁来解锁持续时间，显示 holder 的堆栈跟踪：

 # pmheld.bt $(pgrep mysqld)
 Attaching 5 probes...
 Tracing libpthread mutex held times, Ctrl-C to end.
 ^C
 [...]

  @held_time_ns[0x7f37280019f0, 
    __pthread_mutex_unlock+0
    THD::set_query(st_mysql_const_lex_string const&)+147
    dispatch_command(THD*, COM_DATA const*, enum_server_command)+1045
    do_command(THD*)+544
    handle_connection+680
 , mysqld]: 
 [2K, 4K)            3848 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@             |
 [4K, 8K)            5038 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
 [8K, 16K)              0 |                                                    |
 [16K, 32K)             0 |                                                    |
 [32K, 64K)             1 |                                                    |

这显示了 holder 的不同代码路径。

如果锁具有 symbol name，则打印它而不是 address。没有 symbol name，您可以从堆栈跟踪中识别锁： 这是 THD：：set_query（） 中指令偏移量 147 处的锁。该函数的源代码显示它只获取一个锁：LOCK_thd_query。

跟踪锁确实会增加开销，并且锁事件可能很频繁。请参见 第 4 章 可观测性工具， 第 4.3.7 节 uprobes 中有关 uprobes 开销的详细信息。也许可以基于 kernel futex 函数的 kprobes 开发类似的工具，从而在一定程度上减少开销。开销可以忽略不计的另一种方法是使用 CPU 分析。CPU 分析通常消耗很少的开销，因为它受采样率的限制，并且严重的锁争用可以使用足够的 CPU 周期来显示在 CPU 配置文件中。

# 应用程序内部
如果需要，您可以开发自定义工具来汇总应用程序内部结构。首先检查 USDT 探针是否可用，或者是否可以可用（通常通过使用选项重新编译）。如果这些不可用或不足，请考虑使用 uprobe。有关 bpftrace 和 uprobes 以及 USDT 的示例，请参阅第 4 章 可观测性工具、第 4.3.7 节 uprobes 和 4.3.8 USDT。第 4.3.8 节还描述了动态 USDT，这对于深入了解 JIT 编译的软件可能是必要的，而 uprobe 可能无法检测。

一个复杂的例子是 Java：uprobe 可以检测 JVM 运行时（C 代码）和作系统库，USDT 可以检测高级 JVM 事件，动态 USDT 可以放置在 Java 代码中，为方法执行提供洞察力。

# 5.6 陷阱
以下部分介绍应用程序性能分析的常见问题，特别是缺少符号和堆栈跟踪。在检查 CPU 配置文件（如火焰图）时，您可能首先会遇到这些问题，并发现它缺少函数名称和堆栈跟踪。

这些问题是一个高级主题，我在 BPF Performance Tools 的第 2、12 和 18 章中更详细地介绍了这个问题，并在此处进行了总结。

# #5.6.1 缺少符号
当分析器或跟踪器无法将应用程序指令地址解析为其函数名称（符号）时，它可以将其打印为十六进制数或字符串 “[unknown]”。此问题的解决方法取决于应用程序的编译器、运行时和优化以及分析器本身。

# ELF Binaries (C, C++, ...)
已编译的二进制文件中可能缺少符号，尤其是那些打包和分发的二进制文件，因为它们已使用 strip（1） 进行处理以减小文件大小。一种解决方法是调整构建过程以避免剥离元件;另一种方法是使用不同的符号信息源，例如 debuginfo 或 BPF 类型格式 （BTF）。通过 perf（1）、BCC 和 bpftrace 进行 Linux 性能分析支持 debuginfo 符号

# JIT Runtimes (Java, Node.js, ...)
缺少符号通常发生在 Java 和 Node 等实时 （JIT） 编译器运行时中。JS 的。在这些情况下，JIT 编译器有自己的符号表，该表在运行时会发生变化，并且不是二进制文件中预编译的符号表的一部分。常见的解决方法是使用运行时生成的补充符号表，这些表被放置在 <PID>perf（1） 和 BCC 读取的 /tmp/perf-.map 文件中

例如，Netflix 使用 perf-map-agent [Rudolph 18]，它可以附加到实时 Java 进程并转储补充符号文件。我已经使用另一个名为 jmaps [Gregg 20c] 的工具自动使用它，该工具应该在配置文件之后和符号转换之前立即运行。例如，使用 perf（1）（第 13 章）：

 # perf record -F 49 -a -g -- sleep 10; jmaps
 # perf script --header > out.stacks
 # [...]

并使用 bpftrace （第 15 章）：

 # bpftrace --unsafe -e 'profile:hz:49 { @[ustack] = count(); }
    interval:s:10 { exit(); } END { system("jmaps"); }'

配置文件示例和符号表转储之间的符号映射可能会发生变化，从而在配置文件中产生无效的函数名称。这称为符号改动，在 perf record 之后立即运行 jmaps 可以减少它。到目前为止，这还不是一个严重的问题;如果是，则可以在配置文件之前和之后进行元件转储以查找更改。

还有其他方法可以解析 JIT 符号。一种是使用符号时间戳日志记录，perf（1） 支持它并解决了符号改动问题，尽管启用时开销更高。另一种是让 perf（1） 调用运行时自己的堆栈遍历器（通常存在于异常堆栈中）。这种方法有时使用堆栈帮助程序来调用，对于 Java，它已经由 async-profiler [Pangin 20] 实现。

请注意，JIT 运行时也具有预编译的组件：JVM 还使用 libjvm 和 libc。有关解决这些组件的信息，请参阅前面的 ELF 二进制文件部分。

# #5.6.2 缺少堆栈跟踪
另一个常见问题是堆栈跟踪缺失或不完整，可能短至一帧或两帧。例如，从 MySQL 服务器的 off-CPU 配置文件中：

  finish_task_switch
    schedule
    futex_wait_queue_me
    futex_wait
    do_futex
    __x64_sys_futex
    do_syscall_64
    entry_SYSCALL_64_after_hwframe
    pthread_cond_timedwait@@GLIBC_2.3.2
    [unknown]

这个堆栈是不完整的：pthread_cond_timedwait（） 之后是一个 “[unknown]” 帧。在这一点下面缺少 MySQL 函数，而我们真正需要的是那些 MySQL 函数来理解应用程序上下文。

有时堆栈是单个帧：
---------------
send
---------------
在火焰图中，这可能显示为 “grass”：配置文件底部有许多薄的单帧

不幸的是，不完整的堆栈跟踪很常见，通常是由两个因素共同引起的：1） 可观察性工具使用基于帧指针的方法读取堆栈跟踪，以及 2） 目标二进制文件没有为帧指针保留寄存器（x86_64上的 RBP），而是将其重新用作通用寄存器作为编译器性能优化。可观察性工具读取此寄存器，期望它是一个帧指针，但实际上它现在可以包含任何内容：数字、对象地址、指向字符串的指针等。可观测性工具会尝试解析 symbol 表中的这个数字，如果幸运的话，它不会找到它，并且可以打印 “[unknown]”。如果不走运，该随机数将解析为不相关的符号，现在打印的堆栈跟踪的函数名称是错误的，这会使最终用户感到困惑。

由于 libc 库通常在没有帧指针的情况下编译，因此在 libc 的任何路径中都很常见，包括前面的两个示例：pthread_cond_timedwait（） 和 send（）。

最简单的解决方案通常是修复帧指针寄存器：

■ 对于 C/C 软件，以及使用 gcc（1） 或 LLVM 编译的其他软件：使用 -fno-omit-frame-pointer 重新编译软件。
■ 对于 Java：使用 -XX 运行 java（1）：+PreserveFramePointer

这可能会带来性能成本，但通常以低于 1% 的比例进行衡量;能够使用 Stack Trace 查找性能优势的好处通常远远超过此成本。

另一种方法是切换到不基于帧指针的堆栈遍历技术。perf（1） 支持基于 DWARF 的堆栈遍历、ORC 和最后一个分支记录 （LBR）。其他堆栈遍历方法在第 13 章 perf， 第 13.9 节 perf 记录中提到。

在撰写本文时，BPF 不提供基于 DWARF 的堆栈步进和 LBR 堆栈步进，并且 ORC 尚不可用于用户级软件

# 5.7 练习
1. 回答以下有关术语的问题：
■ 什么是缓存？
■ 什么是环形缓冲区？
■ 什么是旋转锁？
■ 什么是自适应互斥锁？
■ 并发和并行有什么区别？
■ 什么是 CPU 关联性？

2. 回答以下概念性问题：
■ 使用大 I/O 大小的一般优缺点是什么？
■ 锁的哈希表是做什么用的？
■ 描述编译语言、内部语言和使用虚拟机的语言的运行时的一般性能特征。
■ 说明垃圾回收的作用以及它如何影响性能。

3. 选择一个应用程序，并回答以下有关它的基本问题：
■ 应用程序的作用是什么？
■ 应用程序执行什么离散作？
■ 应用程序是在用户模式还是内核模式下运行？应用程序是如何配置的？
■ 关于性能有哪些关键选项？
■ 应用程序提供哪些性能指标？
■ 应用程序创建哪些日志？
■ 它们是否包含性能信息？最新版本的应用程序是否修复了性能问题？
■ 应用程序是否存在已知的性能错误？
■ 应用程序是否有社区（例如，IRC、聚会）？一个表演社区？
■ 有关于该应用程序的书籍吗？性能书籍？
■ 是否有针对该应用程序的知名性能专家？他们是谁？

4. 选择一个负载充足的应用程序，并执行以下任务（其中许多任务可能需要使用动态跟踪）： 
■ 在进行任何测量之前，您预计应用程序是 CPU 绑定还是 I/O 绑定？解释你的理由。
■ 使用可观测性工具确定它是受 CPU 限制还是受 I/O 限制。
■ 为应用程序生成 CPU 火焰图。您可能需要修复符号和堆栈跟踪才能正常工作。最热门的 CPU 代码路径是什么？
■ 为应用程序生成 CPU 外火焰图。应用程序请求期间最长的阻塞事件是什么 （ignore idle stacks）？
■ 描述它执行的 I/O 的大小（例如，文件系统读/写、网络发送/接收）。
■ 应用程序是否有缓存？确定其大小和命中率。
■ 测量应用程序所服务的作的延迟 （响应时间）。显示平均值、最小值、最大值和完全分布。
■ 对作执行向下钻取分析，调查大部分延迟的来源。 
■ 描述应用于应用程序的工作负载（尤其是人员和内容）。
■ 逐步完成静态性能优化清单。
■ 应用程序是否并发运行？调查它对同步基元的使用情况。

5. （可选，高级）为 Linux 开发一个名为 tsastat（8） 的工具，该工具可以打印多个线程状态分析状态的列，并在每个状态中花费时间。这可以类似于 pidstat（1） 并产生滚动输出。

# 5.8 引用
 [Knuth 76] Knuth, D., “Big Omicron and Big Omega and Big Theta,” ACM SIGACT News, 
1976.
 [Knuth 97] Knuth, D., The Art of Computer Programming, Volume 1: Fundamental Algorithms, 
3rd Edition, Addison-Wesley, 1997.
 [Zijlstra 09] Zijlstra, P., “mutex: implement adaptive spinning,” http://lwn.net/
 Articles/314512, 2009.
 [Gregg 17a] Gregg, B., “EuroBSDcon: System Performance Analysis Methodologies,” 
EuroBSDcon, http://www.brendangregg.com/blog/2017-10-28/bsd-performance-analysis
methodologies.html, 2017
 [Intel 18] “Tool tracing syscalls in a fast way using eBPF linux kernel feature,” 
https://github.com/pmem/vltrace, last updated 2018.
 [Microsoft 18] “Fibers,” Windows Dev Center, https://docs.microsoft.com/en-us/windows/
 win32/procthread/fibers, 2018.
 [Rudolph 18] Rudolph, J., “perf-map-agent,” https://github.com/jvm-profiling-tools/
 perf-map-agent, last updated 2018.
 [Schwartz 18] Schwartz, E., “Dynamic Optimizations for SBCL Garbage Collection,” 
11th European Lisp Symposium, https://european-lisp-symposium.org/static/proceedings/
 2018.pdf, 2018.
 [Axboe 19] Axboe, J., “Efficient IO with io_uring,” https://kernel.dk/io_uring.pdf, 2019.
 [Gregg 19] Gregg, B., BPF Performance Tools: Linux System and Application Observability, 
Addison-Wesley, 2019.
 [Apdex 20] Apdex Alliance, “Apdex,” https://www.apdex.org, accessed 2020.
 [Golang 20] “Why goroutines instead of threads?” Golang documentation, https://golang.org/
 doc/faq#goroutines, accessed 2020.
 [Gregg 20b] Gregg, B., “BPF Performance Tools,” https://github.com/brendangregg/
 bpf-perf-tools-book, last updated 2020.
 [Gregg 20c] Gregg, B., “jmaps,” https://github.com/brendangregg/FlameGraph/blob/master/
 jmaps, last updated 2020.
 [Linux 20e] “RCU Concepts,” Linux documentation, https://www.kernel.org/doc/html/
 latest/RCU/rcu.html, accessed 2020.
 [Microsoft 20] “Procmon Is a Linux Reimagining of the Classic Procmon Tool from the 
Sysinternals Suite of Tools for Windows,” https://github.com/microsoft/ProcMon-for-Linux, 
last updated 2020.
 [Molnar 20] Molnar, I., and Bueso, D., “Generic Mutex Subsystem,” Linux documentation, 
https://www.kernel.org/doc/Documentation/locking/mutex-design.rst, accessed 2020.
 [Node.js 20] “Node.js,” http://nodejs.org, accessed 2020.
 [Pangin 20] Pangin, A., “async-profiler,” https://github.com/jvm-profiling-tools/
 async-profiler, last updated 2020