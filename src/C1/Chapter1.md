# Chapter 1: 引言
计算机性能是一门令人兴奋、多样且具有挑战性的学科。本章将向您介绍系统性能领域。本章的学习目标是：

■了解系统性能、角色、活动和挑战。
■了解可观察性和实验工具之间的区别。
■对性能可观测性有基本的了解：统计、分析、火焰图、跟踪、静态检测和动态检测。
■了解方法的作用和 Linux 60 秒检查清单。

包括对后面章节的引用，因此这既可以作为系统性能的介绍，也可以作为本书的介绍。本章以案例研究结束，以展示系统性能在实践中是如何工作的。

# 1.1 系统性能
系统性能研究整个计算机系统的性能，包括所有主要的软件和硬件组件。数据路径中的任何内容（从存储设备到应用程序软件）都包括在内，因为它会影响性能。对于分布式系统，这意味着多个服务器和应用程序。如果您没有显示数据路径的环境图，请找到一个或自己绘制;这将帮助您了解组件之间的关系，并确保您不会忽略整个区域。
系统性能的典型目标是通过减少延迟来改善最终用户体验并降低计算成本。通过消除低效因素、提高系统吞吐量和一般调整，可以降低成本。

图 1.1 显示了单个服务器上的通用系统软件堆栈，包括作系统 （OS） 内核，以及示例数据库和应用程序层。术语 完整堆栈 有时仅用于描述应用程序环境，包括数据库、应用程序和 Web 服务器。但是，当谈到系统性能时，我们使用 full stack 来表示从应用程序到硬件（硬件）的整个软件堆栈，包括系统库、内核和硬件本身。系统性能研究全栈

编译器包含在图 1.1 中，因为它们在系统性能中起着重要作用。此堆栈将在第 3 章作系统中讨论，并在后面的章节中更详细地研究。以下各节更详细地介绍了系统性能。

# 1.2 角色
系统性能由各种工作角色完成，包括系统管理员、站点依赖能力工程师、应用程序开发人员、网络工程师、数据库管理员、Web 管理员和其他支持人员。对于其中许多角色，性能只是工作的一部分，性能分析侧重于该角色的职责范围：网络团队检查网络，数据库团队检查数据库，依此类推。对于某些性能问题，查找根本原因或促成因素需要多个团队的协作努力。

一些公司雇用性能工程师，他们的主要活动是性能。他们可以与多个团队合作，对环境进行整体研究，这种方法对于解决复杂的性能问题可能至关重要。它们还可以充当中心资源，以查找和开发更好的工具，用于整个环境的性能分析和容量规划。

例如，Netflix 有一个云性能团队，我是其中的一员。我们协助微服务和 SRE 团队进行性能分析，并构建供所有人使用的性能工具。1.3 活动 3 雇用多名性能工程师的公司可以允许个人专注于一个或多个领域，从而提供更深层次的支持。例如，大型性能工程团队可能包括内核性能、客户端性能、语言性能（例如 Java）、运行时性能（例如 JVM）、性能工具等方面的专家。

# 1.3 活动
系统性能涉及各种活动。以下是软件项目生命周期中从概念到开发再到生产部署的理想步骤的活动列表。本书介绍了帮助执行这些活动的方法和工具。
1. 为未来的产品设定性能目标和性能建模。
2. 原型软件和硬件的性能表征。
3. 在测试环境中对开发中的产品进行性能分析。
4. 新产品版本的非回归测试。
5. 对产品发布进行基准测试。
6. 在目标生产环境中进行概念验证测试。
7. 生产中的性能调优。
8. 监控正在运行的生产软件。
9. 生产问题的性能分析。
10. 生产问题的事件审查。
11. 性能工具开发以增强生产分析。

步骤 1 到 5 包括传统的产品开发，无论是销售给客户的产品还是公司内部服务。然后启动产品，可能首先在目标环境（客户或本地）中进行概念验证测试，或者可能直接进行部署和配置。如果在目标环境中遇到问题（步骤 6 到 9），则表示在开发阶段未检测到或修复该问题。

理想情况下，性能工程应该在选择任何硬件或编写软件之前开始：第一步应该是设定目标并创建性能模型。但是，产品开发通常没有此步骤，从而将性能工程工作推迟到问题出现后的稍后时间。在开发过程的每一步中，修复由于早期做出的架构决策而出现的性能问题可能会变得越来越困难。

云计算为概念验证测试（步骤 6）提供了新技术，鼓励跳过前面的步骤（步骤 1 到 5）。其中一种技术是在单个实例上测试新软件，而生产工作负载的工作量很小：这称为 Canary 测试。另一种技术使此成为软件部署中的正常步骤：流量逐渐移动到新的实例池，同时使旧池保持在线作为备份;这被称为blue-green-deployment.有了这种安全故障选项，新软件通常在生产中进行测试，而无需事先进行任何性能分析，并在需要时快速恢复。我建议您在可行的情况下，也要执行早期活动，以便实现最佳性能（尽管可能出于上市时间原因，需要尽早迁移到生产环境）。

术语 容量规划 可以指上述许多活动。在设计过程中，它包括研究开发软件的资源占用情况，以了解设计在多大程度上满足目标需求。部署后，它包括监控资源使用情况，以便在问题发生之前预测问题。

生产问题的性能分析（第 9 步）也可能涉及站点可靠性工程师 （SRE）;此步骤之后是事件审查会议（步骤 10），以分析发生的情况，分享调试技术，并寻找避免将来发生相同事件的方法。这样的会议类似于开发者回顾（参见 [Corry 20] 了解回顾及其反模式）。

环境和活动因公司和产品而异，在许多情况下，并非全部执行了 10 个步骤。您的工作也可能只关注其中的一部分或其中一项活动。

# 1.4 观点
除了关注不同的活动外，还可以从不同的对象查看绩效角色。图 1.2 中标记了性能分析的两个角度：工作负载分析和资源分析，它们从不同的方向处理软件堆栈。

资源分析透视图通常由负责系统资源的系统管理员使用。应用程序开发人员，负责交付的工作负载的性能，通常侧重于工作负载分析的角度。每种观点都有自己的优势，第 2 章 方法论 中有详细讨论。对于具有挑战性的问题，尝试从两个角度进行分析会有所帮助

# #1.5 性能是一项挑战
系统性能工程是一个具有挑战性的领域，原因有很多，包括它是主观的、复杂的、可能没有单一的根本原因，并且它经常涉及多个问题。

# #1.5.1 主观性
技术学科往往是客观的，以至于业内人士以非黑即白而闻名。对于软件故障排除来说，情况就是如此，其中 bug 要么存在，要么不存在，要么已修复，要么未修复。此类错误通常表现为错误 mes sages，可以很容易地解释和理解为存在错误。另一方面，性能通常是主观的。对于性能问题，可能不清楚是否存在问题，如果有，则何时修复。对于一个用户来说，可能被视为“不良”性能（因此是一个问题）对于另一个用户来说，可能被视为“良好”性能。

请考虑以下信息

平均磁盘 I/O 响应时间为 1 毫秒。

这是“好”还是“坏”？虽然响应时间或延迟是可用的最佳指标之一，但很难理解延迟信息。在某种程度上，给定指标是“好”还是“坏”可能取决于应用程序开发人员和最终用户的性能期望

通过定义明确的目标，例如设定目标平均响应时间，或要求一定比例的请求处于一定的延迟范围内，可以使主观性能变得客观。第 2 章 方法论 中介绍了处理这种主观性的其他方法，包括延迟分析。

# #1.5.2 复杂性
除了主观性之外，由于系统的复杂性和缺乏明显的分析起点，性能也可能是一门具有挑战性的学科。在云计算环境中，您甚至可能不知道首先要查看哪个服务器实例。有时，我们从一个假设开始，例如归咎于网络或数据库，性能分析师必须弄清楚这是否是正确的方向。

性能问题也可能源于子系统之间的复杂交互，这些交互在单独分析时通常表现良好。这可能是由于级联故障而发生的，当一个故障组件导致其他组件出现性能问题时。要了解由此产生的问题，您必须理清组件之间的关系并了解它们如何发挥作用。

瓶颈也可能很复杂，并以意想不到的方式相关;修复一个可能只是将瓶颈移动到系统中的其他位置，整体性能并没有像预期的那样得到改善。

除了系统的复杂性外，性能问题也可能是由生产工作负载的复杂特性引起的。这些情况在实验室环境中可能永远无法重现，或者只能间歇性地重现。

解决复杂的性能问题通常需要一种整体方法。整个系统（包括其内部和外部交互）可能需要进行调查。这需要广泛的技能，并可能使性能工程成为一项多样化且具有智力挑战性的工作。

正如第 2 章所介绍的那样，可以使用不同的方法来指导我们解决这些复杂性;第 6 章到第 10 章包括针对特定系统资源的特定方法：CPU、内存、文件系统、磁盘和网络。（[Dekker 18] 研究了一般复杂系统的分析，包括石油泄漏和金融系统的崩溃。

在某些情况下，性能问题可能是由这些资源的交互引起的。

# #1.5.3 多种原因
某些性能问题没有单一的根本原因，而是具有多个影响因素。想象一下这样一个场景：三个正常事件同时发生并组合在一起会导致性能问题：每个事件都是正常事件，单独来看并不是根本原因。除了多种原因外，还可能存在多种性能问题。

# #1.5.4 多个性能事件
发现性能问题通常不是问题;在复杂的软件中，通常有很多。为了说明这一点，请尝试查找您的作系统或应用程序的错误数据库，然后搜索单词 performance。你可能会感到惊讶！通常，会存在许多已知但尚未修复的性能问题，即使在被认为具有高性能的成熟软件中也是如此。这在分析性能时带来了另一个困难：真正的任务不是发现问题;它是确定哪个或哪些问题最重要

为此，性能分析师必须量化问题的严重性。某些性能问题可能不适用于您的工作负载，或者可能仅在很小的程度上适用。理想情况下，您不仅会量化问题，还会估计每个问题的潜在加速。当管理层寻找花费工程或运营资源的理由时，此信息可能很有价值

如果可用，一个非常适合性能量化的指标是延迟

# 1.6 延迟
延迟是衡量等待时间的指标，也是一项重要的性能指标。从广义上讲，它可以表示完成任何作的时间，例如应用程序请求、数据库查询、文件系统作等。例如，延迟可以表示网站从链接单击到屏幕绘制完全加载的时间 1.7 可观察性 7。这对客户和网站提供商来说都是一个重要的指标：高延迟会导致挫败感，客户可能会将他们的业务转移到其他地方

作为一个指标，延迟可以估计最大加速比。例如，图 1.3 描述了一个数据库查询，该查询需要 100 毫秒（这是延迟），在此期间，它花费 80 毫秒阻塞等待磁盘读取。通过消除磁盘读取（例如，通过缓存）可以计算出最大的性能提升：从 100 毫秒到 20 毫秒 （100 – 80） 的速度要快五倍 （5 倍）。这是估计的加速比，计算还量化了性能问题：磁盘读取导致查询运行速度慢了 5 倍。

使用其他量度时，无法进行此类计算。例如，每秒 I/O作数 （IOPS） 取决于 I/O 的类型，通常无法直接比较。如果更改将 IOPS 速率降低 80%，则很难知道性能会受到什么影响。IOPS 可能会减少 5 倍，但如果每个 I/O 的大小（字节）都增加了 10 倍，该怎么办。

如果没有限定词，延迟也可能是模棱两可的。例如，在网络中，延迟可能表示建立连接的时间，但不是数据传输时间;或者它可以表示连接的总持续时间，包括数据传输（例如，DNS 延迟通常只能以这种方式衡量）。在本书中，我将尽可能使用澄清术语：这些示例最好描述为连接延迟和请求延迟。每章的开头还总结了延迟术语。

虽然延迟是一个有用的指标，但它并不总是在需要时可用。某些系统区域仅提供平均延迟;有些根本不提供延迟测量。随着基于 BPF2 的新可观测性工具的推出，现在可以从任意兴趣点测量延迟，并且可以提供显示延迟完整分布的数据。

# 1.7 可观测性
可观测性是指通过观察来了解系统，并对实现此目的的工具进行分类。这包括使用计数器、分析和跟踪的工具。它不包括基准测试工具，这些工具通过执行工作负载实验来修改系统的状态。对于生产环境，应尽可能首先尝试可观测性工具，因为实验性工具可能会通过资源争用来扰乱生产工作负载。对于空闲的测试环境，您可能希望从基准测试工具开始，以确定硬件性能。

在本节中，我将介绍计数器、指标、分析和跟踪。我将在第 4 章中更详细地解释可观测性，涵盖系统范围的可观测性与每进程的可观测性、Linux 可观测性工具及其内部结构。第 5 章到第 11 章包括有关可观测性的章节特定部分，例如，第 6.6 节介绍了 CPU 可观测性工具。

# # 1.7.1 计数器，统计，指标
应用程序和内核通常提供有关其状态和活动的数据：作计数、字节计数、延迟测量、资源利用率和错误率。它们通常实现为称为计数器的整数变量，这些变量在软件中硬编码，其中一些是累积的并且始终递增。性能工具可以在不同时间读取这些累积计数器，以计算统计数据：随时间的变化率、平均值、百分位数等。

例如，vmstat（8） 工具根据 /proc 文件系统中的内核计数器打印系统范围的虚拟内存统计信息摘要等。此示例 vmstat（8） 输出来自 48 CPU 的生产 API 服务器

这表明系统范围的 CPU 利用率约为 57%（cpu us sy 列）。第 6 章和第 7 章将详细解释这些列。

指标是已选择用于评估或监控目标的统计数据。大多数公司使用监控代理定期记录选定的统计数据（指标），并在图形界面中绘制它们以查看随时间的变化。监控软件还可以支持根据这些指标创建自定义警报，例如在检测到问题时发送电子邮件以通知员工。

从计数器到警报的层次结构如图 1.4 所示。图 1.4 是作为指南提供的，以帮助您理解这些术语，但它们在行业中的使用并不严格。术语 counters、statistics 和 metrics 通常可以互换使用。此外，警报可以由任何层生成，而不仅仅是专用警报系统。

作为绘制度量标准的一个例子，图 1.5 是一个基于 Grafana 的工具观察与早期 vmstat（8） 输出相同的服务器的屏幕截图

这些折线图可用于容量规划，帮助您预测资源何时会耗尽

了解性能统计信息的计算方式后，您对性能统计信息的解释将得到改进。统计量（包括平均值、分布、众数和异常值）在第 2 章 方法论， Section 2.8 统计中进行了总结。

有时，只需使用时间序列指标即可解决性能问题。知道问题开始的确切时间可能与已知的软件或配置更改相关，这些更改可以恢复。其他时候，指标仅指向一个方向，表明存在 CPU 或磁盘问题，但没有解释原因。分析或跟踪工具对于深入挖掘并找到原因是必需的。

# #1.7.2 分析
在系统性能中，术语 profiling 通常是指使用执行 sam pling 的工具：获取测量的子集（样本）以绘制目标的粗略图片。CPU 是一个常见的性能分析目标。分析 CPU 的常用方法包括对 CPU 上的代码路径进行定时采样。

CPU 配置文件的有效可视化是火焰图。CPU 火焰图可以帮助您找到比任何其他工具（仅次于指标）的性能优势。它们不仅揭示了 CPU 问题，还揭示了其他类型的问题，这些问题是通过它们留下的 CPU 占用空间发现的。通过在 spin paths 中查找 CPU 时间，可以发现锁争用问题;可以通过在内存分配函数 （malloc（）） 中查找过多的 CPU 时间以及导致这些问题的代码路径来分析内存问题;通过在慢速或旧版代码路径中看到 CPU 时间，可以识别涉及错误网络的性能问题;等等。

图 1.6 是一个示例 CPU 火焰图，显示了 iperf（1） 网络微基准测试工具所花费的 CPU 周期

此火焰图显示了复制字节（以 copy_user_enhanced_fast_string（） 结尾的路径）与 TCP 传输（左侧包含 tcp_write_xmit（））的塔）所花费的 CPU 时间。宽度与所花费的 CPU 时间成正比，纵轴显示代码路径。

第 4 章、第 5 章和第 6 章介绍了分析器，火焰图可视化在第 6 章 CPU 的第 6.7.3 节 火焰图 中进行了解释

# #1.7.3 追踪
跟踪是基于事件的记录，其中事件数据被捕获并保存以供以后分析，或动态用于自定义摘要和其他作。有用于系统调用（例如 Linux strace（1））和网络数据包（例如 Linux tcpdump（8））的专用跟踪工具;以及可以分析所有软件和硬件事件执行情况的通用跟踪工具（例如 Linux Ftrace、BCC 和 bpftrace）。这些全能跟踪器使用各种事件源，特别是静态和动态检测，以及用于可编程性的 BPF

# Static Instrumentation 
静态检测描述添加到源代码中的硬编码软件检测点。Linux 内核中有数百个这样的点，用于检测磁盘 I/O、调度程序事件、系统调用等。用于内核静态控制的 Linux 技术称为跟踪点。还有一种用于用户空间软件的静态检测技术，称为用户静态定义跟踪 （USDT）。库（例如 libc）使用 USDT 来检测库调用，许多应用程序使用 USDT 来检测服务请求。

作为一个使用静态 instrumentation 的示例工具，execsnoop（8） 通过检测 execve（2） 系统调用的跟踪点来打印在跟踪（运行）时创建的新进程。下面显示了 execsnoop（8） 跟踪 SSH 登录。

这对于揭示其他可观察能力工具（如 top（1））可能遗漏的短期进程特别有用。这些短期进程可能是性能问题的根源。

有关跟踪点和 USDT 探针的更多信息，请参阅第 4 章

# Dynamic Instrumentation
动态插桩通过修改内存中指令以插入插桩例程，在软件运行后创建插桩点。这类似于调试器在运行软件中的任何函数上插入断点的方式。当遇到断点时，调试器将执行流程传递给交互式调试器，而动态说明运行例程，然后继续目标软件。此功能允许从任何正在运行的软件创建自定义性能统计信息。以前由于缺乏可观察性而无法解决或难以解决的问题现在可以得到修复。

动态仪表与传统观测截然不同，起初可能很难掌握其作用。考虑一个作系统内核：分析内核内部就像冒险进入一个暗室，将蜡烛（系统计数器）放置在内核工程师认为需要它们的地方。动态仪表就像拥有一个可以指向任何地方的手电筒。

动态插桩最早创建于 1990 年代 [Hollingsworth 94]，以及使用它的工具（例如，kerninst [Tamches 99]）。对于 Linux，动态指令于 2000 年首次开发 [Kleen 08]，并于 2004 年开始合并到内核中 （kprobes）。然而，这些技术并不为人所知，并且难以使用。当 Sun Microsystems 在 2005 年推出自己的版本 DTrace 时，这种情况发生了变化，该版本易于使用且对生产安全。我开发了许多基于 DTrace 的工具，这些工具显示了它对系统性能的重要性，这些工具得到了广泛使用，并帮助 DTrace 和动态插桩广为人知。

# BPF
BPF 最初代表 Berkeley Packet Filter，现在为 Linux 的最新动态跟踪工具提供支持。BPF 起源于一个小型内核内虚拟机，用于加速 tcpdump（8） 表达式的执行。自 2013 年以来，它已被扩展（因此有时称为 eBPF3）成为通用的内核内执行环境，提供安全和快速访问资源的环境。它的许多新用途包括跟踪工具，其中它为 BPF 编译器集合 （BCC） 和 bpftrace 前端提供可编程性。execsnoop（8） 是一个 BCC 工具4。

第 3 章介绍了 BPF，第 15 章介绍了 BPF 跟踪前端：BCC 和 BPF 跟踪。其他章节在其可观测性部分中介绍了许多基于 BPF 的跟踪工具;例如，CPU 跟踪工具包含在第 6 章 “CPU”的 Section 6.6 可观测性工具中。我还出版了以前关于跟踪工具的书籍（适用于 DTrace [Gregg 11a] 和 BPF [Gregg 19]）。perf（1） 和 Ftrace 也是跟踪器，具有与 BPF 前端类似的功能。perf（1） 和 Ftrace 在第 13 章和第 14 章中介绍

# 1.8 实验
除了可观测性工具外，还有实验工具，其中大多数是基准工具。它们通过对系统应用综合工作负载并测量其性能来执行实验。这必须小心进行，因为实验工具会干扰被测系统的性能

有一些宏基准测试工具可以模拟真实世界的工作负载，例如客户端发出应用程序请求;还有一些微基准测试工具可以测试特定组件，例如 CPU、磁盘或网络。打个比方：一辆车在 Laguna Seca 赛道的单圈时间可以被认为是一个宏观基准，而它的最高速度和 0 到 60 英里/小时的时间可以被认为是微观基准。这两种基准测试类型都很重要，但微基准测试通常更容易调试、重复和理解，并且更稳定

以下示例在空闲服务器上使用 iperf（1） 对远程空闲服务器执行 TCP 网络吞吐量微基准测试。此基准测试运行 10 秒 （-t 10） 并生成每秒平均值 （-i 1）
-----------------------------------------------------------
Client connecting to 100.65.33.90, TCP port 5001
 TCP window size: 12.0 MByte (default)-----------------------------------------------------------
[  3] local 100.65.170.28 port 39570 connected with 100.65.33.90 port 5001
 [ ID] Interval       Transfer     Bandwidth
 [  3]  0.0- 1.0 sec   582 MBytes  4.88 Gbits/sec
 [  3]  1.0- 2.0 sec   568 MBytes  4.77 Gbits/sec
 [  3]  2.0- 3.0 sec   574 MBytes  4.82 Gbits/sec
 [  3]  3.0- 4.0 sec   571 MBytes  4.79 Gbits/sec
 [  3]  4.0- 5.0 sec   571 MBytes  4.79 Gbits/sec
 [  3]  5.0- 6.0 sec   432 MBytes  3.63 Gbits/sec
 [  3]  6.0- 7.0 sec   383 MBytes  3.21 Gbits/sec
 [  3]  7.0- 8.0 sec   388 MBytes  3.26 Gbits/sec
 [  3]  8.0- 9.0 sec   390 MBytes  3.28 Gbits/sec
 [  3]  9.0-10.0 sec   383 MBytes  3.22 Gbits/sec
 [  3]  0.0-10.0 sec  4.73 GBytes  4.06 Gbits/sec

输出显示前 5 秒的吞吐量5约为 4.8 Gbits，然后下降到大约 3.2 Gbits/秒。这是一个有趣的结果，显示了双峰吞吐量。为了提高性能，人们可以专注于 3.2 Gbits/sec 模式，并搜索其他可以解释它的指标。

考虑仅使用可观测性工具在生产服务器上调试此性能问题的缺点。由于客户端工作负载的自然差异，网络吞吐量可能每秒都不同，并且网络的基础双模行为可能并不明显。通过使用具有固定工作负载的 iperf（1），您可以消除客户端差异，从而揭示由于其他因素（例如，外部网络限制、缓冲区利用率等）引起的差异。

正如我之前建议的那样，在生产系统上，您应该首先尝试可观测性工具。但是，可观测性工具太多了，当实验性工具可以更快地获得结果时，您可能会花费数小时来研究它们。多年前，一位高级性能工程师 （Roch Bourbonnais） 教给我一个比喻是：你有两只手，可观察性和实验。只使用一种类型的工具就像试图单手解决问题一样。

第 6 章至第 10 章包括有关实验工具的部分;例如，CPU 实验工具在第 6 章 CPU 的 第 6.8 节 实验中介绍。

# 1.9 云计算
云计算是一种按需部署计算资源的方法，它支持在越来越多的小型虚拟系统（称为实例）中部署应用程序，从而实现了应用程序的快速扩展。这减少了对严格容量规划的需求，因为可以在短时间内从云中添加更多容量。在某些情况下，它还增加了对性能分析的需求，因为使用更少的资源可能意味着更少的系统。由于云使用通常按分钟或小时收费，因此性能优势导致系统数量减少可能意味着立即节省成本。将此场景与企业数据中心进行比较，在企业数据中心中，您可能被锁定在固定支持合同中多年，在合同结束之前无法实现成本节约。

云计算和虚拟化引起的新困难包括管理来自其他租户的性能影响（有时称为性能隔离）和来自每个租户的物理系统可观察性。例如，除非系统正确管理，否则磁盘 I/O 性能可能会因与邻居争用而变差。在某些环境中，每个租户可能无法观察到物理磁盘的真实使用情况，因此很难识别此问题。

第 11 章 “云计算”中介绍了这些主题

# 1.10 方法
方法是一种记录在系统性能中执行各种任务的推荐步骤的方法。如果没有方法，性能调查可能会变成钓鱼探险：尝试随机的事情，以期获得胜利。这可能既耗时又无效，同时允许忽视重要领域。第 2 章 方法论 包括系统性能的方法库。以下是我用于任何性能问题的第一个方法：基于工具的清单。

# #1.10.1 Linux perf 分析 in 60秒
这是一个基于 Linux 工具的检查表，可以在性能问题调查的前 60 秒内执行，使用大多数 Linux 发行版都应该可用的传统工具 [Gregg 15a]。表 1.1 显示了命令、要检查的内容以及本书中更详细地介绍该命令的部分

如果相同的指标可用，也可以使用监控 GUI 来遵循此清单

第 2 章 方法以及后面的章节包含更多性能分析方法，包括 USE 方法、工作负载特征、延迟分析等。

# 1.11 用例学习
如果您不熟悉系统性能，那么显示何时以及为何执行各种活动的案例研究可以帮助您将它们与当前环境联系起来。这里总结了两个假设的例子;一个是涉及磁盘 I/O 的性能问题，另一个是软件更改的性能测试

这些案例研究描述了本书其他章节中解释的活动。这里描述的方法也不是为了展示正确的方式或不唯一的方式，而是展示这些表演活动的一种方式，供你批判性地考虑。

# #1.11.1 慢磁盘分析
Sumit 是一家中型公司的系统管理员。数据库团队已提交支持票证，抱怨他们的一台数据库服务器上的“磁盘速度慢”。

Sumit 的首要任务是了解有关问题的更多信息，收集详细信息以形成问题陈述。该票证声称磁盘速度较慢，但未说明这是否会导致数据库问题。Sumit 通过提出以下问题来回答：

■目前是否存在数据库性能问题？
■它是如何测量的？
■此问题存在多长时间了？
■数据库最近有什么变化吗？
■为什么怀疑这些磁盘？

数据库团队回答说：“我们有一个日志，用于慢于 1000 毫秒的查询。这些通常不会发生，但在过去的一周里，它们已经增长到每小时几十次。AcmeMon 显示磁盘很忙。

这证实了存在真实的数据库问题，但也表明磁盘假设可能是一种猜测。Sumit 想要检查磁盘，但他也想快速检查其他资源，以防猜测错误。

AcmeMon 是该公司的基本服务器监控系统，它提供基于标准作系统指标的历史性能图表，这些指标与 mpstat（1）、iostat（1） 和系统实用程序打印的指标相同。Sumit 登录到 AcmeMon 亲自查看

Sumit 从一种称为 USE 方法的方法开始（在第 2 章 方法论， 第 2.5.9 节中定义）来快速检查资源瓶颈。正如数据库团队报告的那样，磁盘的利用率很高，约为 80%，而其他资源（CPU、网络）的利用率要低得多。历史数据显示，磁盘利用率在过去一周一直在稳步增长，而 CPU 利用率一直保持稳定。AcmeMon 不提供磁盘的饱和度或错误统计信息，因此要完成 USE 方法，Sumit 必须登录到服务器并运行一些命令

他从 /sys 检查磁盘错误计数器;他们是零。他以 1 秒的间隔运行 iostat（1），并观察一段时间内的利用率和饱和度指标。AcmeMon 报告了 80% 的利用率，但使用一分钟的间隔。在 1 秒的粒度下，Sumit 可以看到磁盘利用率的波动，通常达到 100%，并导致饱和级别和磁盘 I/O 延迟增加

为了进一步确认这是否阻塞了数据库 — 并且不是数据库查询的异步 — 他使用一个名为 offcputime（8） 的 BCC/BPF 跟踪工具来捕获堆栈跟踪，只要数据库被内核取消调度，以及花费在 CPU 之外的时间。堆栈跟踪显示，在文件系统读取期间，在查询期间，数据库经常被阻塞。这对 Sumit 来说已经足够了

下一个问题是为什么。磁盘性能统计信息似乎与高负载一致。Sumit 执行工作负载特征分析以进一步了解这一点，使用 iostat（1） 来测量 IOPS、吞吐量、平均磁盘 I/O 延迟和读/写比率。有关更多详细信息，Sumit 可以使用磁盘 I/O 跟踪;但是，他感到满意的是，这已经表明了磁盘负载较高，而不是磁盘的问题

Sumit 向票证添加了更多详细信息，说明了他检查了什么，并包括用于研究磁盘的命令的屏幕截图。到目前为止，他的总结是磁盘处于高负载下，这增加了 I/O 延迟并减慢了查询速度。但是，磁盘似乎对负载正常工作。他问是否有一个简单的解释：数据库负载是否增加？

数据库团队回答说，它没有，并且查询率（AcmeMon 没有报告）一直很稳定。这听起来与之前的发现一致，即 CPU 利用率也很稳定

Sumit 考虑了其他什么会导致更高的磁盘 I/O 负载，而 CPU 没有明显增加，并与他的同事进行了简短的交谈。其中一个建议文件系统碎片化，当文件系统接近 100% 容量时，这是预期的。Sumit 发现它只有 30%

Sumit 知道他可以执行深入分析7 来了解磁盘 I/O 的确切原因，但这可能很耗时。他尝试根据他对内核 I/O 堆栈的了解，首先考虑其他简单的解释，以便快速检查。他记得这个磁盘 I/O 主要是由文件系统缓存（页面缓存）未命中引起的

Sumit 使用 cachestat（8）8 检查文件系统缓存命中率，发现它目前是 91%。这听起来很高（不错），但他没有历史数据可以进行比较。他登录到其他服务于类似工作负载的数据库服务器，发现它们的缓存命中率超过 98%。他还发现，其他服务器上的文件系统缓存大小要大得多

将注意力转向文件系统缓存大小和服务器内存使用情况，他发现了一些被忽视的东西：一个开发项目有一个原型应用程序，它正在消耗越来越多的内存，即使它还没有处于生产负载下。此内存从文件系统缓存的可用内存中提取，从而降低其命中率并导致更多的文件系统读取变为磁盘读取

Sumit 联系应用程序开发团队，并要求他们关闭应用程序并将其移动到其他服务器，并指出数据库问题。完成此作后，Sumit 会观察 AcmeMon 中的磁盘利用率随着文件系统缓存恢复到其原始大小而逐渐下降。慢速查询返回零，他将票证关闭为已解决。

# #1.11.2 软件挑战
Pamela 是一家小公司的性能和可伸缩性工程师，她负责所有与性能相关的活动。应用程序开发人员开发了一个新的核心功能，并且不确定它的引入是否会损害性能。Pamela 决定在将新应用程序版本部署到生产环境之前执行该版本的非回归测试

Pamela 购买了一台空闲服务器以进行测试，并搜索客户端工作负载模拟器。应用程序团队不久前编写了一个，尽管它有各种限制和已知错误。她决定尝试一下，但想确认它与当前的生产工作负载完全相似

她将服务器配置为与当前部署配置匹配，并将客户端工作负载模拟器从不同的系统运行到服务器。可以通过研究访问日志来描述客户端工作负载的特征，并且已经有一个公司工具可以做到这一点，她使用了这个工具。她还在一天中不同时间的生产服务器日志上运行该工具，并比较工作负载。客户端模拟器似乎应用了平均生产工作负载，但没有考虑差异。她注意到了这一点并继续她的分析

Pamela 知道在这一点上可以使用多种方法。她选择了最简单的方法：增加客户端模拟器的负载，直到达到限制（这有时称为压力测试）。client 模拟器可以配置为每秒执行目标数量的客户端请求，她之前使用的默认值为 1000。她决定从 100 开始增加负载，然后增加 100 的增量，直到达到限制，每个级别测试一分钟。她编写了一个 shell 脚本来执行测试，该脚本将结果收集到一个文件中，以供其他工具进行绘图。

在负载运行时，她执行主动基准测试以确定限制因素是什么。服务器资源和服务器线程似乎在很大程度上处于空闲状态。客户端模拟器显示，请求吞吐量稳定在每秒 700 左右。

她切换到新的软件版本并重复测试。这也达到了 700 大关并趋于平稳。她还分析了服务器以查找限制因素，但同样看不到任何因素。

她绘制结果，显示已完成请求率与负载的关系，以直观地识别扩展能力概况。两者似乎都突然达到了上限

虽然这两个软件版本似乎具有相似的性能特征，但 Pamela 对她无法确定导致可扩展性上限的限制因素感到失望。她知道她只检查了服务器资源，而限制器可能是应用程序逻辑问题。它也可能在其他地方：网络或客户端模拟器。

Pamela 想知道是否需要一种不同的方法，例如运行固定的运行速率，然后描述资源使用情况（CPU、磁盘 I/O、网络 I/O），以便可以用单个客户端请求来表示。她以每秒 700 次的速率运行当前和新软件的模拟器，并测量资源消耗。对于给定负载，当前软件使 32 个 CPU 的平均利用率为 20%。对于相同的负载，新软件将相同的 CPU 利用率提高到 30%。看起来这确实是一种回归，它消耗了更多的 CPU 资源

为了了解 700 的限制，Pamela 启动了更高的负载，然后调查了数据路径中的所有组件，包括网络、客户端系统和客户端工作负载生成器。她还对服务器和客户端软件执行向下钻取分析。她记录了她检查过的内容，包括屏幕截图，以供参考

为了调查客户端软件，她执行线程状态分析，发现它是单线程的！该线程将 100% 的时间花在 CPU 上执行。这让她相信这是测试的限制因素

作为实验，她在不同的客户端系统上并行启动客户端软件。通过这种方式，她将当前软件和新软件的服务器 CPU 利用率提高到 100%。当前版本达到 3500 个请求/秒，新版本达到 2300 个请求/秒，这与之前关于资源消耗的发现一致

Pamela 告诉应用程序开发人员，新软件版本存在回归，她开始使用 CPU 火焰图分析其 CPU 使用情况，以了解原因：哪些代码路径有贡献。她指出，测试的是平均生产工作负载，而不同工作负载则没有。她还提交了一个 Bug，指出客户端工作负载生成器是单线程的，这可能会成为瓶颈。

# #1.11.3 更多阅读
第 16 章 案例研究 提供了更详细的案例研究，其中记录了我如何解决特定的云性能问题。下一章介绍了用于性能分析的方法，其余章节涵盖了必要的背景和细节。

# 1.12 引用
 [Hollingsworth 94] Hollingsworth, J., Miller, B., and Cargille, J., “Dynamic Program 
Instrumentation for Scalable Performance Tools,” Scalable High-Performance Computing 
Conference (SHPCC), May 1994.
 [Tamches 99] Tamches, A., and Miller, B., “Fine-Grained Dynamic Instrumentation of 
Commodity Operating System Kernels,” Proceedings of the 3rd Symposium on Operating Systems 
Design and Implementation, February 1999.
 [Kleen 08] Kleen, A., “On Submitting Kernel Patches,” Intel Open Source TechnologyCenter, 
http://halobates.de/on-submitting-patches.pdf, 2008.20 
 [Gregg 11a] Gregg, B., and Mauro, J., DTrace: Dynamic Tracing in Oracle Solaris, Mac OS X and 
FreeBSD, Prentice Hall, 2011.
 [Gregg 15a] Gregg, B., “Linux Performance Analysis in 60,000 Milliseconds,” Netflix 
Technology Blog, http://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.
 html, 2015.
 [Dekker 18] Dekker, S., Drift into Failure: From Hunting Broken Components to Understanding 
Complex Systems, CRC Press, 2018.
 [Gregg 19] Gregg, B., BPF Performance Tools: Linux System and Application Observability, 
Addison-Wesley, 2019.
 [Corry 20] Corry, A., Retrospectives Antipatterns, Addison-Wesley, 2020