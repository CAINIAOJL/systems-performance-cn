# Chapter 9: 磁盘
磁盘 I/O 可能会导致显著的应用程序延迟，因此是系统性能分析的重要目标。在高负载下，磁盘成为瓶颈，在系统等待磁盘 I/O 完成时使 CPU 处于空闲状态。识别并消除这些瓶颈可以将性能和应用程序吞吐量提高几个数量级。

术语 磁盘 是指系统的主存储设备。它们包括基于闪存的固态磁盘 （SSD） 和磁性旋转磁盘。SSD 的推出主要是为了提高磁盘 I/O 性能，而 SSD 确实如此。但是，对容量、I/O 速率和吞吐量的需求也在增加，闪存设备也不能幸免于性能问题。

本章的学习目标是：
■ 了解磁盘访问模式如何影响性能。
■ 了解解释磁盘利用率的风险。
■ 熟悉磁盘设备特性和内部结构。
■ 熟悉从文件系统到设备的内核路径。
■ 了解 RAID 级别及其性能。
■ 遵循不同的磁盘性能分析方法。
■ 描述系统范围和每个进程的磁盘 I/O 特征。
■ 测量磁盘 I/O 延迟分布并识别异常值。
■ 识别请求磁盘 I/O 的应用程序和代码路径。
■ 使用跟踪器详细调查磁盘 I/O。
■ 了解磁盘可调参数。

本章由六个部分组成，前三个部分为磁盘 I/O 分析提供基础，后三个部分介绍其在基于 Linux 的系统中的实际应用。这些部分如下：

■ 背景：介绍了与存储相关的术语、磁盘设备的基本模型和关键的磁盘性能概念。
■ 体系结构: 提供存储硬件和软件体系结构的一般描述。
■ 方法: 描述了性能分析方法，包括观察性和实验性。
■ Observability Tools: （可观测性工具） 显示基于 Linux 的系统的磁盘性能可观测性工具，包括跟踪和可视化。实验总结了磁盘基准测试工具。
■ 优化: 介绍了磁盘可调参数示例。

上一章介绍了基于磁盘构建的文件系统的性能，是了解应用程序性能的更好研究目标

# 9.1 术语
本章中使用的与磁盘相关的术语包括

■ 虚拟磁盘：存储设备的模拟。它在系统中显示为单个物理磁盘，但它可能是由多个磁盘或磁盘的一部分构成的。■ 传输：用于通信的物理总线，包括数据传输 （I/O） 和其他磁盘命令。
■ 扇区：磁盘上的一个存储块，通常大小为 512 字节，但现在通常为 4 KB。
■ I/O：严格来说，I/O 仅包括磁盘读取和写入，不包括其他磁盘命令。I/O 至少可以通过方向 （读取或写入）、磁盘地址 （位置） 和大小 （字节） 来描述。
■ 磁盘命令：可以命令磁盘执行其他非数据传输命令（例如，缓存刷新）。
■ 吞吐量：对于磁盘，吞吐量通常是指当前数据传输速率，以每秒字节数为单位。
■ 带宽：这是存储传输或控制器的最大可能数据传输速率;它受硬件限制。
■ I/O 延迟：I/O作从开始到结束的时间。第 9.3.1 节 测量时间 定义了更精确的时间术语。请注意，联网使用术语 latency 来指代启动 I/O 所需的时间，后跟数据传输时间。延迟异常值：延迟异常高的磁盘 I/O

本章介绍了其他术语。词汇表包括基本术语以供参考（如果需要），包括磁盘、磁盘控制器、存储阵列、本地磁盘、远程磁盘和 IOPS。另请参阅第 2 章和第 3 章中的术语部分。

# 9.2 原则
以下简单模型说明了磁盘 I/O 性能的一些基本原则

# #9.2.1 简单磁盘
现代磁盘包括一个用于 I/O 请求的磁盘队列，如图 9.1 所示。

磁盘接受的 I/O 可能正在等待队列或正在提供服务。这个简单的模型类似于杂货店结账，客户在其中排队等待服务。它也非常适合使用排队理论进行分析。

虽然这可能意味着先到先得的队列，但磁盘上的控制器可以应用其他算法来优化性能。这些算法可以包括对旋转磁盘的电梯查找（参见 第 9.4.1 节， 磁盘类型 中的讨论），或者为读取和写入 I/O 设置单独的队列（特别是对于基于闪存的磁盘）。

# #9.2.2 缓存磁盘
添加磁盘缓存允许从更快的内存类型满足一些读取请求，如图 9.2 所示。这可以实现为物理磁盘设备中包含的少量内存 （DRAM）。

虽然缓存命中以非常低（良好）的延迟返回，但缓存未命中仍然很频繁，返回时磁盘设备延迟很高。

磁盘上缓存还可用于提高写入性能，方法是将其用作回写缓存。这表示写入在数据传输到缓存之后和传输到持久磁盘存储的速度较慢之前已完成。counter-term 是 write-through cache，它仅在完全传输到 Next Level 后完成写入。

在实践中，存储回写缓存通常与电池结合使用，因此在发生电源故障时仍然可以保存缓冲数据。此类电池可能位于磁盘或磁盘控制器上

# #9.2.3 控制器
图 9.3 显示了一种简单类型的磁盘控制器，它将 CPU I/O 传输与存储传输和连接的磁盘设备连接起来。这些也称为主机总线适配器 （HBA）。

性能可能会受到这些总线、磁盘控制器或磁盘的限制。有关磁盘控制器的更多信息，请参见部分 9.4， 体系结构

# 9.3 概念
以下是磁盘性能中的重要概念

# #9.3.1 测量时间
I/O 时间可以通过以下方式测量：

■ I/O 请求时间（也称为 I/O 响应时间）：从发出 I/O 到完成的全部时间 
■ I/O 等待时间：等待队列 
■ I/O 服务时间：处理 I/O 的时间（未等待）

术语 service time 起源于磁盘是由操作系统直接管理的简单设备，因此操作系统知道磁盘何时主动为 I/O 提供服务。磁盘现在执行自己的内部排队，操作系统服务时间包括等待内核队列所花费的时间。

在可能的情况下，我会使用澄清性术语来说明正在测量的内容，从哪个开始事件到哪个结束事件。开始和结束事件可以基于内核或基于磁盘，基于内核的时间从磁盘设备的块 I/O 接口测量（如图 9.7 所示）。

从内核：

■ Block I/O 等待时间（也称为 OS 等待时间）是从创建新 I/O 并将其插入内核 I/O 队列到离开最终内核队列并发送到磁盘设备所花费的时间。这可能跨越多个内核级队列，包括块 I/O 层队列和磁盘设备队列。
■ Block I/O 服务时间是从向设备发出请求到设备完成中断的时间。
■ Block I/O 请求时间既是 Block I/O 等待时间，也是 Block I/O 服务时间：从创建 I/O 到完成 I/O 的全长时间。

从磁盘：

■ Disk wait time （磁盘等待时间） 是在磁盘队列上花费的时间。
■ 磁盘服务时间是主动处理 I/O 所需的磁盘队列之后的时间。
■ 磁盘请求时间（也称为磁盘响应时间和磁盘 I/O 延迟）既是磁盘等待时间，也是磁盘服务时间，等于块 I/O 服务时间。

这些如图 9.5 所示，其中 DWT 是磁盘等待时间，DST 是磁盘服务时间。此图还显示了磁盘上的缓存，以及磁盘缓存命中如何导致磁盘服务时间 （DST） 大大缩短。

I/O 延迟是另一个常用术语，在第 1 章中介绍。与其他术语一样，这意味着什么取决于它的测量位置。I/O 延迟本身可能是指块 I/O 请求时间：整个 I/O 时间。应用程序和性能工具通常使用术语磁盘 I/O 延迟来指代磁盘请求时间：设备上的整个时间。如果您从设备的角度与硬件工程师交谈，他们可能会使用术语 Disk I/O latency 来指代磁盘等待时间。

块 I/O 服务时间通常被视为当前磁盘性能的度量（这是旧版本的 iostat（1） 显示的）;但是，您应该知道，这是一种简化。在图 9.7 中，图中显示了一个通用的 I/O 堆栈，它显示了 block device 接口下的三个可能的驱动程序层。其中任何一个都可能实现自己的队列，或者可能在互斥锁上阻塞，从而增加 I/O 的延迟。此延迟包含在块 I/O 服务时间内

# 计算时间
磁盘服务时间通常不能通过内核统计信息直接观察，但可以使用 IOPS 和利用率推断出平均磁盘服务时间：

磁盘服务时间 = 利用率/IOPS

例如，利用率为 60% 且 IOPS 为 300，则平均服务时间为 2 毫秒（ 600 毫秒/300 IOPS）。这假定利用率反映的是单个设备（或服务中心），该设备一次只能处理一个 I/O。磁盘通常可以并行处理多个 I/O，因此此计算不准确

事件跟踪可以通过测量磁盘 I/O 的提交和完成的高分辨率时间戳来提供准确的磁盘服务时间，而不是使用内核统计信息。这可以使用本章后面描述的工具来完成（例如，第 9.6.6 节 生物潜伏期中的 biolatency（8）。

# #9.3.2 时间尺度
磁盘 I/O 的时间刻度可以按数量级变化，从几十微秒到几千毫秒不等。在规模最慢的一端，单个缓慢的磁盘 I/O 可能会导致应用程序响应时间不佳;在最快的一端，磁盘 I/O 可能只会在大量情况下成为问题（许多快速 I/O 的总和等于慢速 I/O）。

对于上下文，Table 9.1 提供了磁盘 I/O 延迟的可能范围的一般概念。有关精确值和当前值，请查阅磁盘供应商文档，并执行您自己的微基准测试。另请参阅第 2 章 “方法”，了解磁盘 I/O 以外的时间刻度。

为了更好地说明所涉及的数量级，Scaled 列显示了基于一秒的虚构磁盘缓存命中延迟的比较。

这些延迟可能会根据环境要求进行不同的解释。在企业存储行业工作时，我认为任何超过 10 毫秒的磁盘 I/O 都异常缓慢，并且是性能问题的潜在来源。在云计算行业中，对高延迟的容忍度更高，尤其是在面向 Web 的应用程序中，这些应用程序已经期望网络和客户端浏览器之间出现高延迟。在这些环境中，磁盘 I/O 可能仅在 50 毫秒后成为问题（单独或在应用程序请求期间总共）。

此表还说明了磁盘可以返回两种类型的延迟：一种用于磁盘上的缓存命中（小于 100 μs），另一种用于未命中（1-8 ms 或更高，具体取决于访问模式和设备类型）。由于磁盘将返回这些的混合，因此将它们一起表示为平均延迟（如 iostat（1） ）可能会产生误导，因为这实际上是一个具有两种模式的发行版。请参阅第 2 章 方法中的图 2.23，了解以直方图表示的磁盘 I/O 延迟分布示例。

# #9.3.3 缓存
最好的磁盘 I/O 性能是完全没有。软件堆栈的许多层都尝试通过缓存读取和缓冲写入来避免磁盘 I/O，一直到磁盘本身。这些高速缓存的完整列表位于第 3 章操作系统的表 3.2 中，其中包括应用程序级高速缓存和文件系统高速缓存。在磁盘设备驱动程序级别及以下级别，它们可能包括表 9.2 中列出的缓存

第 8 章 “文件系统”中介绍了基于块的缓冲区高速缓存。这些磁盘 I/O 缓存对于提高随机 I/O 工作负载的性能尤为重要。

# #9.3.4 随机VS顺序I/O
磁盘 I/O 工作负载可以根据 I/O 在磁盘上的相对位置（磁盘偏移量），使用术语随机和顺序来描述。这些术语在 第 8 章 文件系统 中讨论了文件访问模式。

顺序工作负载也称为流式工作负载。术语 流 通常用于应用程序级别，用于描述流式读取和写入 “到磁盘” （文件系统）。

在磁性旋转磁盘时代，随机与顺序磁盘 I/O 模式的研究很重要。对于这些实例，随机 I/O 会在磁盘磁头查找时产生额外的延迟，而platter 在 I/O 之间旋转。如图 9.6 所示，其中 seek 和 rotation 都必须让磁盘磁头在扇区 1 和 2 之间移动（实际采用的路径将尽可能直接）。性能调优涉及识别随机 I/O 并尝试以多种方式消除它，包括缓存、将随机 I/O 隔离到单独的磁盘，以及放置磁盘以缩短寻道距离。

其他磁盘类型（包括基于闪存的 SSD）通常在随机和顺序读取模式上执行时没有区别。根据驱动器的不同，由于其他因素可能会有细微的差异，例如，地址查找缓存可以跨越顺序访问，但不能跨越随机访问。由于读取-修改写入周期，小于块大小的写入可能会遇到性能损失，尤其是对于随机写入。

请注意，从操作系统看到的磁盘偏移量可能与物理磁盘上的偏移量不匹配。例如，硬件提供的虚拟磁盘可能会跨多个磁盘映射连续的偏移量范围。磁盘可以以自己的方式重新映射偏移量（通过磁盘数据控制器）。有时，随机 I/O 不是通过检查偏移量来识别的，而是可以通过测量增加的磁盘服务时间来推断的。

# #9.3.5 读/写比
除了识别随机工作负载与顺序工作负载之外，另一个特征度量是读取与写入的比率，即 IOPS 或吞吐量。这可以表示为随时间变化的比率，以百分比表示，例如，“自启动以来，系统一直以 80% 的读取速度运行”。

了解此比率有助于设计和配置系统。具有高读取速率的系统可能从添加缓存中受益最大。写入速率较高的系统可能从添加更多磁盘以提高最大可用吞吐量和 IOPS 中受益最大

读取和写入本身可能显示不同的工作负载模式：读取可能是随机 I/O，而写入可能是顺序的（特别是对于写入时复制文件系统）。它们也可能表现出不同的 I/O 大小。

# #9.3.6 I/O尺寸
平均 I/O 大小（字节）或 I/O 大小的分布是另一个工作负载特征。较大的 I/O 大小通常提供更高的吞吐量，但每 I/O 延迟会更长。

I/O 大小可由磁盘设备子系统更改（例如，量化为 512 字节扇区）。由于 I/O 是由内核组件（如文件系统、卷管理器和设备驱动程序）在应用程序级别发出的，因此大小也可能已经膨胀和缩小。请参见第 8 章 “文件系统”， 部分 8.3.12， 逻辑 I/O 与物理 I/O“中的”膨胀“和”收缩“部分

某些磁盘设备（尤其是基于闪存的磁盘设备）在读取和写入大小不同时执行非常不同。例如，基于闪存的磁盘驱动器在 4 KB 读取和 1 MB 写入时可能表现最佳。理想的 I/O 大小可以由磁盘供应商记录，或者使用微基准测试来确定。可以使用观察工具找到当前使用的 I/O 大小（请参见部分 9.6， 可观察性工具）。

# #9.3.7 IOPS 并不相等
由于最后三个特征，IOPS 并不相同，无法在不同设备和工作负载之间直接比较。IOPS 值本身并不意味着很多。

例如，对于旋转磁盘，5000 个连续 IOPS 的工作负载可能比 1000 个随机 IOPS 的工作负载快得多。基于 Flash 内存的 IOPS 也很难比较，因为它们的 I/O 性能通常与 I/O 大小和方向（读取或写入）有关

IOPS 对应用程序工作负载甚至可能没有那么重要。由随机请求组成的工作负载通常对延迟敏感，在这种情况下，需要高 IOPS 速率。流式处理（顺序）工作负载对吞吐量敏感，因此可能更需要较大的 I/O 的较低 IOPS 速率

要理解 IOPS，请包括其他详细信息：随机或顺序、I/O 大小、读/写、缓冲/直接以及并行 I/O 数量。此外，请考虑使用基于时间的指标，例如利用率和服务时间，这些指标反映了最终的性能，可以更轻松地进行比较。

# #9.3.8 非数据传输磁盘命令
除了 I/O 读取和写入之外，还可以向磁盘发送其他命令。例如，可以命令具有磁盘上缓存 （RAM） 的磁盘将缓存刷新到磁盘。这样的命令不是数据传输;数据以前通过写入发送到磁盘

另一个示例命令用于丢弃数据：ATA TRIM 命令或 SCSI UNMAP 命令。这告诉驱动器不再需要扇区范围，并可以帮助 SSD 驱动器保持写入性能。

这些磁盘命令可能会影响性能，并可能导致在其他 I/O 等待时使用磁盘。

# #9.3.9 利用率
利用率可以计算为磁盘在时间间隔内忙于主动执行工作的时间

利用率为 0% 的磁盘为 “空闲”，利用率为 100% 的磁盘持续忙于执行 I/O（和其他磁盘命令）。利用率为 100% 的磁盘可能是性能问题的根源，尤其是当它们在一段时间内保持 100% 时。但是，任何磁盘利用率都可能导致性能不佳，因为磁盘 I/O 通常是一项缓慢的活动。

也可能存在 0% 到 100% 之间的点（比如 60%），此时磁盘的性能不再令人满意，因为排队的可能性增加，无论是在磁盘队列中还是在操作系统中。成为问题的确切利用率值取决于磁盘、工作负载和延迟要求。请参见第 2 章 方法， 第 2.6.5 节 排队理论中的 M/D/1 和 60% 利用率部分。

要确认高利用率是否导致应用程序问题，请研究磁盘响应时间以及应用程序是否阻止此 I/O。应用程序或操作系统可能正在异步执行 I/O，因此慢速 I/O 不会直接导致应用程序等待。

请注意，利用率是一个间隔摘要。磁盘 I/O 可能会以突发形式发生，尤其是由于写入刷新，这在较长的时间间隔进行汇总时可能会被掩盖。有关利用率度量类型的进一步讨论，请参见第 2 章 “方法”， 第 2.3.11 节 “利用率”。

# 虚拟磁盘利用率
对于由硬件（例如，磁盘控制器或网络连接存储）提供的虚拟磁盘，操作系统可能知道虚拟磁盘何时繁忙，但对构建虚拟磁盘的基础磁盘的性能一无所知。这会导致操作系统报告的虚拟磁盘利用率与实际磁盘上的意外利用率明显不同（并且有悖常理）：

■ 100% 繁忙且基于多个物理磁盘构建的虚拟磁盘可能能够接受更多工作。在这种情况下，100% 可能意味着某些磁盘一直处于繁忙状态，但并非所有磁盘都处于空闲状态，因此某些磁盘处于空闲状态。
■ 在写入工作负载期间，包含回写缓存的虚拟磁盘可能不会显得非常繁忙，因为磁盘控制器会立即返回写入完成，即使底层磁盘在之后的一段时间内处于繁忙状态。
■ 由于硬件 RAID 重建，磁盘可能很忙，操作系统看不到相应的 I/O。

出于同样的原因，可能很难解释操作系统软件（软件 RAID）创建的虚拟磁盘的利用率。但是，操作系统也应该公开物理磁盘的利用率，可以对其进行检查。

一旦物理磁盘达到 100% 的利用率并请求更多的 I/O，它就会达到饱和

# #9.3.10 饱和率
饱和度是衡量排队工作超出资源可以交付范围的工作的指标。对于磁盘设备，它可以计算为操作系统中设备等待队列的平均长度（假设它排队）。

这提供了超过 100% 利用率点的性能度量。利用率为 100% 的磁盘可能没有饱和度（排队），或者可能有很多，由于 I/O 排队而严重影响性能。

您可能假设利用率低于 100% 的磁盘没有饱和，但这实际上取决于利用率间隔：间隔期间 50% 的磁盘利用率可能意味着在一半的时间内 100% 利用率，其余时间处于空闲状态。任何间隔摘要都可能会遇到类似的问题。当准确了解发生了什么很重要时，可以使用跟踪工具来检查 I/O 事件。

# #9.3.11 I/O 等待
I/O 等待是按 CPU 性能指标，显示当 CPU 调度器队列（处于睡眠状态）上的线程在磁盘 I/O 上被阻止时，显示空闲所花费的时间。这会将 CPU 空闲时间划分为无事可做所花费的时间和磁盘 I/O 阻塞所花费的时间。每个 CPU 的高 I/O 等待率表明磁盘可能是一个瓶颈，使 CPU 在等待磁盘时处于空闲状态。

I/O 等待可能是一个非常令人困惑的指标。如果出现另一个 CPU 密集型进程，则 I/O 等待值可能会下降：CPU 现在有事可做，而不是空闲。但是，尽管 I/O 等待指标有所下降，但相同的磁盘 I/O 仍然存在并阻止线程。当系统管理员升级了应用程序软件，而较新的版本效率更高且使用的 CPU 周期更少，从而揭示了 I/O 等待时，有时会发生相反的情况。这可能会使系统管理员认为升级导致了磁盘问题并使性能变得更糟，而实际上磁盘性能相同，但 CPU 性能得到了提高

更可靠的指标是应用程序线程在磁盘 I/O 上被阻止的时间。这捕获了磁盘引起的应用程序线程所承受的痛苦，无论 CPU 可能正在执行其他工作。可以使用静态或动态检测来衡量此指标。

I/O 等待仍然是 Linux 系统上的一个常用指标，尽管它的性质令人困惑，但它成功地用于识别一种类型的磁盘瓶颈：磁盘繁忙、CPU 空闲。解释它的一种方法是将任何等待 I/O 视为系统瓶颈的标志，然后调整系统以将其降至最低 — 即使 I/O 仍与 CPU 利用率同时发生。并发 I/O 更有可能是非阻塞 I/O，并且不太可能导致直接问题。非并发 I/O（如 I/O 等待所标识）更有可能成为应用程序阻塞 I/O 和瓶颈。

# #9.3.12 同步VS异步
如果应用程序 I/O 和磁盘 I/O 异步运行，则磁盘 I/O 延迟可能不会直接影响应用程序性能，这一点很重要。这通常发生在回写式缓存中，其中应用程序 I/O 提前完成，磁盘 I/O 稍后发出

应用程序可以使用预读来执行异步读取，这在磁盘完成 I/O 时可能不会阻止应用程序。文件系统可能会自行启动此程序以预热缓存 （prefetch）

即使应用程序正在同步等待 I/O，该应用程序代码路径也可能是非关键的，并且与客户端应用程序请求异步。它可以是应用程序 I/O 工作线程，创建该线程是为了在其他线程继续处理工作时管理 I/O。

内核通常还支持异步或非阻塞 I/O，其中为应用程序提供了一个 API 来请求 I/O 并在稍后的某个时间收到其完成的通知。有关这些主题的更多信息，请参见第 8 章 “文件系统”， 部分 8.3.9， 非阻塞 I/O;8.3.5，预读;8.3.4，预取;和 8.3.7 同步写入


# #9.3.13 磁盘VS应用程序I/O
磁盘 I/O 是各种内核组件（包括文件系统和设备驱动程序）的最终结果。此磁盘 I/O 的速率和卷可能与应用程序发出的 I/O 不匹配的原因有很多。这些包括：

■ 文件系统膨胀、通缩和无关的 I/O。请参见第 8 章 文件系统的 第 8.3.12 节 逻辑 I/O 与物理 I/O。
■ 由于系统内存不足而导致的分页。请参见第 7 章 内存， 第 7.2.2 节 分页。
■ 设备驱动程序 I/O 大小：向上舍入 I/O 大小，或对 I/O 进行分段。RAID 写入镜像或校验和块，或验证读取数据。

这种不匹配在意外时可能会令人困惑。可以通过学习架构和执行分析来理解

# 9.4 架构
本节介绍磁盘体系结构，通常在容量规划期间研究磁盘体系结构，以确定不同组件和配置选择的限制。在调查以后的性能问题时，还应检查它，以防问题源于架构选择，而不是当前的负载和优化。

# #9.4.1 磁盘种类
目前最常用的两种磁盘类型是基于磁性旋转和闪存的 SSD。这两者都提供永久存储;与 Volatile Memory 不同，它们存储的内容在重启后仍然可用。

# #9.4.1.1 磁旋转
也称为硬盘驱动器 （HDD），这种类型的磁盘由一个或多个浸渍有氧化铁颗粒的光盘（称为盘片）组成。这些颗粒的一小部分可以在两个方向之一上放大;这个方向用于存储 bit 。盘片旋转，而带有读取和写入数据的电路的机械臂可到达整个表面。此电路包括磁盘磁头，并且一个臂可能有多个磁头，从而允许它同时读取和写入多个位。数据以圆形磁道的形式存储在盘片上，每个磁道被划分为多个扇区

作为机械设备，这些设备的执行速度相对较慢，尤其是对于随机 I/O。随着基于闪存的技术的进步，SSD 正在取代旋转磁盘，可以预见有一天旋转磁盘将过时（以及其他较旧的存储技术：鼓盘和核心内存）。同时，旋转磁盘在某些场景下仍然具有竞争力，例如经济的高密度存储（每 MB 成本低），尤其是对于数据仓库

以下主题总结了影响旋转磁盘性能的因素

# 位移与旋转
磁性旋转盘的慢 I/O 通常是由磁盘磁头的寻道时间和磁盘盘片的旋转时间引起的，这两者都可能需要几毫秒。最好的情况是，下一个请求的 I/O 位于当前服务 I/O 的末尾，这样磁盘磁头就不需要寻找或等待额外的旋转。如前所述，这称为顺序 I/O，而需要磁头搜索或等待旋转的 I/O 称为随机 I/O

有许多策略可以减少搜索和旋转等待时间，包括:
■ 缓存：完全消除 I/O。
■ 文件系统放置和行为，包括 copy-on-write （这使得写入顺序，但可能会使以后的读取随机）。
■ 将不同的工作负载分离到不同的磁盘，以避免在工作负载 I/O 之间寻找。
■ 将不同的工作负载移动到不同的系统（某些云计算环境可以这样做以减少多租户影响）。
■ 电梯搜索，由磁盘本身执行。更高密度的磁盘，以收紧工作负载位置。
■ 分区（或“切片”）配置，例如，短行程。

减少轮换等待时间的另一种策略是使用更快的磁盘。磁盘有不同的转速，包括 5400、7200、10 K 和 15 K 转/分钟 （rpm）。请注意，由于热量和磨损增加，较高的速度会导致磁盘寿命缩短

# 理论最大吞吐量d
如果知道磁盘每个磁道的最大扇区数，则可以使用以下公式计算磁盘吞吐量：

最大吞吐量 = 每个磁道的最大扇区数 × 扇区大小 × RPM/60 秒

此公式对于准确公开此信息的旧磁盘更有用。新式磁盘向操作系统提供磁盘的虚拟映像，并仅公开这些属性的综合值

# 短行程
短行程是指仅将磁盘的外部磁道用于工作负载;其余部分要么未使用，要么用于低吞吐量工作负载（例如存档）。这减少了寻道时间，因为磁头移动的范围较小，并且磁盘可能会将磁头静止在外边缘，从而减少空闲后的第一次寻道。由于扇区分区，外部轨道通常也具有更好的吞吐量（请参阅下一节）。在检查已发布的磁盘基准测试时，请留意短行程，尤其是不包括价格的基准测试，其中可能使用了许多短行程磁盘。

# 扇区分区
磁盘磁道的长度各不相同，最短的磁道位于圆盘的中心，最长的磁道位于外边缘。扇区分区（也称为多区域录制）不是固定每个轨道的扇区（和位）数量，而是增加了较长轨道的扇区数，因为可以物理写入更多的扇区。由于旋转速度是恒定的，因此较长的外边缘磁道提供比内部磁道更高的吞吐量（每秒兆字节）

# 扇区大小
存储行业为磁盘设备开发了一种称为 Advanced Format 的新标准，以支持更大的扇区大小，尤其是 4 KB。这减少了 I/O 计算开销，提高了吞吐量，并减少了磁盘每个扇区存储的元数据的开销。磁盘固件仍可通过称为高级格式 512e 的仿真标准提供 512 字节的扇区。根据磁盘的不同，这可能会增加写入开销，从而调用读取-修改-写入周期以将 512 字节映射到 4 KB 扇区。其他需要注意的性能问题包括未对准的 4 KB I/O，它跨越两个扇区，使扇区 I/O 膨胀以服务于它们

# 磁盘缓存
这些磁盘的常见组件是少量内存 （RAM），用于缓存读取和缓冲区写入的结果。此内存还允许在设备上对 I/O （命令） 进行排队，并更有效地重新排序。对于 SCSI，这是标记命令队列 （TCQ）;对于 SATA，它称为本机命令队列 （NCQ）。

# 电梯搜索
电梯算法（也称为电梯搜索）是命令队列可以提高效率的一种方式。它根据 I/O 在磁盘上的位置对 I/O 进行重新排序，以最大限度地减少磁盘磁头的行程。结果类似于建筑电梯，它不根据按下楼层按钮的顺序为楼层提供服务，而是在建筑物中上下扫荡，停在当前请求的楼层。

当检查磁盘 I/O 跟踪并发现按完成时间排序 I/O 与按开始时间排序不匹配时，此行为变得明显：I/O 完成顺序混乱

虽然这似乎是明显的性能优势，但请考虑以下场景：在偏移量 1,000 附近向磁盘发送了一批 I/O，在偏移量 2,000 处发送了一批 I/O。磁盘磁头当前为 1,000。偏移量为 2,000 的 I/O 何时进行维修？现在考虑一下，当 I/O 接近 1,000 时，更多的 I/O 到达 1,000 附近，更多，更多 — 足够的连续 I/O 使磁盘在偏移量 1,000 附近忙碌 10 秒。何时处理 2000 个偏移量的 I/O，以及其最终 I/O 延迟是多少

# 数据完整性
磁盘在每个扇区的末尾存储纠错码 （ECC） 以确保数据完整性，以便驱动器可以验证数据是否已正确读取，或更正可能发生的任何错误。如果第二个没有被正确读取，磁盘磁头可能会在下一次旋转时重试读取（并且可能会重试几次，每次都稍微改变磁头的位置）。这可能是 I/O 异常缓慢的原因。驱动器可能会向操作系统提供软错误以解释发生了什么。监控软错误率可能很有用，因为增加可能表明驱动器可能很快就会出现故障。

行业从 512 字节扇区切换到 4 KB 扇区的一个好处是，相同数据量所需的 ECC 位更少，因为 ECC 对于较大的扇区大小更有效 [Smith 09]

请注意，其他校验和也可能用于验证数据。例如，循环冗余校验 （CRC） 可用于验证到主机的数据传输，而文件系统可能正在使用其他校验和。

# 振动
虽然磁盘设备供应商很清楚振动问题，但这些问题并未被行业普遍了解或认真对待。2008 年，在调查一个神秘的性能问题时，我进行了一项振动诱导实验，当磁盘阵列执行写入基准测试时，我对它大喊大叫，这导致了非常慢的 I/O 突发。我的实验立即被录像并放到 YouTube 上，在那里它在网上疯传，它被描述为振动对磁盘性能影响的第一次演示 [Turner 10]。该视频的观看次数已超过 1,700,000 次，提高了对磁盘振动问题的认识 [Gregg 08]。根据我收到的电子邮件，我似乎还意外地催生了一个数据中心隔音行业：您现在可以聘请专业人员来分析数据中心的声级，并通过抑制振动来提高磁盘性能。

# 树懒盘
某些旋转磁盘的当前性能问题是发现所谓的懒惰磁盘。这些磁盘有时会返回非常慢的 I/O，超过 1 秒，并且没有报告任何错误。这比基于 ECC 的重试应该花费的时间要长得多。如果此类磁盘返回故障而不是花费这么长时间，那么实际上可能会更好，以便操作系统或磁盘控制者可以采取纠正措施，例如在冗余环境中关闭磁盘并报告故障。懒惰磁盘很麻烦，尤其是当它们是由存储阵列提供的虚拟磁盘的一部分时，操作系统无法直接查看，这使得它们更难识别。

# SMR
叠瓦式磁记录 （SMR） 驱动器通过使用更窄的磁道提供更高的密度。这些磁道对于写入头来说太窄了，但对于（较小的）读磁头来说却不是，所以它通过部分重叠其他磁道来写入它们，其样式类似于屋顶瓦片（因此得名）。使用 SMR 的驱动器将密度增加了约 25%，但代价是写入性能下降，因为重叠数据被销毁，也必须重写。这些驱动器适用于写入一次然后大部分读取的存档工作负载，但不适合 RAID 配置中的写入密集型工作负载 [Mellor 20]

# 磁盘数据控制器
机械磁盘为系统提供了一个简单的接口，这意味着固定的每磁道扇区比率和连续的可寻址偏移量范围。磁盘上实际发生的情况取决于磁盘数据控制器 — 磁盘内部微处理器，由固件编程。磁盘可以实现包括扇区分区在内的算法，从而影响偏移量的布局方式。这是需要注意的一点，但很难分析 —操作系统无法看到磁盘数据控制器

# #9.4.1.2 固态硬盘
这些也称为固态磁盘 （SSD）。术语固态是指它们使用固态电子设备，它提供可编程非易失性存储器，其性能通常比旋转盘好得多。由于没有移动部件，这些磁盘在物理上也很耐用，不易受到振动引起的性能问题的影响。

这种磁盘类型的性能通常在不同的偏移量（无旋转或寻道延迟）之间是一致的，并且对于给定的 I/O 大小是可预测的。工作负载的随机或顺序特性比旋转盘重要得多。所有这些都使它们更容易学习和进行容量规划。但是，如果它们确实遇到了性能病症，由于它们的内部运行方式，了解它们可能与旋转磁盘一样复杂。

一些 SSD 使用非易失性 DRAM （NV-DRAM）。大多数使用闪存。

# 闪存
基于闪存的 SSD 提供高读取性能，尤其是随机读取性能，其性能可以比旋转磁盘高出几个数量级。大多数是使用 NAND 闪存构建的，NAND 闪存使用基于电子的捕获电荷存储介质，可以在无电源状态下持续存储电子4 [Cornwell 12]。“flash” 这个名字与数据的写入方式有关，它需要一次擦除整个内存块（包括多个页面，通常每页 8 或 64 KB）并重写内容。由于这些写入开销，闪存具有非对称的读/写性能：快速读取和较慢写入。驱动器通常使用回写缓存来提高写入性能，并使用小电容器作为电源故障时的备用电池来缓解这种情况


闪存有不同的类型： 
■ 单级单元 （SLC）：将数据位存储在单个单元中。
■ Multi-level cell （MLC）：每个单元存储多个位（通常为 2 位，需要四个电压电平）。企业多层单元 （eMLC）：具有高级固件的 MLC，供企业使用。
■ 三电平单元 （TLC）：存储 3 位（8 个电压电平）。
■ 四级单元 （QLC）：存储 4 位。
■ 3D NAND / 垂直 NAND （V-NAND）：这将闪存层（例如 TLC）堆叠起来，以提高密度和存储容量。

此列表按时间顺序粗略排列，最新技术列在最后：3D NAND 自 2013 年以来一直在商用。

与其他类型的 SLC 相比，SLC 往往具有更高的性能和可靠性，并且是企业使用的首选，尽管成本更高。尽管 MLC 的可靠性较低，但由于其密度较高，现在经常在企业中使用。闪存可靠性通常以驱动器预期支持的块写入 （编程/擦除周期） 数来衡量。对于 SLC，这个预期约为 50,000 到 100,000 个周期;对于 MLC，大约 5,000 到 10,000 次循环;对于 TLC，大约 3,000 次循环;QLC 约为 1,000 个周期 [Liu 20]。

# 控制器
SSD 的控制器具有以下任务 [Leventhal 13]： 
■ 输入：每页进行读取和写入（通常为 8 KB）;写入只能发生在已擦除的页面;页面以 32 到 64 个 （256–512 KB） 的块进行擦除。
■ 输出：模拟硬盘驱动器块接口：读取或写入任意扇区（512 字节或 4 KB）。

输入和输出之间的转换由控制器的 flash 转换层 （FTL） 执行，该层还必须跟踪 free blocks。它本质上使用自己的文件系统来执行此作，例如日志结构的文件系统

写入特性对于写入工作负载来说可能是一个问题，尤其是在写入小于闪存块大小（可能高达 512 KB）的 I/O 大小时。这可能会导致写入放大，即在擦除之前将块的其余部分复制到其他位置，并且至少在擦除-写入周期内也会出现延迟。一些闪存驱动器通过提供由电池供电的磁盘缓冲区（基于 RAM）来缓解延迟问题，以便以后可以缓冲和写入写入，即使在发生电源故障时也是如此。

由于闪存布局，我用过的最常见的企业级闪存驱动器在 4 KB 读取和 1 MB 写入时性能最佳。这些值因驱动器而异，可以通过 I/O 大小的微基准测试找到

鉴于 flash 的本机作与公开的块接口之间的差异，操作系统及其文件系统仍有改进的空间。TRIM 餐厅命令就是一个例子：它通知 SSD 某个区域不再使用，使 SSD 能够更轻松地组装其空闲块池，从而减少写入放大。（对于 SCSI，可以使用 UNMAP 或 WRITE SAME 命令实现;对于 ATA，可以使用 DATA SET MANAGEMENT 命令。Linux 支持包括 discard 挂载选项和 fstrim（8） 命令。

# 寿命
NAND 闪存作为存储介质存在各种问题，包括烧毁、数据衰落和读取干扰 [Cornwell 12]。这些可以通过 SSD 控制器来解决，它可以移动数据以避免出现问题。它通常采用磨损均衡，将写入分散到不同的 ent 块中，以减少单个块的写入周期，以及内存超额配置，它保留额外的内存，可以在需要时映射到服务

虽然这些技术延长了使用寿命，但 SSD 的每个块的写入周期数仍然有限，具体取决于闪存的类型和驱动器采用的缓解功能。企业级驱动器使用内存预留空间和最可靠的闪存类型 SLC 来实现 100 万或更高的写入周期率。基于 MLC 的消费级驱动器可能提供低至 1,000 次循环。

# 病症
以下是一些需要注意的闪存 SSD 病症： 
■ 由于老化而导致的延迟异常值，以及 SSD 更努力地提取正确的数据（使用 ECC 进行检查）。■ 由于碎片导致的延迟更高（重新格式化可能会通过清理 FTL 块图来解决此问题）。
■ 如果 SSD 实施内部压缩，则吞吐量性能会降低。
检查 SSD 性能功能的其他开发情况和遇到的问题。

# #9.4.1.3 持久化存储
持久内存采用电池供电 DRAM 的形式，用于存储控制器回写缓存。这种类型的性能比闪存快几个数量级，但其成本和有限的电池寿命使其仅限于特殊用途。

由 Intel 和美光开发的一种名为 3D XPoint 的新型持久内存将允许持久内存以极具吸引力的性价比用于更多应用，介于 DRAM 和闪存之间。3D XPoint 的工作原理是将位存储在可堆叠的交叉网格数据访问数组中，并且是字节可寻址的。Intel 性能比较报告称，3D XPoint 的访问延迟为 14 微秒，而 3D NAND SSD 的访问延迟为 200 微秒 [Hady 18]。3D XPoint 在测试中也显示出一致的延迟，而 3D NAND 的延迟分布更宽，最高可达 3 毫秒。

3D XPoint 自 2017 年以来一直在商用。英特尔使用品牌名称傲腾，并将其作为 DIMM 封装的英特尔傲腾持久内存和英特尔傲腾固态硬盘发布。

# #9.4.2 接口
接口是驱动器支持的协议，用于与系统通信，通常通过磁盘控制器。以下是 SCSI、SAS、SATA、FC 和 NVMe 接口的简要摘要。您需要检查当前接口和支持的带宽是什么，因为当开发和采用新规范时，它们会随着时间的推移而变化。

# SCSI
小型计算机系统接口最初是一种并行传输总线，使用多个电气连接器并行传输位。第一个版本是 1986 年的 SCSI-1，其数据总线宽度为 8 位，允许每个时钟传输一个字节，并提供 5 MB/s 的带宽。这是使用 50 针 Centronics C50 连接的。后来的并行 SCSI 版本使用更宽的数据总线和更多的连接器引脚，多达 80 个引脚，带宽为数百兆字节

由于并行 SCSI 是共享总线，因此它可能会因总线争用而出现性能问题，例如，当计划的系统备份使低优先级 I/O 使总线饱和时。解决方法包括将低优先级设备放在它们自己的 SCSI 总线或控制器上。

并行总线的时钟在高速下也成为一个问题，这与其他问题（包括有限的设备和对 SCSI 终结器包的需求）一起，导致切换到串行版本：SAS。

# SAS
串行连接 SCSI 接口设计为高速点对点传输，避免了并行 SCSI 的总线争用问题。最初的 SAS-1 规范为 3 Gbits/s（2003 年发布），随后是支持 6 Gbits/s 的 SAS-2（2009 年）、支持 12 Gbits/s 的 SAS-3（2012 年）和支持 22.5 Gbit/s（2017 年）。支持链路聚合，因此多个端口可以组合以提供更高的带宽。由于 8b/10b 编码，实际数据传输速率为带宽的 80%。

其他 SAS 功能包括用于冗余连接器和架构的驱动器双端口、I/O 多路径、SAS 域、热插拔以及对 SATA 设备的兼容性支持。这些功能使 SAS 在企业中广受欢迎，尤其是在冗余架构中

# SATA
由于与 SCSI 和 SAS 类似的原因，并行 ATA（又名 IDE）接口标准已发展成为串行 ATA 接口。SATA 1.0 创建于 2003 年，支持 1.5 Gbits/s;后来的主要版本是支持 3.0 Gbits/s 的 SATA 2.0 （2004） 和支持 6.0 Gbits/s 的 SATA 3.0 （2008）。主要版本和次要版本中添加了其他功能，包括本机命令排队支持。SATA 使用 8b/10b 编码，因此数据传输速率为带宽的 80%。SATA 已普遍用于消费类台式机和笔记本电脑。

# FC
光纤通道 （FC） 是一种用于数据传输的高速接口标准，最初仅用于光纤电缆（因此得名），后来也支持铜缆。常用 FC在企业环境中创建存储区域网络 （SAN），其中多个存储设备可以通过光纤通道结构连接到多个服务器。这提供了比其他接口更大的可扩展性和可访问性，类似于通过网络连接多个主机。而且，与联网一样，FC 可能涉及使用交换机将多个本地端点（服务器和存储）连接在一起。光纤通道标准的开发始于 1988 年，第一个版本于 1994 年获得 ANSI 批准 [FICA 20]。此后，出现了许多变体和速度改进，最近的第 7 代 256GFC 标准达到了 51,200 MB/s 的全双工 [FICA 18]

# NVMe
Non-Volatile Memory Express （NVMe） 是一种用于存储设备的 PCIe 总线规范。NVMe 设备本身是直接连接到 PCIe 总线的卡，而不是将存储设备连接到存储控制器卡。第一个 NVMe 规范创建于 2011 年，是 1.0e（2013 年发布），最新的是 1.4（2019 年）[NVMe 20]。较新的规范添加了各种功能，例如，热管理功能和用于自检、验证数据和扫描数据（使恢复无法）的命令。NVMe 卡的带宽受 PCIe 总线限制;目前常用的 PCIe 4.0 版对 x16 卡（链路宽度）的单向带宽为 31.5 GB/s。

与传统的 SAS 和 SATA 相比，NVMe 的一个优势是它支持多个硬件队列。这些队列可以从同一个 CPU 使用，以促进缓存热度（并且通过 Linux 多队列支持，还可以避免共享内核锁）。这些队列还允许更大的缓冲，每个队列最多支持 64000 个命令，而典型的 SAS 和 SATA 分别限制为 256 和 32 个命令

NVMe 还支持 SR-IOV 以提高虚拟机存储性能（请参见第 11 章 云计算， 第 11.2 节 硬件虚拟化）。

NVMe 用于低延迟闪存设备，预期 I/O 延迟小于 20 微秒。

# #9.4.3 存储类型
可以通过多种方式向服务器提供存储;以下部分介绍了四种常规体系结构：磁盘设备、RAID、存储阵列和网络连接存储 （NAS）。

# 磁盘设备
最简单的架构是带有内部磁盘的服务器，由操作系统单独控制。磁盘连接到磁盘控制器，该控制器是主板或扩展卡上的电路，允许查看和访问磁盘设备。在此体系结构中，磁盘控制器仅充当管道，以便系统可以与磁盘通信。典型的个人计算机或笔记本电脑以这种方式连接了一个磁盘，用于主存储。

此体系结构最容易使用性能工具进行分析，因为每个磁盘都为操作系统所知，并且可以单独观察。

一些磁盘控制器支持这种架构，它简称为一堆磁盘 （JBOD）。

# RAID
高级磁盘控制器可以为磁盘设备提供独立磁盘冗余阵列 （RAID） 架构（最初是廉价磁盘的冗余阵列 [Patterson 88]）。RAID 可以将多个磁盘呈现为单个大、快速且可靠的虚拟磁盘。这些控制器通常包括一个板载高速缓存 （RAM），以提高读写性能

通过磁盘控制器卡提供 RAID 称为硬件 RAID。RAID 也可以通过操作系统软件实现，但硬件 RAID 是首选，因为可以在专用硬件上更快地执行 CPU 昂贵的校验和奇偶校验计算，而且此类硬件可以包括电池备份单元 （BBU） 以提高弹性。然而，处理器的进步已经产生了具有剩余周期和内核的 CPU，从而减少了卸载奇偶校验计算的需要。许多存储解决方案已移回软件 RAID（例如，使用 ZFS），这降低了复杂性和硬件成本，并提高了操作系统的可观察性。在发生重大故障的情况下，软件 RAID 也可能比硬件 RAID 更容易修复（想象一下 RAID 卡死了）

以下各节介绍了 RAID 的性能特征。经常使用术语 stripe ：这是指将数据分组为跨多个驱动器写入的块（例如在它们之间绘制条带）。

# 类型
提供各种 RAID 类型，以满足对容量、性能和可靠性的不同需求。本摘要侧重于表 9.3 中所示的性能特征。

虽然 RAID-0 条带化性能最佳，但它没有冗余，因此对于大多数生产用途来说不切实际。可能的例外情况包括不存储关键数据且将自动替换故障实例的容错云计算环境，以及仅用于缓存的存储服务器。

# 可观察性
如前面有关虚拟磁盘利用率的部分所述，使用硬件提供的虚拟磁盘设备可能会使操作系统中的可观测性更加困难，因为操作系统不知道物理磁盘在做什么。如果 RAID 是通过软件提供的，则通常可以观察到单个磁盘设备，因为操作系统直接管理它们。

# 读取-修改-写入
当数据存储为包含奇偶校验的条带时（与 RAID-5 一样），写入 I/O 可能会产生额外的读取 I/O 和计算时间。这是因为小于条带大小的写入可能需要读取整个条带、修改字节、重新计算奇偶校验，然后重写条带。可以使用 RAID-5 的优化来避免这种情况：不读取整个条带，而是只读取条带（条带）中包括修改后的数据以及奇偶校验的部分。通过一系列 XOR作，可以计算更新的奇偶校验，并将其与修改后的条带一起写入。

跨整个条带的写入可以写入以前的内容，而无需先读取它们。通过平衡条带的大小与写入的平均 I/O 大小，可以减少额外的读取开销，从而提高此环境中的性能。

# 缓存
实现 RAID-5 的磁盘控制器可以通过使用回写高速缓存来降低读-写-修改性能。这些缓存必须由电池供电，以便在发生电源故障时它们仍然可以完成缓冲写入

# 附加功能
请注意，高级磁盘控制器卡可以提供可能影响性能的高级功能。浏览供应商文档是个好主意，这样您至少可以了解可能起作用的内容。例如，以下是 Dell PERC 5 卡 [Dell 20] 的几个功能：

■ Patrol read：每隔几天读取一次所有磁盘块并验证其校验和。如果磁盘忙于处理请求，则提供给巡逻读取功能的资源将减少，以避免与系统工作负载竞争。
■ 缓存刷新间隔：将缓存中的脏数据刷新到磁盘之间的时间（以秒为单位）。由于写入取消和更好的聚合写入，更长的时间可能会减少磁盘 I/O;但是，在较大的 flush 期间，它们也可能导致更高的读取延迟。

这两者都会对性能产生重大影响

# 存储阵列
存储阵列允许将许多磁盘连接到系统。它们使用高级磁盘控制器，以便可以配置 RAID，并且通常提供大缓存 （GB） 来提高读取和写入性能。这些缓存通常也是电池供电的，允许它们在回写模式下运行。一个常见的策略是在 bat 失败时切换到 write-through 模式，这可能会被注意到是由于等待 read-modify-write 周期而导致写入性能突然下降。

另一个性能考虑因素是存储阵列如何连接到系统 — 通常通过外部存储控制器卡。该卡及其与存储阵列之间的传输都将受到 IOPS 和吞吐量的限制。为了提高性能和可靠性，存储阵列通常是双连接的，这意味着它们可以使用两根物理电缆连接到一个或两个不同的存储控制器卡。

# 网络连接存储
NAS 通过网络协议（如 NFS、SMB/CIFS 或 iSCSI）通过现有网络提供给系统，通常来自称为 NAS 设备的专用系统。这些是 Sepa 比率系统，应该这样分析。可以在客户端上进行一些性能分析，以检查应用的工作负载和 I/O 延迟。网络性能也成为一个因素，网络拥塞和多跳延迟可能会引起问题

# #9.4.4 操作系统磁盘I/O栈
磁盘 I/O 堆栈中的组件和层将取决于所使用的操作系统、版本以及软件和硬件技术。图 9.7 描述了一个通用模型。请参见第 3 章 “操作系统”，了解包含应用程序的类似模型

# 块设备接口
块设备接口是在早期的 Unix 中创建的，用于以 512 字节的块为单位访问存储设备，并提供缓冲区缓存以提高性能。该接口存在于 Linux 中，但随着其他文件系统高速缓存的引入，缓冲区高速缓存的作用已经减弱，如第 8 章 “文件系统”中所述。

Unix 提供了一个绕过缓冲区缓存的路径，称为原始块设备 I/O（或只是原始 I/O），可以通过字符特殊设备文件使用（参见第 3 章操作系统）。默认情况下，这些文件在 Linux 中不再常见。原始块设备 I/O 与第 8 章 “文件系统”中描述的“直接 I/O”文件系统功能不同，但在某些方面相似。

块 I/O 接口通常可以从操作系统性能工具 （iostat（1）） 中观察到。它也是静态检测的常见位置，最近也可以使用动态检测进行探索。Linux 通过附加功能增强了内核的这一区域

# Linux
Linux 块 I/O 堆栈的主要组件如图 9.8 所示。

Linux 通过添加用于提高性能的 I/O 合并和 I/O 调度程序、用于对多个设备进行分组的卷管理器以及用于创建虚拟设备的设备映射器，增强了块 I/O

# I/O 合并
创建 I/O 请求时，Linux 可以合并和合并它们，如图 9.9 所示。

这将对 I/O 进行分组，从而减少内核存储堆栈中每 I/O CPU 开销和磁盘上的开销，从而提高吞吐量。这些前端和后端合并的统计数据可以在 iostat（1） 中找到。

合并后，将安排 I/O 传送到磁盘。

# I/O 调度器
I/O 在块层中由经典调度器（仅存在于 5.0 之前的 Linux 版本中）或较新的多队列调度器进行排队和调度。这些调度程序允许对 I/O 进行重新排序（或重新调度）以实现最佳交付。这可以提高并更公平地平衡性能，特别是对于具有高 I/O 延迟的设备（旋转磁盘）

经典调度器包括：
■ Noop：这不执行调度（noop 是 CPU-talk 表示无作），当认为调度开销不必要时（例如，在 RAM 磁盘中）可以使用。
■ Deadline：尝试强制执行延迟 Deadline;例如，可以选择以毫秒为单位的读取和写入到期时间。这对于需要确定性的实时系统非常有用。它还可以解决匮乏问题：当新发出的 I/O 跳转队列时，I/O 请求会耗尽磁盘资源，从而导致延迟异常值。匮乏可能是由于写入匮乏读取，以及电梯寻道和对磁盘的一个区域进行繁重的 I/O 对另一个区域的 I/O 匮乏的结果。deadline 调度器部分通过使用三个单独的 I/O 队列来解决这个问题：读取 FIFO、写入 FIFO 和排序 [Love 10]。
■ CFQ：完全公平的排队调度程序将 I/O 时间片分配给进程，类似于 CPU 调度，以实现磁盘资源的公平使用。它还允许通过 ionice（1） 命令为用户进程设置优先级和类。

经典计划程序的一个问题是它们使用单个请求队列，由单个锁保护，这在高 I/O 速率下成为性能瓶颈。多队列驱动程序（blk-mq，在 Linux 3.13 中添加）通过为每个 CPU 使用单独的提交队列和为设备使用多个调度队列来解决此问题。与传统计划程序相比，这为 I/O 提供了更好的性能和更低的延迟，因为请求可以并行处理，并且可以在启动 I/O 的同一 CPU 上处理。这对于支持基于闪存的器件类型和其他能够处理数百万 IOPS 的设备类型是必要的 [Corbet 13b]。

多队列调度器包括： 
■ 无：无排队。
■ BFQ：预算公平排队调度器，类似于 CFQ，但分配带宽和 I/O 时间。它为每个执行磁盘 I/O 的进程创建一个队列，并为每个队列维护一个以扇区为单位的预算。还有一个系统范围的预算超时，以防止一个进程保持设备太长时间。BFQ 支持 cgroups。
■ mq-deadline：deadline 的 blk-mq 版本（如前所述）。
■ Kyber：一种调度程序，可根据性能调整读取和写入调度队列长度，以便满足目标读取或写入延迟。它是一个简单的调度程序，只有两个可调参数：目标读取延迟 （read_lat_nsec） 和目标同步写入延迟 （write_lat_nsec）。Kyber 在 Netflix 云中显示出改进的存储 I/O 延迟，默认情况下使用它。

从 Linux 5.0 开始，多队列调度器是默认的（经典调度器不再包含在内）

I/O 调度器详细记录在 Linux 源代码的 Documentation/block 下。

在 I/O 调度之后，请求将放置在块设备队列中，以便向设备发出

# 9.5 方法论
本节介绍用于磁盘 I/O 分析和调整的各种方法和练习。表 9.4 总结了这些主题。

参见第 2 章 方法，了解更多方法和其中许多方法的介绍

这些方法可以单独遵循或组合使用。在调查磁盘问题时，我的建议是按以下顺序使用以下策略：USE 方法、性能监控、工作负载特征、延迟分析、微基准测试、静态分析和事件跟踪

第 9.6 节 可观测性工具介绍了用于应用这些方法的操作系统工具。

# #9.5.1 工具方法
工具方法是迭代可用工具的过程，检查它们提供的关键指标。虽然方法很简单，但它可能会忽略工具提供较差或没有可见性的问题，并且执行起来可能很耗时。

对于磁盘，工具方法可能涉及检查以下内容（对于 Linux）：

■ iostat：使用扩展模式查找繁忙的磁盘（利用率超过 60%）、平均服务时间高（超过 10 毫秒）和高 IOPS（取决于）
■ iotop/biotop：确定哪个进程导致磁盘 I/O 生物延迟：以直方图的形式检查 I/O 延迟的分布，查找多模态分布和延迟异常值（超过， 比如 100 毫秒）
■ biosnoop：检查单个 I/O 
■ perf（1）/BCC/bpftrace：用于自定义分析，包括查看发出 I/O 磁盘控制器特定工具的用户和内核堆栈（来自供应商）

如果发现问题，请检查可用工具中的所有字段以了解更多上下文。有关每个工具的更多信息，请参见部分 9.6， 可观测性工具 。也可以使用其他方法，这些方法可以识别更多类型的问题

# #9.5.2 USE方法
USE 方法用于在性能调查的早期识别所有组件的瓶颈和错误。以下各节描述了如何将 USE 方法应用于磁盘设备和控制器，而第 9.6 节 可观测性工具则介绍了用于测量特定指标的工具。

磁盘设备 对于每个磁盘设备，请检查： 
■ 利用率：设备繁忙的时间 
■ 饱和度：I/O 在队列中等待的程度 
■ 错误：设备错误

可以先检查错误。它们有时会被忽视，因为尽管存在磁盘故障，系统仍能正常运行（尽管运行速度较慢）：磁盘通常配置在冗余磁盘池中，旨在容忍某些故障。除了操作系统中的标准磁盘错误计数器外，磁盘设备可能支持更多种类的错误计数器，这些计数器可以通过特殊工具（例如 SMART data）进行检索。

如果磁盘设备是物理磁盘，则利用率应该很容易找到。如果它们是虚拟磁盘，则利用率可能无法反映基础物理磁盘的运行情况。有关此内容的更多讨论，请参见 第 9.3.9 节 利用率 。

# 磁盘控制器
对于每个磁盘控制器，请检查： 
■ 利用率：当前与最大吞吐量之比，运行速率也是如此 
■ 饱和度：由于控制器饱和而等待 I/O 的程度 
■ 错误：控制器错误

这里的利用率指标不是根据时间定义的，而是根据磁盘控制器卡的限制来定义的：吞吐量（每秒字节数）和操作速率（每秒作数）。操作包括读/写和其他磁盘命令。吞吐量或操作速率也可能受到将磁盘控制器连接到系统的传输的限制，就像它也可能受到从控制器到单个磁盘的传输的限制一样。每个传输都应该以相同的方式检查：错误、利用率、饱和度

您可能会发现可观测性工具（例如 Linux iostat（1））不提供每个控制器的 ric，而只提供每个磁盘的 ric。有一些解决方法：如果系统只有一个控制器，您可以通过对所有磁盘的这些指标求和来确定控制器 IOPS 和吞吐量。如果系统具有多个控制器，则需要确定哪些磁盘属于哪个磁盘，并相应地对指标求和

磁盘控制器和传输的性能经常被忽视。幸运的是，它们不是系统瓶颈的常见来源，因为它们的容量通常超过附加磁盘的容量。如果总磁盘吞吐量或 IOPS 始终以一定的速率趋于平稳，即使在不同的工作负载下也是如此，这可能是磁盘控制器或传输工具实际导致问题的线索。

# #9.5.3 性能监控
性能监控可以识别一段时间内的活动问题和行为模式。磁盘 I/O 的关键指标是： 

■ 磁盘利用率 
■ 响应时间

磁盘利用率持续数秒为 100% 很可能是一个问题。根据您的环境，超过 60% 也可能会因排队增加而导致性能不佳。“normal” 或 “bad” 的值取决于您的工作负载、环境和延迟要求。如果您不确定，可以执行已知好工作负载与坏工作负载的微基准测试，以展示如何通过磁盘指标找到这些工作负载。请参见部分 9.8， 实验

应按磁盘检查这些指标，以查找不平衡的工作负载和单个性能不佳的磁盘。响应时间指标可以作为每秒平均值进行监控，并且可以包括其他值，例如最大值和标准偏差。理想情况下，可以检查响应时间的完整分布，例如使用直方图或热图，以查找延迟异常值和其他模式

如果系统实施磁盘 I/O 资源控制，则还可以收集统计信息，以显示是否以及何时使用这些控制。磁盘 I/O 可能是由于施加的限制而造成的瓶颈，而不是磁盘本身的活动。

利用率和响应时间显示磁盘性能的结果。可以添加更多指标来描述工作负载的特征，包括 IOPS 和吞吐量，从而提供用于容量规划的重要数据（请参阅下一部分和部分 9.5.10 扩展）

# #9.5.4 工作负载特征描述
描述应用的负载是容量规划、基准测试和模拟工作负载的一项重要练习。它还可以通过识别可以消除的不必要工作来带来一些最大的性能提升

以下是描述磁盘 I/O 工作负载的基本属性：
■ I/O 速率 
■ I/O 吞吐量 
■ I/O 大小 
■ 读/写比率 
■ 随机与顺序

随机与顺序、读/写比率和 I/O 大小在部分 9.3， 概念中描述。I/O 速率 （IOPS） 和 I/O 吞吐量在部分 9.1， 术语中定义。

这些特性可能每秒钟都不同，尤其是对于每隔一段时间缓冲和刷新写入的应用程序和文件系统。为了更好地描述工作负载，请捕获最大值和平均值。更好的是，检查值随时间推移的完整分布。

下面是一个示例工作负载描述，用于说明如何一起表示这些属性：

系统磁盘具有轻量级随机读取工作负载，平均 350 IOPS，吞吐量为 3 MB/s，以 96% 的读取速度运行。偶尔会出现短暂的顺序写入突增，持续 2 到 5 秒，将磁盘驱动到 4,800 IOPS 和 560 MB/s 的最大速度。读取大小约为 8 KB，写入大小约为 128 KB。

除了在系统范围内描述这些特征外，它们还可用于描述每个磁盘和每个控制器的 I/O 工作负载。

# 高级工作负载特征描述/核对表
可能包含其他详细信息来描述工作负载的特征。这些问题已在此处列为需要考虑的问题，在彻底研究磁盘问题时，也可以作为检查清单

■ 系统范围的 IOPS 速率是多少？每个磁盘？每个控制器？
■ 系统范围的吞吐量是多少？每个磁盘？每个控制器？
■ 哪些应用程序或用户正在使用磁盘？
■ 正在访问哪些文件系统或文件？
■ 是否遇到任何错误？它们是由于无效的请求还是磁盘上的问题造成的？
■ 可用磁盘的 I/O 平衡程度如何？
■ 涉及的每条传输总线的 IOPS 是多少？
■ 涉及的每条传输总线的吞吐量是多少？
■ 将发出哪些非数据传输磁盘命令？
■ 为什么会发出磁盘 I/O （内核调用路径）？
■ 磁盘 I/O 应用程序同步的程度如何？
■ I/O 到达时间的分布情况如何？

IOPS 和吞吐量问题可以分别针对读取和写入提出。也可以随时间检查其中任何一个，以查找最大值、最小值和基于时间的变化。另请参阅第 2 章 方法， 第 2.5.11 节 工作负载特征，其中提供了要测量的特征（谁、为什么、什么、如何）的更高级别摘要

# 性能表征
前面的工作负载特征列表检查应用的工作负载。下面检查了结果性能：

■ 每个磁盘的繁忙程度 （利用率） ？
■ 每个磁盘的 I/O 饱和度如何（等待排队）？
■ 平均 I/O 服务时间是多少？
■ 平均 I/O 等待时间是多少？
■ 是否存在延迟较高的 I/O 异常值？
■ I/O 延迟的完整分布是什么？
■ 系统资源控制（如 I/O 限制）是否存在并处于活动状态？
■ 非数据传输磁盘命令的延迟是多少？

# 事件跟踪
跟踪工具可用于将所有文件系统作和详细信息记录到日志中，以供以后分析（例如，第 9.6.7 节，biosnoop）。这可能包括磁盘设备 ID、I/O 或命令类型、偏移量、大小、提交和完成时间戳、完成状态以及原始进程 ID 和名称（如果可能）。使用 issue 和 completion 时间戳，可以计算 I/O 延迟（也可以直接包含在日志中）。通过研究请求和完成时间戳的顺序，还可以识别设备的 I/O 重新排序。虽然这可能是工作负载特征描述的终极工具，但在实践中，捕获和保存可能会花费相当大的开销，具体取决于磁盘作的速率。如果跟踪中包含事件跟踪的磁盘写入，则不仅可能会污染跟踪，还会造成反馈循环和性能问题。

# #9.5.5 延迟分析
延迟分析涉及更深入地钻取系统以查找延迟的来源。对于磁盘，这通常在磁盘接口处结束：I/O 请求和完成之间的时间。如果这与应用程序级别的 I/O 延迟匹配，则通常可以安全地假设 I/O 延迟源自磁盘，从而允许您将调查重点放在磁盘上。如果延迟不同，则在操作系统堆栈的不同级别测量延迟将识别来源。

图 9.10 描绘了一个通用的 I/O 堆栈，其中延迟显示在两个 I/O 异常值 A 和 B 的不同级别。

I/O A 的延迟在从应用程序到磁盘驱动程序的每个级别都是相似的。这种关联表明磁盘（或磁盘驱动程序）是延迟的原因。如果这些层是根据它们之间相似的延迟值独立测量的，则可以推断出这一点。

B 的延迟似乎源自文件系统级别（锁定还是排队），较低级别的 I/O 延迟占用的时间要少得多。请注意，堆栈的不同层可能会使 I/O 膨胀或收缩，这意味着大小、计数和延迟会因层而异。示例 B 可能是在较低级别（10 毫秒）仅观察到一个 I/O 的情况，但未能考虑为同一文件系统 I/O 提供服务而发生的其他相关 I/O（例如，元数据）。

每个级别的延迟可以表示为：
■ 每个间隔的 I/O 平均值： 通常由操作系统工具报告。
■ 完整的 I/O 分布：作为直方图或热图;请参见部分 9.7.3， 
■ 延迟热图。每 I/O 延迟值：请参阅前面的事件跟踪部分。

最后两个选项对于跟踪离群值的来源很有用，并且可以帮助识别 I/O 被拆分或合并的情况。

# #9.5.6 静态性能调优
静态性能优化侧重于已配置环境的问题。对于磁盘性能，请检查静态配置的以下方面：

■ 存在多少个磁盘？哪些类型（例如 SMR、MLC）？大小？
■ 磁盘固件是什么版本？
■ 存在多少个磁盘控制器？哪些接口类型？
■ 磁盘控制器卡是否连接到高速插槽？
■ 每个 HBA 连接了多少个磁盘？
■ 如果存在磁盘 / 控制器电池备份，它们的功率水平是多少？
■ 磁盘控制器固件是什么版本？
■ RAID 是否已配置？包括条带宽度在内的具体情况如何？
■ 多路径是否可用并已配置？
■ 磁盘设备驱动程序是什么版本？
■ 服务器主内存大小是多少？是否有页面和缓冲区缓存使用？
■ 是否有任何存储设备驱动程序的操作系统错误/补丁？
■ 是否有用于磁盘 I/O 的资源控制？

请注意，设备驱动程序和固件中可能存在性能错误，理想情况下，供应商的更新可以修复这些错误。回答这些问题可以揭示被忽视的配置选择。有时，系统已针对一个工作负载进行了配置，然后又针对另一个工作负载重新调整了用途。该策略将重新审视这些选择。

在担任 Sun 的 ZFS 存储产品的性能主管时，我收到的最常见的性能投诉是由错误配置引起的：使用了半个 JBOD（12 个磁盘）的 RAID-Z2（宽条带）。这种配置提供了良好的可靠性，但性能并不令人印象深刻，类似于单个磁盘。我学会了先询问配置详细信息（通常通过电话），然后再花时间登录系统并检查 I/O 延迟。

# #9.5.7 缓存调优
系统中可能存在许多不同的缓存，包括应用程序级缓存、文件系统缓存、磁盘控制器缓存和磁盘本身缓存。部分 9.3.3， 缓存中包括了这些列表，可以按照第 2 章 方法， 部分 2.5.18 缓存调整中所述进行调整。总之，检查哪些缓存存在，检查它们是否正常工作，检查它们运行情况如何，然后调整缓存的工作负载并调整工作负载的缓存

# #9.5.8 资源控制
操作系统可以提供用于将磁盘 I/O 资源分配给进程或进程组的控件。这些可能包括 IOPS 和吞吐量的固定限制，或更灵活的方法的份额。这些工作如何特定于实现，如部分 9.9， 调整中所述

# #9.5.9 微基准测试
第 8 章 “文件系统”中介绍了磁盘 I/O 的微基准测试，其中解释了测试文件系统 I/O 和测试磁盘 I/O 之间的区别。在这里，我们想要测试磁盘 I/O，这通常意味着通过操作系统的设备路径进行测试，特别是原始设备路径（如果可用），以避免所有文件系统行为（包括缓存、缓冲、I/O 拆分、I/O 合并、代码路径开销和偏移映射差异）。

微基准测试的因素包括：
■ 方向：读取或写入 
■ 磁盘偏移模式：随机或顺序 
■ 偏移量范围：全盘或小范围（例如，仅偏移量 0） 
■ I/O 大小：512 字节（典型最小值）最多 1 MB 
■ 并发：正在进行的 I/O 数量，或执行 I/O 的线程数量 
■ 设备数量： 单磁盘测试或多磁盘（探索控制器和总线限制）

接下来的两节将介绍如何组合这些因素来测试磁盘和磁盘控制器性能。有关可用于执行这些测试的特定工具的详细信息，请参见部分 9.8 实验。

# 磁盘
可以按磁盘执行微基准测试，以确定以下内容以及建议的工作负载

■ 最大磁盘吞吐量（MB/秒）：128 KB 或 1 MB 读取，顺序 
■ 最大磁盘运行速率 （IOPS）：512 字节读取，偏移量 0 
■ 最大磁盘随机读取 （IOPS）：512 字节读取，随机偏移量 
■ 读取延迟配置文件（平均微秒）：顺序读取，重复 512 字节、1K、2K、4K 等 ■ 随机 I/O 延迟配置文件（平均微秒）： 512 字节读取，对整个偏移量范围重复，仅开始偏移量，仅结束偏移量

可以对写入重复这些测试。使用 “offset 0 only” 是为了将数据缓存在磁盘上的缓存中，以便测量缓存访问时间。

# 磁盘控制器
磁盘控制器可以通过将工作负载应用于多个磁盘来进行微基准测试，旨在达到控制器中的限制。可以使用以下内容以及建议的磁盘工作负载来执行这些测试：

■ 最大控制器吞吐量（MB/秒）：128 KB，仅偏移量 0
■ 最大控制器运行速率 （IOPS）：512 字节读取，仅偏移量 0

将工作负载逐个应用于磁盘，并观察限制。可能需要十几个磁盘才能在磁盘控制器中找到限制。

# #9.5.10 缩放
磁盘和磁盘控制器具有吞吐量和 IOPS 限制，这可以通过前面所述的微基准测试来演示。优化只能将性能提高到这些限制。如果需要更高的磁盘性能，而其他策略（如缓存）不起作用，则磁盘将需要扩展。

下面是一个基于资源容量规划的简单方法：

1. 根据吞吐量和 IOPS 确定目标磁盘工作负载。如果这是一个新系统，请参见第 2 章 方法， 第 2.7 节 容量规划。如果系统已有工作负载，请根据当前磁盘吞吐量和 IOPS 表示用户群体，并将这些数字扩展到目标用户群体。（如果缓存未同时扩展，则磁盘工作负载可能会增加，因为每个用户的缓存比率会变小。
2. 计算支持此工作负载所需的磁盘数。考虑 RAID 配置。请勿使用每个磁盘的最大吞吐量和 IOPS 值，因为这会导致以 100% 的利用率驱动磁盘，由于饱和和排队而导致立即出现性能问题。选择一个目标利用率（比如 50%）并相应地缩放值。
3. 计算支持此工作负载所需的磁盘控制器数量。
4. 检查是否未超过运输限制，并在必要时调整运输规模。
5. 计算每个磁盘 I/O 的 CPU 周期数和所需的 CPU 数量（这可能需要多个 CPU 和并行 I/O）。

使用的最大每个磁盘吞吐量和 IOPS 数字将取决于其类型和磁盘类型。请参见第 9.3.7 节 IOPS 不相等。可以使用微基准测试来查找给定 I/O 大小和 I/O 类型的特定限制，并且可以对现有工作负载使用工作负载特征来查看哪些大小和类型很重要。

为了满足磁盘工作负载要求，需要数十个磁盘并通过存储阵列连接的服务器并不少见。我们过去常说，“添加更多主轴”。我们现在可以说，“添加更多 flash”。

# 9.6 观测工具
本节介绍适用于基于 Linux 的操作系统的磁盘 I/O 可观测性工具。有关使用它们时要遵循的策略，请参阅上一节。

Table 9.5 中列出了本节中的工具

这是支持 Section 9.5， 方法论 的一系列工具，从传统工具和统计开始，然后是跟踪工具，最后是磁盘控制器统计。一些传统工具可能在它们起源的其他类 Unix操作系统上可用，包括：iostat（8） 和 sar（1）。许多跟踪工具都是基于 BPF 的，并使用 BCC 和 bpftrace 前端（第 15 章）;它们是：Biolatency（8）、Biosnoop（8）、Biotop（8） 和 BioStacks（8）。

有关其功能的完整参考，请参阅每个工具的文档，包括其手册页。

# #9.6.1 iostat
iostat（1） 汇总了每个磁盘的 I/O 统计数据，提供了工作负载特征、利用率和饱和度的指标。它可以由任何用户执行，并且通常是在命令行中用于调查磁盘 I/O 问题的第一个命令。它提供的统计信息通常也由监控软件显示，因此值得详细学习 iostat（1） 以加深对监控统计信息的理解。默认情况下，这些统计信息由内核启用，因此此工具的开销可以忽略不计。

名称“iostat”是“I/O statistics”的缩写，尽管将其称为“diskiostat”以反映它报告的 I/O 类型可能更好。当用户知道应用程序正在执行 I/O（对文件系统）但想知道为什么无法通过 iostat（1）（磁盘）看到它时，这会导致偶尔的混淆。

iostat（1） 是 1980 年代初为 Unix 编写的，在不同的操作系统上有不同的版本。它可以通过 sysstat 软件包添加到基于 Linux 的系统中。Linux 版本说明如下。

# iostat 默认输出
在没有任何参数或选项的情况下，将打印 CPU 和磁盘统计信息的 summary-since-boot。这里介绍的是这个工具;但是，您不需要使用此模式，因为稍后介绍的扩展模式更有用。

# $ iostat
 Linux 5.3.0-1010-aws (ip-10-1-239-218)    02/12/20        _x86_64_  (2 CPU)
 avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.29    0.01    0.18    0.03    0.21   99.28
 Device             
tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
 loop0             0.00         0.05         0.00       1232          0
 [...]
 nvme0n1           3.40        17.11        36.03     409902     863344

第一行输出是系统的摘要，包括内核版本、主机名、日期、体系结构和 CPU 计数。随后的几行显示 CPU（avg-cpu;这些统计信息在第 6 章 “CPU”和磁盘设备（在 Device：下）中介绍的 summary-since-boot 统计信息。

每个磁盘设备都显示为一行，各列中包含基本详细信息。我以粗体突出显示了 column 标题;他们是：

■ tps：每秒事务数 （IOPS）
■ kB_read/s，kB_wrtn/s：每秒读取和每秒写入的千字节 
■ kB_read，kB_wrtn：读取和写入的总千字节数

某些 SCSI 设备，包括 CD-ROM，可能不被 iostat（1） 显示。可以使用 tapestat（1） 来检查 SCSI 磁带驱动器，也可以在 sysstat 软件包中检查。还要注意，虽然 iostat（1） 报告块设备读取和写入，但它可能会根据内核排除一些其他类型的磁盘设备命令（参见内核函数 blk_do_io_stat（）） 中的逻辑）。iostat（1） 扩展模式包含这些设备命令的额外字段。

# iostat 选项
iostat（1） 可以使用各种选项执行，后跟可选的 interval 和 count。例如：

 # iostat 1 10

将打印 10 次 1 次 1 秒的摘要。和
 # iostat 1

将无休止地打印一秒钟的摘要（直到键入 Ctrl-C）

常用的选项是：
■ -c： 显示 CPU 报告
■ -d： 显示磁盘报告
■ -k：使用千字节而不是（512 字节）块
■ -m：使用兆字节而不是（512 字节）块
■ -p：包括每个分区的统计信息
■ -t：时间戳输出
■ -x：扩展统计
■ -s：短（窄）输出
■ -z：跳过显示零活动摘要

还有一个环境变量 POSIXLY_CORRECT=1，用于输出块（每个 512 字节）而不是 KB。一些旧版本包括 NFS 统计信息选项 -n。从 sysstat 版本 9.1.3 开始，这已移至单独的 nfsiostat 命令。

# iostat 扩展简短输出
扩展输出 （-x） 提供了额外的列，这些列对于早期涵盖的方法非常有用。这些额外的列包括用于工作负载特征描述的 IOPS 和吞吐量指标USE 方法的利用率和队列长度，以及用于性能特征描述和延迟分析的磁盘响应时间。

多年来，扩展输出获得了越来越多的字段，最新版本（12.3.1,2019 年 12 月）生成的输出宽度为 197 个字符。这不仅不适合本书，也不适合许多宽终端，由于换行，输出难以阅读。2017 年添加了一种解决方案，即 -s 选项，用于提供适合 80 个字符宽度的“短”或窄输出。

以下是简短 （-s） 扩展 （-x） 统计信息和跳过零活动设备 （-z） 的示例

# $ iostat -sxz 1
 [...]
 avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          15.82    0.00   10.71   31.63    1.53   40.31
 Device             
tps      kB/s    rqm/s   await aqu-sz  areq-sz  %util
 nvme0n1        1642.00   9064.00   664.00    0.44   0.00     5.52 100.00
 [...]

磁盘列是：
■ tps：每秒发出的事务数 （IOPS） 
■ kB/s：每秒千字节数 
■ rqm/s：每秒排队和合并的请求 
■ await：平均 I/O 响应时间，包括在操作系统中排队的时间和设备的 I/O 响应时间 （ms） 
■ aqu-sz：在驱动程序请求队列中等待并在设备上处于活动状态的平均请求数 
■ areq-sz： 平均请求大小 （KB） 
■ %util：设备忙于处理 I/O 请求的时间百分比（利用率）

交付性能的最重要指标是 await，它显示 I/O 的平均总等待时间。什么构成“好”或“坏”取决于您的需求。在示例输出中，await 为 0.44 毫秒，这对于此数据库服务器来说是令人满意的。它可能由于多种原因而增加：排队 （负载）、更大的 I/O 大小、旋转设备上的随机 I/O 以及设备错误。

对于资源使用和容量规划，%util 很重要，但请记住，它只是繁忙程度（非空闲时间）的度量，对于由多个磁盘支持的虚拟设备来说可能意义不大。通过应用的负载可以更好地理解这些设备：tps （IOPS） 和 kB/s （吞吐量）。

rqm/s 列中的非零计数表示连续请求在传送到设备之前已合并，以提高性能。此指标也是连续工作负载的标志。

由于 areq-sz 是在合并之后，因此小大小（8 KB 或更小）表示无法合并的随机 I/O 工作负载。大型可能是大型 I/O 或合并的顺序工作负载（如前面的列所示）

# iostat 扩展输出
如果没有 -s 选项，-x 将打印更多列。以下是 sysstat 版本 12.3.2（从 2020 年 4 月起）自启动（无 inter val 或 count）以来的摘要：

# $ iostat -x
 [...]
 Device            
r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   
wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     
f/s f_await  aqu-sz  %util
 nvme0n1          0.23      9.91     0.16  40.70    0.56    43.01    3.10     33.09     
0.92  22.91    0.89    10.66    0.00      0.00     0.00   0.00    0.00     0.00    
0.00    0.00    0.00   0.12

这些指标将许多 -sx 指标分解为读取和写入组件，还包括丢弃和刷新。

额外的列是： 
■ r/s、w/s、d/s、f/s：每秒从磁盘设备完成的读取、写入、丢弃和刷新请求（合并后） 
■ rkB/s、wkB/s、dkB/s：每秒从磁盘设备读取、写入和丢弃 KB 
■ %rrqm/s、%wrqm/s、%drqm/s：读取、 写入和丢弃排队和合并的请求数占该类型请求总数的百分比 
■ r_await、w_await、d_await f_await：读取、写入、丢弃和刷新平均响应时间，包括操作系统中排队的时间和来自设备的响应时间 （ms） 
■ rareq-sz、wareq-sz、dareq-sz：读取、写入和丢弃平均大小 （KB）

分别检查读取和写入非常重要。应用程序和文件系统通常使用技术来缓解写入延迟（例如，回写缓存），因此应用程序不太可能在磁盘写入时被阻止。这意味着对读取和写入进行分组的任何指标都会被可能并不直接相关的组件（写入）所扭曲。通过拆分它们，您可以开始检查r_wait，它显示平均读取延迟，并且可能是应用程序性能的最重要指标。

IOPS （r/s、w/s） 和吞吐量（rkB/s、wkB/s）的读取和写入对于工作负载特征描述非常重要。

discard 和 flush 统计信息是 iostat（1） 的新增功能。丢弃操作会释放驱动器上的块（ATA TRIM 命令），并且它们的统计信息已添加到 Linux 4.19 内核中。在 Linux 5.5 中添加了 flush 统计信息。这些可以帮助缩小磁盘延迟的原因。

这是另一个有用的 iostat（1） 组合

# $ iostat -dmstxz -p ALL 1
 Linux 5.3.0-1010-aws (ip-10-1-239-218)    02/12/20        _x86_64_  (2 CPU)
  02/12/20 17:39:29
 Device             tps      MB/s    rqm/s   await  areq-sz  aqu-sz  %util
 nvme0n1           3.33      0.04     1.09    0.87    12.84    0.00   0.12
 nvme0n1p1         3.31      0.04     1.09    0.87    12.91    0.00   0.12
 02/12/20 17:39:30
 Device             tps      MB/s    rqm/s   await  areq-sz  aqu-sz  %util
 nvme0n1        1730.00     14.97   709.00    0.54     8.86    0.02  99.60
 nvme0n1p1      1538.00     14.97   709.00    0.61     9.97    0.02  99.60
 [...]

第一个输出是自启动以来的摘要，后跟 1 秒的间隔。-d 仅关注磁盘统计信息（无 CPU），-m 用于 MB，-t 用于时间戳，这在将输出与其他带时间戳的源进行比较时非常有用，而 -p ALL 包括每个分区的统计信息。

不幸的是，当前版本的 iostat（1） 不包含磁盘错误;否则，所有 USE 方法指标都可以从一个工具中检查！

# #9.6.2 sar
系统活动报告器 sar（1） 可用于观察当前活动，并且可以配置为存档和报告历史统计信息。它在 Section 4.4 sar 中介绍，并在本书的其他各个章节中提到了它提供的不同统计数据。

sar（1） 磁盘摘要使用 -d 选项打印，以下示例中演示了 1 秒的间隔。输出很宽，因此这里分为两部分 （sysstat 12.3.2）：


# $ sar -d 1
 Linux 5.3.0-1010-aws (ip-10-0-239-218)    02/13/20        _x86_64_  (2 CPU)
 09:10:22          DEV       tps     rkB/s     wkB/s     dkB/s   areq-sz \ ...
 09:10:23     dev259-0   1509.00  11100.00  12776.00      0.00     15.82 / ...
 [...]

以下是其余列：

# $ sar -d 1
 09:10:22     \ ... \  aqu-sz     await     %util
 09:10:23     / ... /    0.02      0.60     94.00
 [...]

这些列也出现在 iostat（1） -x 输出中，在上一节中进行了介绍。此输出显示混合读/写工作负载，等待时间为 0.6 毫秒，将磁盘利用率驱动到 94%。

以前版本的 sar（1） 包括一个 svctm （service time） 列：平均（推断的）磁盘响应时间，以毫秒为单位。有关服务时间的背景信息，请参见部分 9.3.1 测量时间。由于其简单的计算对于并行执行 I/O 的现代磁盘不再准确，因此在更高版本中已删除 svctm。

# 9.6.3 PSI
Linux 4.20 中添加的 Linux 压力失速信息 （PSI） 包括 I/O 饱和度的统计信息。这些指标不仅显示是否存在 I/O 压力，还显示过去 5 分钟内压力的变化情况。输出示例：

 # cat /proc/pressure/io
 some avg10=63.11 avg60=32.18 avg300=8.62 total=667212021
 full avg10=60.76 avg60=31.13 avg300=8.35 total=622722632

此输出显示 I/O 压力正在增加，10 秒平均值 （63.11） 高于 300 秒平均值 （8.62）。这些平均值是任务 I/O 停止的时间百分比。some 行显示某些任务（线程）何时受到影响，而 full 行显示所有可运行任务何时受到影响。

与负载平均值一样，这可以是用于警报的高级指标。一旦你意识到存在磁盘性能问题，你可以使用其他工具来查找根本原因，包括 pidstat（8） 按进程统计磁盘

# #9.6.4 pidstat
Linux 中的 pidstat（1） 工具默认打印 CPU 使用率，并包含一个用于磁盘 I/O 统计的 -d 选项。这在内核 2.6.20 及更高版本上可用。例如：

# $ pidstat -d 1
 Linux 5.3.0-1010-aws (ip-10-0-239-218)    02/13/20        _x86_64_  (2 CPU)
 09:47:41      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
 09:47:42        0      2705  32468.00      0.00      0.00       5  tar
 09:47:42        0      2706      0.00   8192.00      0.00       0  gzip
 [...]
 09:47:56      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
 09:47:57        0       229      0.00     72.00      0.00       0  systemd-journal
 09:47:57        0       380      0.00      4.00      0.00       0  auditd
 09:47:57        0      2699      4.00      0.00      0.00      10  kworker/
 u4:1-flush-259:0
 09:47:57        0      2705  15104.00      0.00      0.00       0  tar
 09:47:57        0      2706      0.00   6912.00      0.00       0  gzip

列包括： 
■ kB_rd/s：每秒读取的千字节数 
■ kB_wd/s：每秒写入发出的千字节数 
■ kB_ccwr/s：每秒写入取消的千字节数（例如，在刷新之前被覆盖或删除） 
■ iodelay：进程在磁盘 I/O 上被阻塞的时间（时钟滴答），包括交换

输出中看到的工作负载是将文件系统读取到管道的 tar 命令，以及读取管道并写入压缩存档文件的 gzip 命令。tar 读取导致 iodelay（5 clock ticks），而 gzip 写入没有，因为页面缓存中有回写缓存。一段时间后，页面缓存被刷新，从 kworker/u4：1-flush-259：0 进程输出的第二个间隔中可以看出，该进程遇到了 iodelay

iodelay 是最近添加的，它显示了性能问题的严重性：应用程序等待了多少时间。其他列显示应用的工作负载。

请注意，只有超级用户 （root） 才能访问他们不拥有的进程的磁盘统计信息。这些通过 /proc/PID/io 读取。

# #9.6.5 perf
Linux perf（1） 工具（第 13 章）可以记录块跟踪点。列出它们

 # perf list 'block:*'
 List of pre-defined events (to be used in -e):
  block:block_bio_backmerge                          [Tracepoint event]
  block:block_bio_bounce                             [Tracepoint event]
  block:block_bio_complete                           [Tracepoint event]
  block:block_bio_frontmerge                         [Tracepoint event]
  block:block_bio_queue                              [Tracepoint event]
  block:block_bio_remap                              [Tracepoint event]
  block:block_dirty_buffer                           [Tracepoint event]
  block:block_getrq                                  [Tracepoint event]
  block:block_plug                                   [Tracepoint event]
  block:block_rq_complete                            [Tracepoint event]
  block:block_rq_insert                              [Tracepoint event]
  block:block_rq_issue                               [Tracepoint event]
  block:block_rq_remap                               [Tracepoint event]
  block:block_rq_requeue                             [Tracepoint event]
  block:block_sleeprq                                [Tracepoint event]
  block:block_split                                  [Tracepoint event]
  block:block_touch_buffer                           [Tracepoint event]
  block:block_unplug                                 [Tracepoint event]

例如，以下记录通过堆栈跟踪阻止设备问题。sleep 10 命令作为跟踪的持续时间提供。

# perf record -e block:block_rq_issue -a -g sleep 10
 [ perf record: Woken up 22 times to write data ]
 [ perf record: Captured and wrote 5.701 MB perf.data (19267 samples) ]
 # perf script --header
 [...]
 mysqld  1965 [001] 160501.158573: block:block_rq_issue: 259,0 WS 12288 () 10329704 + 
24 [mysqld]
        ffffffffb12d5040 blk_mq_start_request+0xa0 ([kernel.kallsyms])
        ffffffffb12d5040 blk_mq_start_request+0xa0 ([kernel.kallsyms])
        ffffffffb1532b4c nvme_queue_rq+0x16c ([kernel.kallsyms])
        ffffffffb12d7b46 __blk_mq_try_issue_directly+0x116 ([kernel.kallsyms])
        ffffffffb12d87bb blk_mq_request_issue_directly+0x4b ([kernel.kallsyms])
        ffffffffb12d8896 blk_mq_try_issue_list_directly+0x46 ([kernel.kallsyms])
        ffffffffb12dce7e blk_mq_sched_insert_requests+0xae ([kernel.kallsyms])
        ffffffffb12d86c8 blk_mq_flush_plug_list+0x1e8 ([kernel.kallsyms])
        ffffffffb12cd623 blk_flush_plug_list+0xe3 ([kernel.kallsyms])
        ffffffffb12cd676 blk_finish_plug+0x26 ([kernel.kallsyms])
        ffffffffb119771c ext4_writepages+0x77c ([kernel.kallsyms])
        ffffffffb10209c3 do_writepages+0x43 ([kernel.kallsyms])
        ffffffffb1017ed5 __filemap_fdatawrite_range+0xd5 ([kernel.kallsyms])
        ffffffffb10186ca file_write_and_wait_range+0x5a ([kernel.kallsyms])
        ffffffffb118637f ext4_sync_file+0x8f ([kernel.kallsyms])
        ffffffffb1105869 vfs_fsync_range+0x49 ([kernel.kallsyms])
        ffffffffb11058fd do_fsync+0x3d ([kernel.kallsyms])
        ffffffffb1105944 __x64_sys_fsync+0x14 ([kernel.kallsyms])
        ffffffffb0e044ca do_syscall_64+0x5a ([kernel.kallsyms])
        ffffffffb1a0008c entry_SYSCALL_64_after_hwframe+0x44 ([kernel.kallsyms])
            7f2285d1988b fsync+0x3b (/usr/lib/x86_64-linux-gnu/libpthread-2.30.so)
            55ac10a05ebe Fil_shard::redo_space_flush+0x44e (/usr/sbin/mysqld)
            55ac10a06179 Fil_shard::flush_file_redo+0x99 (/usr/sbin/mysqld)
            55ac1076ff1c [unknown] (/usr/sbin/mysqld)
            55ac10777030 log_flusher+0x520 (/usr/sbin/mysqld)
            55ac10748d61 
std::thread::_State_impl<std::thread::_Invoker<std::tuple<Runnable, void (*)(log_t*), 
log_t*> > >::_M_run+0xc1 (/usr/sbin/mysql
            7f228559df74 [unknown] (/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.28)
            7f226c3652c0 [unknown] ([unknown])
            55ac107499f0 
std::thread::_State_impl<std::thread::_Invoker<std::tuple<Runnable, void (*)(log_t*), 
log_t*> > >::~_State_impl+0x0 (/usr/sbin/
        5441554156415741 [unknown] ([unknown])
 [...]

输出是每个事件的单行摘要，后跟导致该事件的堆栈跟踪。单行摘要以 perf（1） 中的默认字段开头：进程名称、线程 ID、CPU ID、时间戳和事件名称（参见第 13 章 perf， Section 13.11 perf 脚本）。其余字段特定于跟踪点：对于此 block：block_rq_issue 跟踪点，它们与字段内容一起：

■ 磁盘主次序号：259,0 
■ I/O 类型：WS（同步写入） 
■ I/O 大小：12288（字节） 
■ I/O 命令字符串：（） 
■ 扇区地址：10329704 
■ 扇区数：24 
■ 进程：mysqld

这些字段来自跟踪点的格式字符串（请参见第 4 章 可观测性工具， 第 4.3.5 节 跟踪点的跟踪点参数和格式字符串）

堆栈跟踪可以帮助解释磁盘 I/O 的性质。在本例中，它来自调用 fsync（2） 的 mysqld log_flusher（） 例程。内核代码路径显示它由 ext4 文件系统处理，并通过 blk_mq_try_issue_list_directly（） 成为磁盘 I/O 提交。

通常 I/O 会排队，然后由内核线程发出，跟踪 block：block_ rq_issue 跟踪点不会显示原始进程或用户级堆栈跟踪。在这些情况下，你可以尝试跟踪 block：block_rq_insert，它用于队列插入。请注意，它错过了未排队的 I/O。

# 单行
以下单行代码演示了如何对块跟踪点使用筛选器。

跟踪所有大小至少为 100 KB 的块完成，直到 Ctrl-C10：

# perf record -e block:block_rq_complete --filter 'nr_sector > 200'

跟踪所有块完成，仅同步写入，直到 Ctrl-C：
# perf record -e block:block_rq_complete --filter 'rwbs == "WS"

跟踪所有块完成，所有类型的写入，直到 Ctrl-C：
# perf record -e block:block_rq_complete --filter 'rwbs ~ "*W*"'

# 磁盘 I/O 延迟
磁盘 I/O 延迟（前面称为磁盘请求时间）也可以通过记录磁盘提交和完成事件来确定，以供以后分析。下面记录它们 60 秒，然后将事件写入 out.disk01.txt 文件：

# perf record -e block:block_rq_issue,block:block_rq_complete -a sleep 60
# perf script --header > out.disk01.txt

你可以使用任何方便的东西对输出文件进行后处理：awk（1）、Perl、Python、R、Google Spreadsheets 等。将提交与完成相关联，并使用记录的时间戳来计算延迟。

以下工具 biolatency（8） 和 biosnoop（8） 使用 BPF 程序有效地计算内核空间中的磁盘 I/O 延迟，并将延迟直接包含在输出中。

# #9.6.6 biolatency
biolatency（8）是一个 BCC 和 bpftrace 工具，用于以直方图的形式显示磁盘 I/O 延迟。此处使用的术语 I/O 延迟是指从向设备发出请求到请求完成（又名磁盘请求时间）的时间。

下面显示了来自 BCC 跟踪块 I/O 的 biolatency（8） 10 秒

 # biolatency 10 1
 Tracing block device I/O... Hit Ctrl-C to end.
     usecs               : count     distribution
         0 -> 1          : 0        |                                        |
         2 -> 3          : 0        |                                        |
         4 -> 7          : 0        |                                        |
         8 -> 15         : 0        |                                        |
        16 -> 31         : 2        |                                        |
        32 -> 63         : 0        |                                        |
        64 -> 127        : 0        |                                        |
       128 -> 255        : 1065     |*****************                       |
       256 -> 511        : 2462     |****************************************|
       512 -> 1023       : 1949     |*******************************         |
      1024 -> 2047       : 373      |******                                  |
      2048 -> 4095       : 1815     |*****************************           |
      4096 -> 8191       : 591      |*********                               |
      8192 -> 16383      : 397      |******                                  |
     16384 -> 32767      : 50       |                                        |


此输出显示双峰分布，一种模式在 128 到 1023 微秒之间，另一种模式在 2048 到 4095 微秒（2.0 到 4.1 毫秒）之间。现在我知道设备延迟是双峰的，了解原因可能会导致调整将更多 I/O 移动到更快的模式。例如，较慢的 I/O 可以是随机 I/O 或较大尺寸的 I/O （可以使用其他 BPF 工具确定）或不同的 I/O 标志（使用 -F 选项显示）。此输出中最慢的 I/O 达到 16 到 32 毫秒的范围：这听起来像在设备上排队。

BCC 版本的 biolatency（8） 支持的选项包括

■ -m：以毫秒为单位输出
■ -Q：包括操作系统排队的I/O时间（OS请求时间）
■ -F：显示每个I/O标志的直方图set
■ -D：显示每个磁盘设备的直方图

使用 -Q 会使 biolatency（8） 报告从在内核队列中创建和插入到设备完成的完整 I/O 时间，前面描述为块 I/O 请求时间

BCC biolatency（8） 也接受可选的 interval 和 count 参数（以秒为单位）。

# Per-Flag
-F 选项特别有用，它可以分解每个 I/O 标志的分布。例如，使用 -m 表示毫秒直方图

 # biolatency -Fm 10 1
 Tracing block device I/O... Hit Ctrl-C to end.
 flags = Sync-Write
     msecs               : count     distribution
         0 -> 1          : 2        |****************************************|
 flags = Flush
     msecs               : count     distribution
         0 -> 1          : 1        |****************************************|
 flags = Write
     msecs               : count     distribution
         0 -> 1          : 14       |****************************************|
         2 -> 3          : 1        |**                                      |
         4 -> 7          : 10       |****************************            |
         8 -> 15         : 11       |*******************************         |
        16 -> 31         : 11       |*******************************         |
 flags = NoMerge-Write
     msecs               : count     distribution
         0 -> 1          : 95       |**********                              |
         2 -> 3          : 152      |*****************                       |
         4 -> 7          : 266      |******************************          |
         8 -> 15         : 350      |****************************************|
        16 -> 31         : 298      |**********************************      |
 flags = Read
     msecs               : count     distribution
         0 -> 1          : 11       |****************************************|
 flags = ReadAhead-Read
     msecs               : count     distribution
         0 -> 1          : 5261     |****************************************|
         2 -> 3          : 1238     |*********                               |
         4 -> 7          : 481      |***                                     |
         8 -> 15         : 5        |                                        |
        16 -> 31         : 2        |                                        |

存储设备可能会以不同的方式处理这些标志;将它们分开使我们能够孤立地研究它们。前面的输出显示写入比读取慢，并且可以解释早期的双峰分布。

biolatency（8） 总结了磁盘 I/O 延迟。要检查每个 I/O 的 I/O，请使用 biosnoop（8）。

# #9.6.7 biosnoop
biosnoop（8）是一个 BCC 和 bpftrace 工具，可以为每个磁盘 I/O 打印一行摘要。例如

 # biosnoop
 TIME(s)        COMM           PID    DISK    T  SECTOR    BYTES   LAT(ms)
 0.009165000    jbd2/nvme0n1p1 174    nvme0n1 W  2116272   8192       0.43
 0.009612000    jbd2/nvme0n1p1 174    nvme0n1 W  2116288   4096       0.39
 0.011836000    mysqld         1948   nvme0n1 W  10434672  4096       0.45
 0.012363000    jbd2/nvme0n1p1 174    nvme0n1 W  2116296   8192       0.49
 0.012844000    jbd2/nvme0n1p1 174    nvme0n1 W  2116312   4096       0.43
 0.016809000    mysqld         1948   nvme0n1 W  10227712  262144     1.82
 0.017184000    mysqld         1948   nvme0n1 W  10228224  262144     2.19
 0.017679000    mysqld         1948   nvme0n1 W  10228736  262144     2.68
 0.018056000    mysqld         1948   nvme0n1 W  10229248  262144     3.05
 0.018264000    mysqld         1948   nvme0n1 W  10229760  262144     3.25
 0.018657000    mysqld         1948   nvme0n1 W  10230272  262144     3.64
 0.018954000    mysqld         1948   nvme0n1 W  10230784  262144     3.93
 0.019053000    mysqld         1948   nvme0n1 W  10231296  131072     4.03
 0.019731000    jbd2/nvme0n1p1 174    nvme0n1 W  2116320   8192       0.49
 0.020243000    jbd2/nvme0n1p1 174    nvme0n1 W  2116336   4096       0.46
 0.020593000    mysqld         1948   nvme0n1 R  4495352   4096       0.26
 [...]

此输出显示了对磁盘 nvme0n1 的写入工作负载，主要来自 mysqld，PID 174，具有不同的 I/O 大小。这些列是

■ TIME：I/O 完成时间（以秒为单位） 
■ COMM：进程名称（如果此工具知道） 
■ PID：进程 ID（如果此工具知道） 
■ DISK：存储设备名称 
■ T：类型：R == 读取，W == 写入 
■ SECTOR：磁盘上的地址，以 512 字节扇区为单位 
■ BYTES：I/O 请求的大小 
■ LAT（ms）： 从设备发出到设备完成的 I/O 持续时间（磁盘请求时间）

示例输出的中间是一系列 262144 字节的写入，从 1.82 毫秒的延迟开始，到每个后续 I/O 的延迟增加，以 4.03 毫秒结束。这是我经常看到的一种模式，可能的原因可以从输出中的另一列 TIME（s） 计算出来。如果从 TIME（s） 列中减去 LAT（ms） 列，则得到 I/O 的开始时间，并且这些时间大约在同一时间开始。这似乎是同时发送的一组写入，在设备上排队，然后依次完成，每个写入的延迟都会增加。

通过仔细检查开始和结束时间，还可以识别设备上的重新排序。由于输出可以有数千行，我经常使用 R 统计软件将输出绘制为散点图，以帮助识别这些模式（参见第 9.7 节 可视化）。

# 离群值分析
这是一种使用 biosnoop（8） 查找和分析延迟异常值的方法。

1. 将输出写入文件：

# biosnoop > out.biosnoop01.txt

2. 按 latency 列对输出进行排序，并打印最后五个条目（延迟时间最长的条目）：

# sort -n -k 8,8 out.biosnoop01.txt | tail -5
 31.344175   logger         10994  nvme0n1 W 15218056   262144   30.92
 31.344401   logger         10994  nvme0n1 W 15217544   262144   31.15
 31.344757   logger         10994  nvme0n1 W 15219080   262144   31.49
 31.345260   logger         10994  nvme0n1 W 15218568   262144   32.00
 46.059274   logger         10994  nvme0n1 W 15198896   4096     64.86

3. 在文本编辑器（例如 vi（1） 或 vim（1）中打开输出：

 # vi out.biosnoop01.txt

4. 从最慢到最快处理离群值，在第一列中搜索时间。最慢的是 64.86 毫秒，完成时间为 46.059274（秒）。搜索 46.059274：

[...]
 45.992419   jbd2/nvme0n1p1 174    nvme0n1 W 2107232    8192      0.45
 45.992988   jbd2/nvme0n1p1 174    nvme0n1 W 2107248    4096      0.50
 46.059274   logger         10994  nvme0n1 W 15198896   4096     64.86
 [...]

5. 查看在异常值之前发生的事件，看看它们是否具有相似的延迟，因此这是排队的结果（类似于第一个 biosnoop（8） 示例输出中看到的 1.82 到 4.03 毫秒的斜坡），或者任何其他线索。这里的情况并非如此：前一个事件大约早了 6 毫秒，延迟为 0.5 毫秒。设备可能已对事件重新排序并首先完成其他事件。如果上一个完成事件大约在 64 毫秒前，那么设备完成次数的差距可以用其他因素来解释：例如，这个系统是一个 VM 实例，可以在 I/O 期间由超级面罩取消调度，从而将该时间添加到 I/O 时间中。

# 排队时间
BCC biosnoop（8） 的 -Q 选项可用于显示从创建 I/O 到设备提交所花费的时间（以前称为块 I/O 等待时间或操作系统等待时间）。此时间主要花在 OS 队列上，但也可能包括内存分配和锁获取。例如

# biosnoop -Q
 TIME(s)     COMM           PID    DISK    T SECTOR     BYTES  QUE(ms) LAT(ms)
 0.000000    kworker/u4:0   9491   nvme0n1 W 5726504    4096      0.06    0.60
 0.000039    kworker/u4:0   9491   nvme0n1 W 8128536    4096      0.05    0.64
 0.000084    kworker/u4:0   9491   nvme0n1 W 8128584    4096      0.05    0.68
 0.000138    kworker/u4:0   9491   nvme0n1 W 8128632    4096      0.05    0.74
 0.000231    kworker/u4:0   9491   nvme0n1 W 8128664    4096      0.05    0.83
 [...]

排队时间显示在 QUE（ms） 列中。

# #9.6.8 iotop, biotop
我在 2005 年为基于 Solaris 的系统 [McDougall 06a] 编写了第一个 iotop。现在有很多版本，包括一个基于内核会计统计的 Linux iotop（1） 工具13 [Chazarain 13]，以及我自己的基于 BPF 的 biotop（8）

# iotop
iotop 通常可以通过 iotop 包进行安装。当在没有参数的情况下运行时，它每秒刷新一次屏幕，显示排名靠前的磁盘 I/O 进程。批处理模式 （-b） 可用于提供滚动输出（不清除屏幕）;此处演示了仅 I/O 进程 （-o） 和 5 秒的间隔 （-d5）

 # iotop -bod5
 Total DISK READ:       4.78 K/s | Total DISK WRITE:      15.04 M/s
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN      IO    COMMAND
 22400 be/4 root        4.78 K/s    0.00 B/s  0.00 % 13.76 % [flush-252:0]
  279 be/3 root        0.00 B/s 1657.27 K/s  0.00 %  9.25 % [jbd2/vda2-8]
 22446 be/4 root        0.00 B/s   10.16 M/s  0.00 %  0.00 % beam.smp -K true ...
 Total DISK READ:       0.00 B/s | Total DISK WRITE:      10.75 M/s
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN      IO    COMMAND
  279 be/3 root        0.00 B/s    9.55 M/s  0.00 %  0.01 % [jbd2/vda2-8]
 22446 be/4 root        0.00 B/s   10.37 M/s  0.00 %  0.00 % beam.smp -K true ...
  646 be/4 root        0.00 B/s  272.71 B/s  0.00 %  0.00 % rsyslogd -n -c 5
 [...]

输出显示 beam.smp 进程 （Riak） 执行大约 10 MB/s 的磁盘写入工作负载。这些列包括： 
■ DISK READ：读取 KB/s 
■ DISK WRITE：写入 KB/s 
■ SWAPIN：线程等待换入 I/O 
■ IO：线程等待 I/O 所花费的时间百分比

iotop（8） 支持各种其他选项，包括 -a 用于累积统计信息（而不是每个间隔），-p PID 匹配进程，以及 -d SEC 设置间隔。

我建议您使用已知的工作负载测试 iotop（8） 并检查数字是否匹配。我刚刚尝试了（iotop 版本 0.6），发现它大大低估了写入工作负载。你也可以使用 biotop（8），它使用不同的 instrumentation 源，并且确实与我的测试工作负载相匹配。

# biotop
biotop（8） 是一个 BCC 工具，也是另一个用于磁盘的 top（1）。示例输出

 # biotop
 Tracing... Output every 1 secs. Hit Ctrl-C to end
 08:04:11 loadavg: 1.48 0.87 0.45 1/287 14547
 PID    COMM             D MAJ MIN DISK       I/O  Kbytes  AVGms
 14501  cksum            R 202 1   xvda1      361   28832   3.39
 6961   dd               R 202 1   xvda1     1628   13024   0.59
 13855  dd               R 202 1   xvda1     1627   13016   0.59
 326    jbd2/xvda1-8     W 202 1   xvda1        3     168   3.00
 1880   supervise        W 202 1   xvda1        2       8   6.71
 1873   supervise        W 202 1   xvda1        2       8   2.51
 1871   supervise        W 202 1   xvda1        2       8   1.57
 1876   supervise        W 202 1   xvda1        2       8   1.22
 [...]

这显示了执行读取的 cksum（1） 和 dd（1） 命令，以及监督执行某些写入的进程。这是确定谁在执行磁盘 I/O 以及执行多少的快速方法。这些列是

■ PID：缓存的进程 ID（尽力而为） 
■ COMM：缓存的进程名称（尽力而为） 
■ D：方向（R == 读取，W == 写入） 
■ MAJ MIN：磁盘主编号和次编号（内核标识符） 
■ 磁盘：磁盘名称 
■ I/O：间隔期间的磁盘 I/O 数量 
■ KB：间隔期间的磁盘总吞吐量（KB ） 
■ AVGms： 从提交到设备到完成的平均 I/O 时间（延迟）（毫秒）

当磁盘 I/O 被发送到设备时，请求进程可能不再位于 CPU 上，并且可能很难识别它。biotop（8） 使用尽力而为的方法： PID 和 COMM 色谱柱通常会匹配正确的工艺，但这并不能保证。

biotop（8） 支持可选的 interval 和 count 列（默认间隔为 1 秒），-C 不清屏，-r MAXROWS 指定要显示的进程数。

# #9.6.9 biostacks
biostacks（8）14 是一个 bpftrace 工具，它使用 I/O 初始化堆栈跟踪来跟踪块 I/O 请求时间（从操作系统排队到设备完成）。例如：

 # biostacks.bt
 Attaching 5 probes...
 Tracing block I/O with init stacks. Hit Ctrl-C to end.
 ^C
 [...]
  @usecs[
    blk_account_io_start+1
    blk_mq_make_request+1069
    generic_make_request+292
    submit_bio+115
    submit_bh_wbc+384
    ll_rw_block+173
    ext4_bread+102
    __ext4_read_dirblock+52
    ext4_dx_find_entry+145
    ext4_find_entry+365
    ext4_lookup+129
    lookup_slow+171
    walk_component+451
    path_lookupat+132
    filename_lookup+182
    user_path_at_empty+54
    sys_access+175
    do_syscall_64+115
    entry_SYSCALL_64_after_hwframe+61
 ]: 
 [2K, 4K)               2 |@@                                                  |
 [4K, 8K)              37 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
 [8K, 16K)             15 |@@@@@@@@@@@@@@@@@@@@@                               |
 [16K, 32K)             9 |@@@@@@@@@@@@                                        |
 [32K, 64K)             1 |@                                                   |

输出显示磁盘 I/O 的延迟直方图（以微秒为单位）以及请求的 I/O 堆栈：通过 access（2） syscall、filename_lookup（） 和 ext4_lookup（）。此 I/O 是由于在文件权限检查期间查找路径名引起的。输出包括许多这样的堆栈，这些堆栈表明 I/O 是由读取和写入以外的活动引起的。

我见过存在神秘磁盘 I/O 但没有任何应用程序导致它的情况。原因原来是后台文件系统任务。（在一个案例中，它是 ZFS 的后台清理程序，它会定期验证校验和。biostacks（8） 可以通过显示内核堆栈跟踪来识别磁盘 I/O 的真正原因

# #9.6.10 blktrace
blktrace（8） 是 Linux 上使用内核 blktrace tracer 的块设备 I/O 事件的自定义跟踪工具。这是一个专门的跟踪器，通过 BLKTRACE ioctl（2） 系统调用对磁盘设备文件进行控制。前端工具包括 blktrace（8）、blkparse（1） 和 btrace（8）

blktrace（8） 启用内核块驱动程序跟踪并检索原始跟踪数据，这些数据可以使用 blkparse（1） 进行处理。为方便起见，btrace（8） 工具同时运行 blktrace（8） 和 blkparse（1），因此以下内容是等效的：

 # blktrace -d /dev/sda -o - | blkparse -i 
 # btrace /dev/sda

blktrace（8） 是一个低级工具，每个 I/O 显示多个事件。

# 默认输出
下面显示了 btrace（8） 的默认输出，并通过 cksum（1） 命令捕获单个磁盘读取事件：

 # btrace /dev/sdb
  8,16   3        1     0.429604145 20442  A   R 184773879 + 8 <- (8,17) 184773816
  8,16   3        2     0.429604569 20442  Q   R 184773879 + 8 [cksum]
  8,16   3        3     0.429606014 20442  G   R 184773879 + 8 [cksum]
  8,16   3        4     0.429607624 20442  P   N [cksum]
  8,16   3        5     0.429608804 20442  I   R 184773879 + 8 [cksum]
  8,16   3        6     0.429610501 20442  U   N [cksum] 1
  8,16   3        7     0.429611912 20442  D   R 184773879 + 8 [cksum]
  8,16   1        1     0.440227144     0  C   R 184773879 + 8 [0]
 [...]

对于这个单个磁盘 I/O，报告了 8 行输出，显示了涉及块存储设备队列和设备的每个作（事件）。

默认情况下，有七列： 
1. 设备主，次编号 
2. CPU ID 
3. 序号 
4. 操作时间，以秒为单位 
5. 进程 ID 
6. 操作标识符：事件的类型（请参阅作标识符 标题） 
7. RWBS 描述：I/O 标志（请参阅“RWBS 描述”标题）

可以使用 -f 选项自定义这些输出列。它们后面跟着基于作的自定义数据。

最终数据取决于操作。例如，184773879 8 [cksum] 表示位于大小为 8（扇区）的块地址 184773879 的 I/O，来自名为 cksum 的进程

# 操作标识符
这些在 blkparse（1） 手册页中进行了介绍：

1. A IO 已重新映射到其他设备
2. B IO 退回 
3. C IO 完成 
4. D 向驱动程序发出的 IO
5. F IO 前端与队列上的请求合并
6. G 获取请求
7. I IO 插入请求队列 
8. M IO 与队列上的请求合并
9. P 插头请求
10. Q 由请求队列代码处理的 IO 
11. S 睡眠请求 
12. T 因超时而拔下
13. U 拔掉请求
14. X 拆分

之所以包含此列表，是因为它还显示了 blktrace 框架可以观察到的事件。

# RWBS 说明
为了跟踪可观测性，内核提供了一种使用名为 rwbs 的 character 字符串来描述每个 I/O 类型的方法。rwbs 被 blktrace（8） 和其他磁盘跟踪工具使用。它在内核 blk_fill_rwbs（） 函数中定义，并使用以下字符：

■ R：读取 
■ W：写入 
■ M：元数据 
■ S：同步 
■ A：预读 
■ F：刷新或强制访问单元 
■ D：丢弃 
■ E：擦除 
■ N：无

字符可以组合。例如，“WM” 用于元数据的写入

# 操作筛选
blktrace（8） 和 btrace（8） 命令可以过滤作，只显示感兴趣的事件类型。例如，要仅跟踪 D操作（发出 I/O），请使用过滤器选项 -a issue

 # btrace -a issue /dev/sdb
  8,16   1        1     0.000000000   448  D   W 38978223 + 8 [kjournald]
  8,16   1        2     0.000306181   448  D   W 104685503 + 24 [kjournald]
  8,16   1        3     0.000496706   448  D   W 104685527 + 8 [kjournald]
  8,16   1        1     0.010441458 20824  D   R 184944151 + 8 [tar]
 [...]

blktrace（8） 手册页中介绍了其他过滤器，包括仅跟踪读取 （-a read）、写入 （-a write） 或同步作 （-a sync） 的选项。

# 分析
blktrace 软件包包括 btt（1） 来分析 I/O 跟踪。下面是一个示例调用，现在在 /dev/nvme0n1p1 上使用 blktrace（8） 来写入跟踪文件（使用新目录，因为这些命令会创建多个文件）

 # mkdir tracefiles; cd tracefiles
 # blktrace -d /dev/nvme0n1p1 -o out -w 10
 === nvme0n1p1 ===
  CPU  0:                20135 events,      944 KiB data
  CPU  1:                38272 events,     1795 KiB data
  Total:                 58407 events (dropped 0),     2738 KiB data
 # blkparse -i out.blktrace.* -d out.bin
 259,0    1        1     0.000000000  7113  A  RM 161888 + 8 <- (259,1) 159840
 259,0    1        1     0.000000000  7113  A  RM 161888 + 8 <- (259,1) 159840
 [...]
 # btt -i out.bin
 ==================== All Devices ====================
            ALL           MIN           AVG           MAX           N--------------- ------------- ------------- ------------- ----------
 Q2Q               0.000000001   0.000365336   2.186239507       24625
 Q2A               0.000037519   0.000476609   0.001628905        1442
 Q2G               0.000000247   0.000007117   0.006140020       15914
 G2I               0.000001949   0.000027449   0.000081146         602
 Q2M               0.000000139   0.000000198   0.000021066        8720
 I2D               0.000002292   0.000008148   0.000030147         602
 M2D               0.000001333   0.000188409   0.008407029        8720
 D2C               0.000195685   0.000885833   0.006083538       12308
 Q2C               0.000198056   0.000964784   0.009578213       12308
 [...]

这些统计信息以秒为单位，并显示 I/O 处理的每个阶段的时间。有趣的时间包括：

■ Q2C：从 I/O 请求到完成的总时间（块层时间） 
■ D2C：设备提交到完成（磁盘 I/O 延迟） 
■ I2D：从设备队列插入到设备提交的时间（请求队列时间） 
■ M2D：从 I/O 合并到提交的时间

输出显示平均 D2C 时间为 0.86 毫秒，最大 M2D 为 8.4 毫秒。诸如此类的最大值可能会导致 I/O 延迟异常值

有关更多信息，请参阅 btt 用户指南 [Brunelle 08]

# 可视化
blktrace（8） 工具可以将事件记录到跟踪文件中，这些文件可以使用 iowatcher（1） 进行可视化，iowatcher（1） 也包含在 blktrace 包中提供，也可以使用 Chris Mason 的 seekwatcher [Mason 08] 进行可视化。

# #9.6.11 bpftrace
bpftrace 是一种基于 BPF 的跟踪器，它提供了一种高级编程语言，允许创建强大的单行代码和简短脚本。它非常适合根据其他工具的线索进行自定义磁盘分析。

bpftrace 在第 15 章中进行了解释。本节介绍磁盘分析的一些示例：单行代码、磁盘 I/O 大小和磁盘 I/O 延迟。

# 单行
以下单行代码非常有用，并演示了不同的 bpftrace 功能。

对块 I/O 跟踪点事件进行计数：
# bpftrace -e 'tracepoint:block:* { @[probe] = count(); }'

将块 I/O 大小汇总为直方图：
# bpftrace -e 't:block:block_rq_issue { @bytes = hist(args->bytes); }'

对块 I/O 请求用户堆栈跟踪进行计数
# bpftrace -e 't:block:block_rq_issue { @[ustack] = count(); }'
# bpftrace -e 't:block:block_rq_insert { @[ustack] = count(); }'

对块 I/O 类型标志进行计数
# bpftrace -e 't:block:block_rq_issue { @[args->rwbs] = count(); }'

设备和 I/O 类型的跟踪块 I/O 错误：
# bpftrace -e 't:block:block_rq_complete /args->error/ {
    printf("dev %d type %s error %d\n", args->dev, args->rwbs, args->error); }'

对 SCSI操作码进行计数：
# bpftrace -e 't:scsi:scsi_dispatch_cmd_start { @opcode[args->opcode] =
    count(); }'

对 SCSI结果代码进行计数：
#  bpftrace -e 't:scsi:scsi_dispatch_cmd_done { @result[args->result] = count(); }'

计算 SCSI 驱动程序功能
# bpftrace -e 'kprobe:scsi* { @[func] = count(); }'

# 磁盘 I/O 大小
有时磁盘 I/O 速度慢仅仅是因为它很大，尤其是对于 SSD 驱动器。另一个基于大小的问题是，当应用程序请求许多小型 I/O 时，这些 I/O 可以聚合为更大的大小以减少 I/O 堆栈开销。这两个问题都可以通过检查 I/O 大小分布来调查。

使用 bpftrace，下面显示了按请求进程名称细分的磁盘 I/O 大小分布：

# bpftrace -e 't:block:block_rq_issue /args->bytes/ { @[comm] = hist(args->bytes); }'
 Attaching 1 probe...
 ^C
 [...]
 @[kworker/3:1H]: 
 [4K, 8K)               1 |@@@@@@@@@@                                          |
 [8K, 16K)              0 |                                                    |
 [16K, 32K)             0 |                                                    |
 [32K, 64K)             0 |                                                    |
 [64K, 128K)            0 |                                                    |
 [128K, 256K)           0 |                                                    |
 [256K, 512K)           0 |                                                    |
 [512K, 1M)             5 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
 [1M, 2M)               3 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                     |
 @[dmcrypt_write]: 
 [4K, 8K)             103 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
 [8K, 16K)             46 |@@@@@@@@@@@@@@@@@@@@@@@                             |
 [16K, 32K)            11 |@@@@@                                               |
 [32K, 64K)             0 |                                                    |
 [64K, 128K)            1 |                                                    |
 [128K, 256K)           1 |                                                    |
 
输出显示名为 dmcrypt_write 的进程正在执行小型 I/O，主要在 4 到 32 KB 范围内

tracepoint block：block_rq_issue 显示 I/O 何时发送到设备驱动程序以传送到磁盘设备。无法保证发起进程仍在 CPU 上，尤其是在 I/O 由调度程序排队的情况下，因此显示的进程名称可能适用于从队列中读取 I/O 以进行设备交付的后续内核工作线程。你可以将跟踪点切换到 block：block_rq_ insert，以便从队列的插入开始测量，这可能会提高进程名称的准确性，但它也可能错过绕过队列的插桩 I/O（这也在 Section 9.6.5， perf 中提到过）。

如果您将 args->rwbs 添加为直方图键，则输出将按 I/O 类型进一步细分

 # bpftrace -e 't:block:block_rq_insert /args->bytes/ { @[comm, args->rwbs] =
    hist(args->bytes); }'
 Attaching 1 probe...
 ^C
 [...]
 @[dmcrypt_write, WS]: 
 [4K, 8K)               4 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
 [8K, 16K)              1 |@@@@@@@@@@@@@                                       |
 [16K, 32K)             0 |                                                    |
 [32K, 64K)             1 |@@@@@@@@@@@@@                                       |
 [64K, 128K)            1 |@@@@@@@@@@@@@                                       |
 [128K, 256K)           1 |@@@@@@@@@@@@@                                       |
 @[dmcrypt_write, W]: 
 [512K, 1M)             8 |@@@@@@@@@@                                          |
 [1M, 2M)              38 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|

输出现在包括 W （用于写入）、WS （用于同步写入） 等。有关这些字母的解释，请参阅前面的 RWBS 描述 部分

# 磁盘 I/O 延迟
磁盘响应时间（通常称为磁盘 I/O 延迟）可以通过检测设备问题到完成事件来衡量。biolatency.bt 工具执行此作，以直方图的形式显示磁盘 I/O 延迟。例如

 # biolatency.bt
 Attaching 4 probes...
 Tracing block device I/O... Hit Ctrl-C to end.
 ^C
 @usecs: 
 [32, 64)               2 |@                                                   |
 [64, 128)              1 |                                                    |
 [128, 256)             1 |                                                    |
 [256, 512)            27 |@@@@@@@@@@@@@@@@@@@@@@@@@@                          |
 [512, 1K)             43 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@           |
 [1K, 2K)              54 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
 [2K, 4K)              41 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@             |
 [4K, 8K)              47 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@       |
 [8K, 16K)             16 |@@@@@@@@@@@@@@@                                     |
 [16K, 32K)             4 |@@@                                                 |

此输出显示 I/O 通常在 256 微秒到 16 毫秒（16K 微秒）之间完成。源代码是

 #!/usr/local/bin/bpftrace
 BEGIN
 {
        printf("Tracing block device I/O... Hit Ctrl-C to end.\n");
 }
 tracepoint:block:block_rq_issue
 {
        @start[args->dev, args->sector] = nsecs;
 }
 tracepoint:block:block_rq_complete
 /@start[args->dev, args->sector]/
 {
        @usecs = hist((nsecs - @start[args->dev, args->sector]) / 1000);
        delete(@start[args->dev, args->sector]);
 }
 END
 {
      clear(@start);
 }

测量 I/O 延迟需要为每个 I/O 的开始存储一个自定义时间戳，然后在 I/O 完成时引用该时间戳以计算运行时间。在第 8 章 文件系统， 第 8.6.15 节 bpftrace 中测量 VFS 延迟时，开始时间戳存储在以线程 ID 为键的 BPF 映射中：这有效，因为相同的线程 ID 将位于 CPU 上，用于开始和完成事件。磁盘 I/O 不是这种情况，因为 completion 事件将中断 CPU 上的任何其他内容。biolatency.bt 中的唯一 ID 是根据设备和扇区号构建的：它假设一次只有一个 I/O 正在飞往给定扇区

与 I/O 大小单行代码一样，您可以将 args->rwbs 添加到映射键中，以便按 I/O 类型进行细分

# 磁盘 I/O 错误
I/O 错误状态是 block：block_rq_complete 跟踪点的一个参数，下面的 bioerr（8） 工具 用它来打印出错的 I/O作的详细信息（前面包含了单行版本）：

 #!/usr/local/bin/bpftrace
 BEGIN
 {
 }
        printf("Tracing block I/O errors. Hit Ctrl-C to end.\n");
 tracepoint:block:block_rq_complete
 /args->error != 0/
 {
        time("%H:%M:%S ");
        printf("device: %d,%d, sector: %d, bytes: %d, flags: %s, error: %d\n",
            args->dev >> 20, args->dev & ((1 << 20) - 1), args->sector,
            args->nr_sector * 512, args->rwbs, args->error);
 }

查找有关磁盘错误的更多信息可能需要较低级别的磁盘工具，例如接下来的三个工具（MegaCli、smartctl、SCSI 日志记录）。

# #9.6.12 MegaCli
磁盘控制器（主机总线适配器）由系统外部的硬件和固件组成。操作系统分析工具，即使是动态跟踪器，也无法直接观察其内部结构。有时，可以通过仔细观察输入和输出（包括通过内核静态或动态插桩）来推断它们的工作原理，以了解磁盘控制器如何响应一系列 I/O

有一些针对特定磁盘控制器的分析工具，例如 LSI 的 MegaCli。下面显示了最近的控制器事件：

# MegaCli -AdpEventLog -GetLatest 50 -f lsi.log -aALL
# more lsi.log
 seqNum: 0x0000282f
 Time: Sat Jun 16 05:55:05 2012
 Code: 0x00000023
 Class: 0
 Locale: 0x20
 Event Description: Patrol Read complete
 Event Data:
 ===========
 None
 seqNum: 0x000027ec
 Time: Sat Jun 16 03:00:00 2012
 Code: 0x00000027
 Class: 0
 Locale: 0x20
 Event Description: Patrol Read started
 [...]

最后两个事件显示巡逻读取（可能会影响性能）发生在凌晨 3：00 到 5：55 之间。巡查读取在第 9.4.3 节 存储类型中提到;它们读取磁盘块并验证其校验和。

MegaCli 还有许多其他选项，可以显示适配器信息、磁盘设备信息、虚拟设备信息、机箱信息、电池状态和物理错误。这些有助于识别配置和错误问题。即使有这些信息，也无法轻松分析某些类型的问题，例如特定 I/O 花费数百毫秒的确切原因。

查看供应商文档，了解存在哪些接口（如果有）用于磁盘控制器分析。

# #9.6.13 smartctl
磁盘具有控制磁盘作的逻辑，包括排队、缓存和错误处理。与磁盘控制器类似，操作系统无法直接观察磁盘的内部行为，而是通常通过观察 I/O 请求及其延迟来推断

许多现代驱动器提供 SMART（自我监控、分析和报告技术）数据，这些数据提供各种运行状况统计数据。在 Linux 上 smartctl（8） 的以下输出显示了可用的数据类型（这是使用 -d megaraid，0 访问虚拟 RAID 设备中的第一个磁盘）：

 # smartctl --all -d megaraid,0 /dev/sdb
 smartctl 5.40 2010-03-16 r3077 [x86_64-unknown-linux-gnu] (local build)
 Copyright (C) 2002-10 by Bruce Allen, http://smartmontools.sourceforge.net
 Device: SEAGATE  ST3600002SS      Version: ER62
 Serial number: 3SS0LM01
 Device type: disk
 Transport protocol: SAS
 Local Time is: Sun Jun 17 10:11:31 2012 UTC
 Device supports SMART and is Enabled
 Temperature Warning Disabled or Not Supported
 SMART Health Status: OK
 Current Drive Temperature:     23 C
 Drive Trip Temperature:        68 C
 Elements in grown defect list: 0
 Vendor (Seagate) cache information
  Blocks sent to initiator = 3172800756
  Blocks received from initiator = 2618189622
  Blocks read from cache and sent to initiator = 854615302
  Number of read and write commands whose size <= segment size = 30848143
  Number of read and write commands whose size > segment size = 0
 Vendor (Seagate/Hitachi) factory information
  number of hours powered up = 12377.45
  number of minutes until next internal SMART test = 56
 Error counter log:
           Errors Corrected by         Total  Correction   Gigabytes   Total
               ECC        rereads/    errors  algorithm    processed uncorrected
           fast | delayed rewrites  corrected invocations [10^9 bytes] errors
 read:    7416197        0       0   7416197   7416197     1886.494          0
 write:         0        0       0         0         0     1349.999          0
 verify: 142475069        0       0  142475069  142475069   22222.134         0
 Non-medium error count:     2661
 SMART Self-test log
 Num  Test              Status     segment  LifeTime  LBA_first_err [SK ASC ASQ]
     Description                  number   (hours)
 # 1  Background long   Completed      16       3                 - [-   -    -]
 # 2  Background short  Completed      16       0                 - [-   -    -]
 Long (extended) Self Test duration: 6400 seconds [106.7 minutes]

虽然这非常有用，但它没有像内核跟踪框架那样回答有关单个慢速磁盘 I/O 的问题的分辨率。更正的错误信息是有用的用于监控，帮助在磁盘故障发生之前预测磁盘故障，以及确认磁盘是否已发生故障或正在发生故障。

# #9.6.14 SCSI Logging
Linux 具有用于 SCSI 事件日志记录的内置工具。它可以通过 sysctl（8） 或 /proc 来启用。例如，这两个命令都将所有事件类型的日志记录设置为最大值（警告：根据您的磁盘工作负载，这可能会淹没您的系统日志）：

# sysctl -w dev.scsi.logging_level=03333333333
# echo 03333333333 > /proc/sys/dev/scsi/logging_level

数字的格式是一个位域，它将 10 种不同事件类型的日志记录级别设置为 1 到 7（此处以八进制表示;十六进制为 0x1b6db6db）。此位域在 drivers/ scsi/scsi_logging.h 中定义。sg3-utils 软件包提供了一个 scsi_logging_level（8） 工具来设置这些。例如：

 # scsi_logging_level -s --all 3

示例事件：

 # dmesg
 [...]
 [542136.259412] sd 0:0:0:0: tag#0 Send: scmd 0x0000000001fb89dc
 [542136.259422] sd 0:0:0:0: tag#0 CDB: Test Unit Ready 00 00 00 00 00 00
 [542136.261103] sd 0:0:0:0: tag#0 Done: SUCCESS Result: hostbyte=DID_OK 
driverbyte=DRIVER_OK
 [542136.261110] sd 0:0:0:0: tag#0 CDB: Test Unit Ready 00 00 00 00 00 00
 [542136.261115] sd 0:0:0:0: tag#0 Sense Key : Not Ready [current] 
[542136.261121] sd 0:0:0:0: tag#0 Add. Sense: Medium not present
 [542136.261127] sd 0:0:0:0: tag#0 0 sectors total, 0 bytes done.
 [...]

这可用于帮助调试错误和超时。虽然提供了时间戳（第一列），但如果没有唯一的标识详细信息，使用它们来计算 I/O 延迟是很困难的。

# #9.6.15 其他工具
表 9.6 列出了本书其他章节和 BPF 性能工具 [Gregg 19] 中包含的磁盘工具。

其他 Linux 磁盘可观测性工具和来源包括：
■ /proc/diskstats：高级每个磁盘统计信息 
■ seekwatcher：可视化磁盘访问模式 [Mason 08]

磁盘供应商可能具有访问固件统计信息的其他工具，或者通过安装固件的调试版本来访问。

# 9.7 可视化
有许多类型的可视化可以帮助分析磁盘 I/O 性能。本节通过各种工具的屏幕截图来演示这些作。有关可视化的一般讨论，请参见第 2 章 方法， 第 2.10 节 可视化。

# #9.7.1 折线图
性能监控解决方案通常将磁盘 IOPS、吞吐量和利用率测量值随时间变化的图表绘制为折线图。这有助于说明基于时间的模式，例如白天的负载变化，或重复发生的事件，例如文件系统刷新间隔。

请注意绘制的指标。平均延迟可以隐藏多模式分布和异常值。所有磁盘设备的平均值可以隐藏不平衡的行为，包括单个设备的异常值。长期平均值也可以隐藏短期波动。

# #9.7.2 延迟散点图
散点图可用于可视化每个事件的 I/O 延迟，其中可能包括数千个事件。x 轴可以显示完成时间，y 轴 I/O 响应时间（延迟）。图 9.11 中的示例绘制了来自生产 MySQL 数据库服务器的 1,400 个 I/O 事件，使用 iosnoop（8） 捕获并使用 R 绘制。

散点图以不同的方式显示读取 （+） 和写入 （°）。可以绘制其他维度，例如，在 y 轴上绘制磁盘块地址，而不是延迟

此处可以看到几个读取异常值，延迟超过 150 毫秒。这些异常值的原因以前尚不清楚。此散点图以及包含类似异常值的其他散点图显示，它们发生在写入突增之后。写入具有低延迟，因为它们是从 RAID 控制器回写缓存返回的，该缓存将在返回完成后将其写入设备。我怀疑读取在设备写入之后排队。

此散点图显示单个服务器几秒钟。多个服务器或更长的间隔可以捕获更多事件，这些事件在绘制时合并在一起，变得难以阅读。此时，请考虑使用延迟热图

# #9.7.3 延迟热图
热图可用于可视化延迟，将时间流逝放在 x 轴上，将 I/O 延迟放在 y 轴上，将特定时间内的 I/O 数量和延迟放在 z 轴上，以颜色显示（颜色越深表示越多）。热图在第 2 章 方法论， 第 2.10.3 节 热图中介绍。图 9.12 显示了一个有趣的磁盘示例。

可视化的工作负载是实验性的：我逐个对多个磁盘进行顺序读取，以探索总线和控制器的限制。生成的热图是出乎意料的（它被描述为翼手龙），并且显示了当只考虑平均值时会错过的信息。看到的每个细节都有技术原因：例如，“喙”结束于 8 个磁盘，等于连接的 SAS 端口数（2 个 x4 端口），而“头”从这些端口开始遭受争用时从 9 个磁盘开始

我发明了延迟热图来可视化随时间变化的延迟，灵感来自 taztool，如下一节所述。图 9.12 来自 Sun Microsystems ZFS Storage appliance [Gregg 10a] 中的分析：我收集了这个和其他有趣的延迟热图，以公开分享并推广它们的使用。

x 轴和 y 轴与延迟散点图相同。热图的主要优点是它们可以扩展到数百万个事件，而散点图则变成了“绘制”。此问题已在第 2.10.2 节 散点图和 2.10.3 热图中讨论过

# #9.7.4 偏移热图
I/O 位置或偏移量也可以可视化为热图（在计算中早于延迟热图）。图 9.13 显示了一个示例。

磁盘偏移量 （块地址） 显示在 y 轴上，时间显示在 x 轴上。每个像素根据该时间和延迟范围内的 I/O 数量进行着色，对于较大的 I/O 数量，颜色较深。可视化的工作负载是一个文件系统存档，它从块 0 爬过磁盘。较深的线条表示顺序 I/O，较浅的云表示随机 I/O。

此可视化是在 1995 年由 Richard McDougall 通过 taztool 引入的。此屏幕截图来自 DTraceTazTool，这是我在 2006 年编写的版本。磁盘 I/O 偏移热图可从多种工具获得，包括 seekwatcher （Linux）

# #9.7.5 利用率热图
每个设备的利用率也可以显示为热图，以便可以识别设备利用率平衡和单个异常值 [Gregg 11b]。在这种情况下，利用率百分比位于 y 轴上，颜色较暗表示该利用率级别的磁盘越多。此热图类型可用于将单个热磁盘（包括树懒盘）识别为热图顶部的线条 （100%）。有关利用率热图的示例，请参见第 6 章 “CPU”， 部分 6.7.1， 利用率热图

# 9.8 实验
本节介绍用于主动测试磁盘 I/O 性能的工具。请参阅 第 9.5.9 节 微基准测试 ，了解建议遵循的方法。

当使用这些工具时，最好让 iostat（1） 持续运行，这样就可以立即仔细检查任何结果。某些微基准测试工具可能需要 “直接”作模式来绕过文件系统缓存，并专注于磁盘设备性能。

# #9.8.1 临时
dd（1） 命令 （device-to-device copy） 可用于执行顺序磁盘性能的临时测试。例如，使用 1 MB I/O 大小测试顺序读取：

 # dd if=/dev/sda1 of=/dev/null bs=1024k count=1k
 1024+0 records in
 1024+0 records out
 1073741824 bytes (1.1 GB) copied, 7.44024 s, 144 MB/s

由于内核可以缓存和缓冲数据，因此 dd（1） 测得的吞吐量可以是缓存和磁盘的吞吐量，而不仅仅是磁盘的吞吐量。要只测试磁盘的性能，你可以为磁盘使用字符特殊设备：在 Linux 上，raw（8） 命令（如果可用）可以在 /dev/raw 下创建这些。Sequential write 可以类似地进行测试;但是，请注意销毁磁盘上的所有数据，包括主引导记录和分区表

更安全的方法是将直接 I/O 标志用于 dd（1） 和文件系统文件，而不是磁盘设备。请记住，该测试现在包括一些文件系统开销。例如，对名为 out1 的文件执行写入测试：

# dd if=/dev/zero of=out1 bs=1024k count=1000 oflag=direct
 1000+0 records in
 1000+0 records out
 1048576000 bytes (1.0 GB, 1000 MiB) copied, 1.79189 s, 585 MB/s

iostat（1） 确认磁盘 I/O 写入吞吐量约为 585 MB/秒。

使用 iflag=direct 对输入文件进行直接 I/O。

# #9.8.2 自定义负载生成器
要测试自定义工作负载，您可以编写自己的负载生成器并使用 iostat（1） 测量结果性能。自定义负载生成器可以是一个简短的 C 程序，用于打开设备路径并应用预期的工作负载。在 Linux 上，可以使用 O_DIRECT 打开块特殊设备文件，以避免缓冲。如果你使用高级语言，请尝试使用至少避免库缓冲的系统级接口（例如，Perl 中的 sysread（）），最好也避免内核缓冲（例如，O_DIRECT）。

# #9.8.3 微基准测试工具
可用的磁盘基准测试工具包括 Linux 上的 hdparm（8）：

# hdparm -Tt /dev/sdb
 /dev/sdb:
 Timing cached reads:   16718 MB in  2.00 seconds = 8367.66 MB/sec
 Timing buffered disk reads:  846 MB in  3.00 seconds = 281.65 MB/sec

-T 选项测试缓存的读取，而 -t 测试磁盘设备读取。结果显示了磁盘上缓存命中和未命中之间的巨大差异。

阅读工具文档以了解任何注意事项，并参阅第 12 章 基准测试，了解有关微基准测试的更多背景信息。另请参阅第 8 章 “文件系统”，了解通过文件系统测试磁盘性能的工具（还有更多工具可用）。

# #9.8.4 随机读取示例
作为一个示例实验，我编写了一个自定义工具来执行磁盘设备路径的随机 8 KB 读取工作负载。该工具的 1 到 5 个实例同时运行，其中 iostat（1） 正在运行。包含零的写入列已被删除

 Device:    rrqm/s      r/s    rkB/s  avgrq-sz   aqu-sz r_await  svctm  %util
 sda        878.00   234.00  2224.00     19.01     1.00    4.27   4.27 100.00
 [...]
 Device:    rrqm/s      r/s    rkB/s  avgrq-sz   aqu-sz r_await  svctm  %util
 sda       1233.00   311.00  3088.00     19.86     2.00    6.43   3.22 100.00
 [...]
 Device:    rrqm/s      r/s    rkB/s  avgrq-sz   aqu-sz r_await  svctm  %util
 sda       1366.00   358.00  3448.00     19.26     3.00    8.44   2.79 100.00
 [...]
 Device:    rrqm/s      r/s    rkB/s  avgrq-sz   aqu-sz r_await  svctm  %util
 sda       1775.00   413.00  4376.00     21.19     4.01    9.66   2.42 100.00
 [...]
 Device:    rrqm/s      r/s    rkB/s  avgrq-sz   aqu-sz r_await  svctm  %util
 sda       1977.00   423.00  4800.00     22.70     5.04   12.08   2.36 100.00

请注意 aqu-sz 的阶梯式增加和 r_await 的延迟增加。

# #9.8.5 ioping
ioping（1） 是一个有趣的磁盘微基准测试工具，类似于 ICMP 的 ping（8） 工具。在 nvme0n1 磁盘设备上运行 ioping（1）：

# ioping /dev/nvme0n1
 4 KiB <<< /dev/nvme0n1 (block device 8 GiB): request=1 time=438.7 us (warmup)
 4 KiB <<< /dev/nvme0n1 (block device 8 GiB): request=2 time=421.0 us
 4 KiB <<< /dev/nvme0n1 (block device 8 GiB): request=3 time=449.4 us
 4 KiB <<< /dev/nvme0n1 (block device 8 GiB): request=4 time=412.6 us
 4 KiB <<< /dev/nvme0n1 (block device 8 GiB): request=5 time=468.8 us
 ^C--- /dev/nvme0n1 (block device 8 GiB) ioping statistics --
4 requests completed in 1.75 ms, 16 KiB read, 2.28 k iops, 8.92 MiB/s
 generated 5 requests in 4.37 s, 20 KiB, 1 iops, 4.58 KiB/s
 min/avg/max/mdev = 412.6 us / 437.9 us / 468.8 us / 22.4 us

默认情况下，ioping（1） 每秒发出 4 KB 的读取，并以微秒为单位打印其 I/O 延迟。终止时，将打印各种统计信息。

ioping（1） 与其他基准测试工具的不同之处在于它的工作负载是轻量级的。以下是 ioping（1） 运行时的一些 iostat（1） 输出：

 $ iostat -xsz 1
 [...]
 Device             tps      kB/s    rqm/s   await aqu-sz  areq-sz  %util
 nvme0n1           1.00      4.00     0.00    0.00   0.00     4.00   0.40

磁盘的利用率仅为 0.4%。ioping（1） 可能用于调试其他微基准测试不适用的生产环境中的问题，因为它们通常会将目标磁盘驱动到 100% 的利用率。

# #9.8.6 fio
灵活的 IO 测试仪 （fio） 是一个文件系统基准测试工具，还可以揭示磁盘设备的性能，特别是当与 --direct=true 选项一起使用以使用非缓冲 I/O 时（当文件系统支持非缓冲 I/O 时）。它在第 8 章 文件系统， 第 8.7.2 节 微基准测试工具中介绍。

# #9.8.7 blkreplay
块 I/O 重放工具 （blkreplay） 可以重放使用 blktrace（第 9.6.10 节，blktrace）或 Windows DiskMon [Schöbel-Theuer 12] 捕获的块 I/O 负载。这在调试难以使用微基准测试工具重现的磁盘问题时非常有用。

请参见Chapter 12 ， Benchmarking， Section 12.2.3， replay，了解如果目标系统已更改，磁盘 I/O 重放如何产生误导。

# 9.9 调优
部分 9.5， 方法中介绍了许多调整方法，包括高速缓存调整、扩展和工作负载特征描述，这可以帮助您识别和消除不必要的工作。调优的另一个重要领域是存储配置，可以作为静态性能调优方法的一部分进行研究。

以下部分显示了可以调整的区域：操作系统、磁盘设备和磁盘控制器。可用的可调参数因操作系统版本、磁盘型号、磁盘控制器及其固件而异;请参阅各自的文档。虽然更改可调参数很容易，但默认设置通常是合理的，很少需要太多调整

# #9.9.1 操作系统可调参数
这些参数包括 ionice（1）、资源控制和内核可调参数。

# ionice
在 Linux 上，ionice（1） 命令可用于设置进程的 I/O 调度类和优先级。调度类以数字方式标识： 
■ 0， none： 未指定类，因此内核将选择一个默认值 — 尽力而为，其优先级基于进程 nice 值。
■ 1、real-time：对磁盘的最高优先级访问。如果使用不当，这可能会使其他进程饥饿（就像 RT CPU 调度类一样）。
■ 2、尽力而为：默认调度类，支持优先级 0-7，其中 0 为最高优先级。
■ 3、idle：仅在磁盘空闲宽限期后才允许磁盘 I/O。

用法示例：

# ionice -c 3 -p 1623

这会将进程 ID 1623 置于空闲 I/O 调度类中。这对于长时间运行的备份作业来说可能是可取的，这样它们就不太可能干扰生产工作负载

# 资源控制
现代操作系统提供了资源控制，用于以自定义方式管理磁盘或文件系统 I/O 使用情况。

对于 Linux，容器组 （cgroups） 块 I/O （blkio） 子系统为进程或进程组提供存储设备资源控制。这可以是按比例权重（如份额）或固定限制。可以独立地为读取和写入以及 IOPS 或吞吐量（每秒字节数）设置限制。有关更多详细信息，请参见第 11 章 “云计算”。

# 可调参数
Linux 可调参数示例包括： 
■ /sys/block/*/queue/scheduler： 选择 I/O 调度器策略：这些策略可能包括 noop、deadline、cfq 等。请参见部分 9.4体系结构中对这些内容的前面描述。
■ /sys/block/*/queue/nr_requests：块层可以分配的读或写请求数。
■ /sys/block/*/queue/read_ahead_kb：文件系统请求的最大预读 KB 数

与其他内核可调参数一样，请查看文档以获取完整列表、描述和警告。在 Linux 源代码中，请参阅 Documentation/block/queue-sysfs.txt。

# #9.9.2 磁盘控制器可调参数
在 Linux 上，hdparm（8） 工具可以设置各种磁盘设备可调参数，包括电源管理和降速超时 [Archlinux 20]。使用此工具时要非常小心，并阅读 hdparm（8） 手册页 — 各种选项都标记为 “DANGEROUS”，因为它们可能会导致数据丢失。

# #9.9.3 磁盘控制器可调参数
可用的磁盘控制器可调参数取决于磁盘控制器型号和供应商。为了让您了解这些设置可能包括哪些内容，下面显示了 Dell PERC 6 卡的一些设置，使用 MegaCli 命令查看：

 # MegaCli -AdpAllInfo -aALL
 [...]
 Predictive Fail Poll Interval    : 300sec
 Interrupt Throttle Active Count  : 16
  Interrupt Throttle Completion    : 50us
 Rebuild Rate                     : 30%
 PR Rate                          : 0%
 BGI Rate                         : 1%
 Check Consistency Rate           : 1%
 Reconstruction Rate              : 30%
 Cache Flush Interval             : 30s
 Max Drives to Spinup at One Time : 2
 Delay Among Spinup Groups        : 12s
 Physical Drive Coercion Mode     : 128MB
 Cluster Mode                     : Disabled
 Alarm                            : Disabled
 Auto Rebuild                     : Enabled
 Battery Warning                  : Enabled
 Ecc Bucket Size                  : 15
 Ecc Bucket Leak Rate             : 1440 Minutes
 Load Balance Mode                : Auto
 [...]

每个设置都有一个描述性合理的名称，供应商文档中对此进行了更详细的描述。

# 9.10 练习
1. 回答以下有关磁盘术语的问题： 
■ 什么是 IOPS？
■ 服务时间和等待时间有什么区别？
■ 什么是磁盘 I/O 等待时间？
■ 什么是延迟异常值？
■ 什么是非数据传输磁盘命令？

2. 回答以下概念性问题： 
■ 描述磁盘利用率和饱和度。
■ 描述随机磁盘 I/O 和顺序磁盘 I/O 之间的性能差异。
■ 描述磁盘上缓存在读取和写入 I/O 中的作用。

3. 回答以下更深层次的问题： 
■ 解释为什么虚拟磁盘的利用率（繁忙百分比）可能具有误导性。■ 解释为什么“I/O 等待”指标可能具有误导性。
■ 描述 RAID-0（条带化）和 RAID-1（镜像）的性能特征。
■ 描述当磁盘工作过载时会发生什么，包括对应用程序性能的影响。
■ 描述当存储控制器工作过载（吞吐量或 IOPS）时会发生什么，包括对应用程序性能的影响。

4. 为您的操作系统制定以下程序： 
■ 磁盘资源（磁盘和控制器）的 USE 方法检查表。包括如何获取每个指标（例如，要执行哪个命令）以及如何解释结果。在安装或使用其他软件产品之前，请尝试使用现有的操作系统可观测性工具。
■ 磁盘资源的工作负载特征清单。包括如何获取每个指标，并首先尝试使用现有的操作系统可观测性工具

5. 单独描述此 Linux iostat（1） 输出中可见的磁盘行为：
# $ iostat -x 1
 [...]
 avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           3.23    0.00   45.16   31.18    0.00   20.43
 Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz 
avgqu-sz   await r_await w_await  svctm  %util
 vda              39.78 13156.99  800.00  151.61  3466.67 41200.00    93.88    
11.99    7.49    0.57   44.01   0.49  46.56
 vdb               0.00     0.00    0.00    0.00     0.00     0.00     0.00     
0.00    0.00    0.00    0.00   0.00   0.00

6. （可选，高级）开发一个工具来跟踪除读取和写入之外的所有磁盘命令。这可能需要在 SCSI 级别进行跟踪。

# 9.11 引用
 [Patterson 88] Patterson, D., Gibson, G., and Kats, R., “A Case for Redundant Arrays of 
Inexpensive Disks,” ACM SIGMOD, 1988.
 [McDougall 06a] McDougall, R., Mauro, J., and Gregg, B., Solaris Performance and Tools: 
DTrace and MDB Techniques for Solaris 10 and OpenSolaris, Prentice Hall, 2006.
 [Brunelle 08] Brunelle, A., “btt User Guide,” blktrace package, /usr/share/doc/blktrace/btt.
 pdf, 2008.
 [Gregg 08] Gregg, B., “Shouting in the Datacenter,” https://www.youtube.com/
 watch?v=tDacjrSCeq4, 2008.
 [Mason 08] Mason, C., “Seekwatcher,” https://oss.oracle.com/~mason/seekwatcher, 2008.
 [Smith 09] Smith, R., “Western Digital’s Advanced Format: The 4K Sector Transition Begins,” 
https://www.anandtech.com/show/2888, 2009.
  [Gregg 10a] Gregg, B., “Visualizing System Latency,” Communications of the ACM, July 2010.
 [Love 10] Love, R., Linux Kernel Development, 3rd Edition, Addison-Wesley, 2010.
 [Turner 10] Turner, J., “Effects of Data Center Vibration on Compute System Performance,” 
USENIX SustainIT, 2010.
 [Gregg 11b] Gregg, B., “Utilization Heat Maps,” http://www.brendangregg.com/HeatMaps/
 utilization.html, published 2011.
 [Cassidy 12] Cassidy, C., “SLC vs MLC: Which Works Best for High-Reliability Applications?” 
https://www.eetimes.com/slc-vs-mlc-which-works-best-for-high-reliability-applications/#, 
2012.
 [Cornwell 12] Cornwell, M., “Anatomy of a Solid-State Drive,” Communications of the ACM, 
December 2012.
 [Schöbel-Theuer 12] Schöbel-Theuer, T., “blkreplay - a Testing and Benchmarking Toolkit,” 
http://www.blkreplay.org, 2012.
 [Chazarain 13] Chazarain, G., “Iotop,” http://guichaz.free.fr/iotop, 2013.
 [Corbet 13b] Corbet, J., “The multiqueue block layer,” LWN.net, https://lwn.net/
 Articles/552904, 2013.
 [Leventhal 13] Leventhal, A., “A File System All Its Own,” ACM Queue, March 2013.
 [Cai 15] Cai, Y., Luo, Y., Haratsch, E. F., Mai, K., and Mutlu, O., “Data Retention in MLC 
NAND Flash Memory: Characterization, Optimization, and Recovery,” IEEE 21st International 
Symposium on High Performance Computer Architecture (HPCA), 2015. 
https://users.ece.cmu.edu/~omutlu/pub/flash-memory-data-retention_hpca15.pdf
 [FICA 18] “Industry’s Fastest Storage Networking Speed Announced by Fibre Channel 
Industry Association—64GFC and Gen 7 Fibre Channel,” Fibre Channel Industry Association, 
https://fibrechannel.org/industrys-fastest-storage-networking-speed-announced-by-fibre
channel-industry-association-%E2%94%80-64gfc-and-gen-7-fibre-channel, 2018.
 [Hady 18] Hady, F., “Achieve Consistent Low Latency for Your Storage-Intensive Workloads,” 
https://www.intel.com/content/www/us/en/architecture-and-technology/optane-technology/
 low-latency-for-storage-intensive-workloads-article-brief.html, 2018.
 [Gregg 19] Gregg, B., BPF Performance Tools: Linux System and Application Observability, 
Addison-Wesley, 2019.
 [Archlinux 20] “hdparm,” https://wiki.archlinux.org/index.php/Hdparm, last updated 
2020.
 [Dell 20] “PowerEdge RAID Controller,” https://www.dell.com/support/article/en-us/
 sln312338/poweredge-raid-controller?lang=en, accessed 2020.
 [FCIA 20] “Features,” Fibre Channel Industry Association, https://fibrechannel.org/
 fibre-channel-features, accessed 2020.
 [Liu 20] Liu, L., “Samsung QVO vs EVO vs PRO: What’s the Difference? [Clone Disk],” 
https://www.partitionwizard.com/clone-disk/samsung-qvo-vs-evo.html, 2020.
  [Mellor 20] Mellor, C., “Western Digital Shingled Out in Lawsuit for Sneaking RAID
unfriendly Tech into Drives for RAID arrays,” TheRegister, https://www.theregister.com/
 2020/05/29/wd_class_action_lawsuit, 2020.
 [Netflix 20] “Open Connect Appliances,” https://openconnect.netflix.com/en/appliances, 
accessed 2020.
 [NVMe 20] “NVM Express,” https://nvmexpress.org, accessed 2020.