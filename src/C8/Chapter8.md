# Chapter 8: 文件系统
对于应用程序来说，文件系统性能通常比磁盘或存储设备更重要，因为它是应用程序与之交互和等待的文件系统。文件系统可以使用缓存、缓冲和异步 I/O 来避免应用程序受到磁盘级（或远程存储系统）延迟的影响。

系统性能分析和监控工具历来关注磁盘性能，使文件系统性能成为一个盲点。本章阐明了文件系统，展示了它们的工作原理以及如何测量它们的延迟和其他详细信息。这通常可以排除文件系统及其底层磁盘设备是性能不佳的根源，从而允许调查转移到其他方面

本章的学习目标是：

■ 了解文件系统模型和概念。
■ 了解文件系统工作负载如何影响性能。
■ 熟悉文件系统缓存。
■ 熟悉文件系统内部和性能功能。
■ 遵循各种方法进行文件系统分析。
■ 测量文件系统延迟以识别模式和异常值。
■ 使用跟踪工具调查文件系统使用情况。
■ 使用微基准测试测试文件系统性能。
■ 了解文件系统可调参数。

本章由六个部分组成，前三个部分为文件系统分析提供基础，后三个部分介绍其在基于 Linux 的系统中的实际应用。这些部分如下：

■ 背景介绍了与文件系统相关的术语和基本模型，说明了文件系统原理和关键的文件系统性能概念。■ 架构 介绍通用和特定的文件系统架构。
■ 方法描述了性能分析方法，包括观察性和实验性。
■ Observability Tools （可观测性工具） 显示基于 Linux 的系统的文件系统可观测性工具，包括静态和动态检测。
■ 实验总结了文件系统基准测试工具。
■ 优化描述了文件系统可调参数。

# 8.1 术语
作为参考，本章中使用的与文件系统相关的术语包括

■ 文件系统：将数据组织为文件和目录，具有基于文件的界面用于访问它们，以及用于控制访问的文件权限。其他内容可能包括设备、套接字和管道的特殊文件类型，以及包括文件访问时间戳在内的元数据。
■ 文件系统缓存：用于缓存文件系统内容的主内存（通常是 DRAM）区域，其中可能包括各种数据和元数据类型的不同缓存。
■ operations：文件系统作是文件系统的请求，包括 read（2）、write（2）、open（2）、close（2）、stat（2）、mkdir（2） 等操作。
■ I/O：输入/输出。文件系统 I/O 可以通过多种方式定义;这里它只表示直接读写（执行 I/O）的作，包括 read（2）、write（2）、stat（2）（读取统计信息）和 mkdir（2）（写入新的目录条目）。I/O 不包括 open（2） 和 close（2）（尽管这些调用会更新元数据并可能导致间接磁盘 I/O）
■ 逻辑 I/O：应用程序向文件系统发出的 I/O。
■ 物理 I/O：由文件系统（或通过原始 I/O）直接向磁盘发出的 I/O。
■ 块大小：也称为记录大小，是文件系统磁盘数据组的大小。请参见部分 8.4.4， 文件系统功能中的块与范围。
■ 吞吐量：应用程序和文件系统之间的当前数据传输速率，以每秒字节数为单位。
■ inode：索引节点 （inode） 是一种数据结构，包含文件系统对象的元数据，包括权限、时间戳和数据指针。
■ VFS：虚拟文件系统，用于抽象和支持不同文件系统类型的内核接口
■ 卷：一种存储实例，比使用整个存储设备提供更大的灵活性。卷可以是设备的一部分，也可以是多个设备。
■ 卷管理器：用于以灵活的方式管理物理存储设备，创建供作系统使用的虚拟卷的软件。

本章介绍了其他术语。词汇表包括供参考的基本术语，包括 fsck 、 IOPS 、作速率和 POSIX 。另请参阅第 2 章和第 3 章中的术语部分。

# 8.2 Models
以下简单模型说明了文件系统的一些基本原理及其性能。

# #8.2.1 文件系统接口
图 8.1 显示了文件系统的基本模型，就其接口而言

图中还标记了发生逻辑和物理操作的位置。有关这些的更多信息，请参见第 8.3.12 节 逻辑 I/O 与物理 I/O 的比较。

图 8.1 显示了通用对象操作。内核可以实现其他变体：例如，Linux 提供 readv（2）、writev（2）、openat（2） 等。

研究文件系统性能的一种方法是将其视为黑盒，重点关注对象作的延迟。部分 8.5.2， 延迟分析中对此进行了更详细的解释。

# #8.2.2 文件系统缓存
存储在主内存中的通用文件系统缓存如图 8.2 所示，它为读取作提供服务。

读取从缓存 （缓存命中） 或磁盘 （缓存未命中） 返回数据。缓存未命中存储在缓存中，填充缓存（预热）。

文件系统缓存还可以缓冲写入，以便稍后写入（刷新）。执行此作的机制因文件系统类型而异，如部分 8.4 体系结构中所述。

如果需要，内核通常提供一种绕过缓存的方法。请参见部分 8.3.8， 原始和直接 I/O。

# #8.2.3 二级缓存
二级缓存可以是任何内存类型;图 8.3 将其显示为闪存。这种缓存类型最初是我自己在 2007 年为 ZFS 开发的。

# 8.3 概念
以下是一些重要的文件系统性能概念。

# #8.3.1 文件系统延迟
文件系统延迟是文件系统性能的主要指标，以从逻辑文件系统请求到完成的时间来衡量。它包括在文件系统和磁盘 I/O 子系统中花费的时间，以及在磁盘设备（物理 I/O）上等待的时间。应用程序线程通常会在应用程序请求期间阻塞，以便等待文件系统请求完成，因此，文件系统延迟会直接按比例影响应用程序性能

应用程序可能不会受到直接影响的情况包括使用非阻塞 I/O、预取（第 8.3.4 节）以及从异步线程（例如，后台刷新线程）发出 I/O 时。如果应用程序提供其文件系统使用情况的详细指标，则可以从应用程序中识别这些情况。如果没有，一种通用的方法是使用内核跟踪工具，它可以显示导致逻辑文件系统 I/O 的用户级堆栈跟踪。然后可以研究此堆栈跟踪以查看哪些应用程序例程发出了它。

操作系统历来没有使文件系统延迟易于观察，而是提供磁盘设备级统计数据。但在许多情况下，此类统计信息与应用程序性能无关，并且它们也具有误导性。这方面的一个例子是文件系统对写入数据执行后台刷新，这可能表现为高延迟磁盘 I/O 的突发。从磁盘设备级别的统计信息来看，这看起来令人担忧;但是，没有应用程序等待这些完成。有关更多情况，请参见第 8.3.12 节 逻辑 I/O 与物理 I/O。

# #8.3.2 缓存
文件系统通常使用主内存 （RAM） 作为缓存来提高性能。对于应用程序，此过程是透明的：应用程序逻辑 I/O 延迟变得更低（更好），因为它可以从主内存而不是速度慢得多的磁盘设备提供。

随着时间的推移，缓存会增长，而操作系统的可用内存会缩小。这可能会让新用户感到警觉，但这是完全正常的。原则是：如果有备用的主内存，就用它做一些有用的事情。当应用程序需要更多内存时，内核应迅速将其从文件系统缓存中释放出来以供使用。

文件系统使用缓存来提高读取性能，使用缓冲（在缓存中）来提高写入性能。文件系统和 block device 子系统通常使用多种类型的缓存，其中可能包括 Table 8.1 中的那些。

部分 8.4， 体系结构中介绍了特定的高速缓存类型，而第 3 章作系统则提供了高速缓存的完整列表（包括应用程序级和设备级）。

# #8.3.3 随机VS顺序I/O
根据每个 I/O 的文件偏移量，一系列逻辑文件系统 I/O 可以描述为随机或顺序。对于顺序 I/O，每个 I/O 偏移量都从前一个 I/O 的末尾开始。随机 I/O 之间没有明显的关系，偏移量是随机变化的。随机文件系统工作负载也可以指随机访问许多不同的文件

图 8.4 说明了这些访问模式，显示了一系列有序的 I/O 和示例文件偏移量

由于某些存储设备的性能特征（在第 9 章 磁盘中介绍），文件系统历来尝试通过按顺序和连续地将文件数据放置在磁盘上来减少随机 I/O。术语碎片描述了文件系统在这方面做得很差的情况，导致文件分散在驱动器上，从而使顺序逻辑 I/O 产生随机的物理 I/O。

文件系统可以测量逻辑 I/O 访问模式，以便它们可以识别顺序工作负载，然后使用预取或预读来提高其性能。这对旋转盘很有帮助;闪存驱动器则不然

# #8.3.4 预取
常见的文件系统工作负载涉及按顺序读取大量文件数据，例如，用于文件系统备份。此数据可能太大而无法放入缓存中，或者它可能只读取一次并且不太可能保留在缓存中（取决于缓存驱逐策略）。此类工作负载的性能相对较差，因为它的缓存命中率较低。

预取是解决此问题的常见文件系统功能。它可以根据当前和以前的文件 I/O 偏移量检测顺序读取工作负载，然后在应用程序请求磁盘读取之前预测并发出磁盘读取。这将填充文件系统缓存，因此，如果应用程序确实执行了预期的读取，则会导致缓存命中（所需的数据已在缓存中）。示例场景如下：

1. 应用程序发出一个文件 read（2），将执行传递给内核。
2. 数据未缓存，因此文件系统将读取问题发送到磁盘。
3. 将前一个文件偏移指针与当前位置进行比较，如果它们是连续的，则文件系统会发出额外的读取（预取）。
4. 第一次读取完成，内核将数据和执行传递回应用程序。
5. 所有预取读取都已完成，填充缓存以供将来的应用程序读取。
6. 未来的顺序应用程序读取通过 RAM 中的缓存快速完成

图 8.5 也说明了这种情况，其中应用程序读取偏移量 1 和 2 触发接下来三个偏移量的预取。

当预取检测运行良好时，应用程序的顺序读取性能会显著提高;磁盘会领先于应用程序请求（前提是它们有足够的带宽来执行此作）。当预取检测效果不佳时，会发出应用程序不需要的不必要的 I/O，从而污染高速缓存并消耗磁盘和 I/O 传输资源。文件系统通常允许根据需要调整预取。

# #8.3.5 预读
从历史上看，预取也称为预读。Linux 使用预读术语 readahead（2） 进行系统调用，它允许应用程序显式预热文件系统缓存

# #8.3.6 回写缓存
文件系统通常使用回写缓存来提高写入性能。它的工作原理是在传输到主内存后将写入视为已完成，并在一段时间后异步将它们写入磁盘。将此 “脏” 数据写入磁盘的文件系统过程称为 flushing。示例序列如下：

1. 应用程序发出文件 write（2），将执行传递给内核。
2. 将应用程序地址空间中的数据复制到内核。
3. 内核将 write（2） syscall 视为已完成，并将执行传递回应用程序。
4. 一段时间后，异步内核任务会找到写入的数据并发出磁盘写入问题。

权衡是可靠性。基于 DRAM 的主内存具有易失性，如果发生电源故障，脏数据可能会丢失。数据也可能不完整地写入磁盘，从而留下损坏的磁盘状态。

如果文件系统元数据损坏，文件系统可能无法再加载。这种状态可能只能从系统备份中恢复，从而导致停机时间延长。更糟糕的是，如果损坏影响了应用程序读取和使用的文件内容，则业务可能会处于危险之中。

为了平衡速度和可靠性的需求，文件系统可以默认提供回写缓存，并提供同步写入选项以绕过此行为并直接写入持久性存储设备。

# #8.3.7 同步写入
同步写入仅在完全写入持久性存储（例如磁盘设备）时完成，其中包括写入任何必要的文件系统元数据更改。这些比异步写入（回写缓存）慢得多，因为同步写入会导致磁盘设备 I/O 延迟（并且由于文件系统元数据，可能会有多个 I/O）。某些应用程序（如数据库日志写入器）使用同步写入，这些应用程序不可接受异步写入导致数据损坏的风险。

同步写入有两种形式：单个 I/O （同步写入）和先前写入组 （同步提交）。

# 单个同步写入
当使用标志 O_SYNC 或变体之一 O_DSYNC 和 O_RSYNC 打开文件时，写入 I/O 是同步的（从 Linux 2.6.31 开始，它们由 glibc 映射到 O_SYNC）。某些文件系统具有挂载选项，以强制对所有文件的所有写入 I/O 都是同步的

# 同步提交以前的写入
应用程序可以使用 fsync（2） 系统调用在其代码的检查点同步提交以前的异步写入，而不是同步写入单个 I/O。这可以通过对写入进行分组来提高性能，还可以通过使用写入取消来避免多个元数据更新

还有其他情况将提交以前的写入，例如关闭文件句柄，或者当文件上有太多未提交的缓冲区时。前者通常很明显，因为在解压缩包含许多文件的存档时，尤其是在 NFS 上。

# #8.3.8 原始 I/O 和直接 I/O
这些是应用程序可以使用的其他类型的 I/O（如果内核或文件系统支持）

原始 I/O 直接发送到磁盘偏移量，完全绕过文件系统。它已被一些应用程序（尤其是数据库）使用，这些应用程序可以比文件系统缓存更好地管理和缓存自己的数据。缺点是软件更复杂，并且管理困难：常规文件系统工具集不能用于备份/还原或可观察性。

Direct I/O 允许应用程序使用文件系统，但绕过文件系统缓存，例如，在 Linux 上使用 O_DIRECT open（2） 标志。这类似于同步写入（但没有 O_SYNC 提供的保证），也适用于读取。它不像原始设备 I/O 那样直接，因为文件偏移量到磁盘偏移量的映射仍必须由文件系统代码执行，并且 I/O 也可以调整大小以匹配文件系统用于磁盘布局的大小（其记录大小），否则可能会出错 （EINVAL）。根据文件系统的不同，这不仅可能禁用读取缓存和写入缓冲，还可能禁用预取

# #8.3.9 非阻塞I/O
通常，文件系统 I/O 将立即完成（例如，从缓存中）或等待后完成（例如，对于磁盘设备 I/O）。如果需要等待，应用程序线程将阻塞并离开 CPU，

允许其他线程在等待时执行。虽然被阻止的线程无法执行其他工作，但这通常不是问题，因为多线程应用程序可以创建额外的线程来执行，而某些线程被阻止。

在某些情况下，非阻塞 I/O 是可取的，例如，当避免线程创建的性能或资源开销时。非阻塞 I/O 可以通过对 open（2） 系统调用使用 O_NONBLOCK 或 O_NDELAY 标志来执行，这会导致读取和写入返回 EAGAIN 错误，而不是阻塞，阻塞告诉应用程序稍后再试。（对此的支持取决于文件系统，它可能仅对建议或强制文件锁定遵循非阻塞。

操作系统还可以提供单独的异步 I/O 接口，例如 aio_read（3） 和 aio_ write（3）。Linux 5.1 添加了一个名为 io_uring 的新异步 I/O 接口，提高了易用性、效率和性能 [Axboe 19]。

非阻塞 I/O 也在第 5 章 应用程序， 第 5.2.6 节 非阻塞 I/O 中讨论过

# #8.3.10 内存映射文件
对于某些应用程序和工作负载，可以通过将文件映射到进程地址空间并直接访问内存偏移量来提高文件系统 I/O 性能。这避免了在调用 read（2） 和 write（2） 系统调用来访问文件数据时产生的系统调用执行和上下文切换开销。如果内核支持直接将文件数据缓冲区映射到进程地址空间，它还可以避免数据的双重复制。

内存映射是使用 mmap（2） 系统调用创建的，并使用 munmap（2） 删除的。映射可以使用 madvise（2） 进行调整，如 第 8.8 节 调整 中所述。某些应用程序提供了在其配置中使用 mmap 系统调用（可能称为“mmap 模式”）的选项。例如，Riak 数据库可以将 mmap 用于其内存中的数据存储

我注意到一种倾向，即尝试使用 mmap（2） 来解决文件系统性能问题，而不先分析它们。如果问题是磁盘设备的高 I/O 延迟，那么当高磁盘 I/O 延迟仍然占主导地位时，使用 mmap（2） 避免小的 syscall 开销可能收效甚微

在多处理器系统上使用映射的一个缺点可能是保持每个 CPU MMU 同步的开销，特别是用于删除映射的 CPU 交叉调用（TLB 击降）。根据内核和映射，可以通过延迟 TLB 更新（惰性击降）来最小化这些 [Vahalia 96]。

# #8.3.11 元数据
数据描述文件和目录的内容，而元数据描述有关它们的信息。元数据可以引用可从文件系统接口 （POSIX） 读取的信息，或实现文件系统磁盘布局所需的信息。这些元数据分别称为逻辑元数据和物理元数据。

# 逻辑元数据
逻辑元数据是使用者（应用程序）读取和写入文件系统的信息，可以是：

■ 显式：读取文件统计信息 （stat（2））、创建和删除文件 （creat（2）、unlink（2）） 和目录 （mkdir（2）、rmdir（2））、设置文件属性 （chown（2）、chmod（2））
■ 隐式：文件系统访问时间戳更新、目录修改时间戳更新、已用块位图更新、可用空间统计信息

“元数据繁重”的工作负载通常是指逻辑元数据，例如，对文件进行 stat（2）作以确保它们在缓存后未更改的 Web 服务器，其速率比读取文件数据内容要快得多。

# 物理元数据
物理元数据是指记录所有文件系统信息所需的磁盘布局元数据。使用的元数据类型取决于文件系统，可能包括超级块、inode、数据指针块（主、辅助等）和空闲列表。

逻辑元数据和物理元数据是逻辑 I/O 和物理 I/O 之间存在差异的一个原因

# #8.3.12 逻辑I/OVS物理I/O
尽管这似乎有悖常理，但出于多种原因，应用程序对文件系统请求的 I/O （逻辑 I/O） 可能与磁盘 I/O （物理 I/O） 不匹配。

文件系统的作用远不止将持久存储（磁盘）呈现为基于文件的接口。它们缓存读取、缓冲区写入、将文件映射到地址空间，并创建额外的 I/O 来维护他们需要记录所有内容位置的磁盘上物理布局元数据。与应用程序 I/O 相比，这可能会导致磁盘 I/O 不相关、间接、隐式、膨胀或收缩。

# 不相关的
这是与应用程序无关的磁盘 I/O，可能是由于：

■ 其他应用程序 
■ 其他租户：磁盘 I/O 来自另一个云租户（在某些虚拟化技术下，通过系统工具可见）。
■ 其他内核任务：例如，当内核重建软件 RAID 卷或执行异步文件系统校验和验证时（请参见部分 8.4 体系结构）。
■ 管理任务：如备份

# 间接
这是由应用程序引起的磁盘 I/O，但没有立即对应的应用程序 I/O。这可能是由于：

■ 文件系统预取：添加应用程序可能使用也可能不使用的其他 I/O。
■ 文件系统缓冲：使用回写缓存来延迟和合并写入，以便以后刷新到磁盘。某些系统可能会在写入之前将写入缓冲数十秒，然后表现为不频繁的大突发。

# 含蓄
这是由应用程序事件直接触发的磁盘 I/O，而不是显式文件系统读取和写入，例如：

内存映射加载/存储：对于内存映射 （mmap（2）） 文件，加载和存储指令可能会触发磁盘 I/O 来读取或写入数据。写入可以缓冲并在以后写入。当分析文件系统作（read（2）、write（2））并且无法找到 I/O 的来源（因为它是由指令而不是系统调用触发）时，这可能会令人困惑。

# 瘪
小于应用程序 I/O 的磁盘 I/O，甚至不存在。这可能是由于：
■ 文件系统缓存：满足从主内存而不是磁盘的读取。
■ 文件系统写入取消：相同的字节偏移量在刷新到磁盘一次之前会多次修改。
■ 压缩：将数据量从逻辑 I/O 减少到物理 I/O。
■ 合并：在将顺序 I/O 发送到磁盘之前合并它们（这会减少 I/O 计数，但不会减少总大小）。
■ 内存文件系统：可能永远不会写入磁盘的内容（例如 tmpfs1）。

# 膨胀
大于应用程序 I/O 的磁盘 I/O。这是典型的情况，因为： 
■ 文件系统元数据：添加额外的 I/O。
■ 文件系统记录大小：四舍五入 I/O 大小（膨胀字节）或分段 I/O（膨胀计数）。
■ 文件系统日志：如果使用，则可以将磁盘写入翻倍，一次写入日志，另一次写入最终目标。
■ 卷管理器奇偶校验：读取-修改-写入周期，添加额外的 I/O。
■ RAID 膨胀：将额外的奇偶校验数据或数据写入镜像卷。

# 例子
为了说明这些因素如何同时发生，以下示例描述了 1 字节应用程序可以写入的内容：

1. 应用程序对现有文件执行 1 字节的写入作。
2. 文件系统将位置标识为 128 KB 文件系统记录的一部分，该记录未缓存（但引用它的元数据是缓存）。
3. 文件系统请求从磁盘加载记录。
4. 磁盘设备层将 128 KB 的读取分解为适合设备的较小读取。
5. 磁盘执行多个较小的读取，总计 128 KB。
6. 文件系统现在将记录中的 1 字节替换为新字节。
7. 一段时间后，文件系统或内核请求将 128 KB 的脏记录写回磁盘。
8. 磁盘写入 128 KB 的记录（如果需要，可以分解）。
9. 文件系统写入新的元数据，例如，更新引用（用于写入时复制）或访问时间。
10. 磁盘执行更多写入操作。

因此，虽然应用程序只执行一次 1 字节的写入，但磁盘执行了多次读取（总共 128 KB）和更多写入（超过 128 KB）。

# #8.3.13 操作并不相等
从前面的部分可以清楚地看出，文件系统操作可以根据其类型表现出不同的性能。仅从速率来看，您无法判断 “500 次作/秒” 的工作负载。某些操作可能会以主内存速度从文件系统缓存返回;其他 Cookie 可能会从磁盘返回，并且速度要慢几个数量级。其他决定因素包括作是随机的还是顺序的、读取还是写入、同步写入还是异步写入、它们的 I/O 大小、它们是否包括其他作类型、它们的 CPU 执行成本（以及系统的 CPU 负载程度）以及存储设备特征。