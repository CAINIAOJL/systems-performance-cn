# Chapter 2: 方法论
给一个人一条鱼，你就能喂他一天。教一个人钓鱼，你就能养活他一辈子。中国谚语 （相当于英文）

我从初级系统管理员开始了我的技术职业生涯，我认为我可以通过单独学习命令行工具和指标来学习性能。我错了。我从上到下阅读了手册页，并学习了页面错误、上下文切换和各种其他系统指标的定义，但我不知道如何处理它们：如何从信号转向解决方案。

我注意到，每当出现性能问题时，高级系统管理员都有自己的心理程序，可以快速浏览工具和指标以找到根本原因。他们了解哪些指标是重要的，何时指出问题，以及如何使用它们来缩小调查范围。正是这些专业知识在手册页中缺失 — 通常是通过在高级管理员或工程师的肩膀上观察来学习的

从那时起，我收集、记录、分享和开发了自己的性能方法。本章包括这些方法和系统性能的其他基本背景：概念、术语、统计和可视化。在后面的章节深入探讨实现之前，这涵盖了理论。

本章的学习目标是：
■ 了解关键性能指标：延迟、利用率和饱和度。
■ 培养对测量时间尺度的感觉，精确到纳秒。
■ 了解优化权衡、目标以及何时停止分析。
■ 确定工作负载与架构的问题。
■ 考虑资源与工作负载分析。
■ 遵循不同的性能方法，包括：USE 方法、工作负载特征、延迟分析、静态性能调整和性能口号。
■ 了解统计和排队理论的基础知识。
在本书的所有章节中，这一章自第一版以来变化最小。软件、硬件、性能工具和性能可调参数在我的职业生涯中都发生了变化。保持不变的是理论和方法：本章涵盖的持久技能。
本章分为三个部分： 
■  背景 介绍术语、基本模型、关键性能概念和观点。其中大部分将假设为 r 的知识
■  方法论讨论了观察性和实验性的性能分析方法;建 模;和容量规划。
■  Metrics 介绍了性能统计信息、监控和可视化。

此处介绍的许多方法将在后面的章节中更详细地探讨，包括第 5 章到第 10 章中的方法部分

# 2.1 技术
以下是系统性能的关键术语。后面的章节提供了额外的术语，并在不同的上下文中描述了其中的一些术语。
IOPS：每秒的输入/输出作数是衡量数据传输作速率的指标。对于磁盘 I/O，IOPS 是指每秒的读取和写入。
吞吐量：执行的工作量的速率。特别是在通信中，该术语用于指代数据速率（每秒字节数或每秒位数）。在某些上下文（例如，数据库）吞吐量可以指作速率（每秒作数或每秒事务数）。
响应时间：作完成的时间。这包括等待所花费的任何时间和被服务所花费的时间 （服务时间），包括传输结果的时间。
Latency（延迟）：作等待服务所花费的时间的度量。在某些情况下，它可以指作的整个时间，相当于响应时间。有关示例，请参见部分 2.3， 概念。
利用率：对于服务请求的资源，利用率是衡量资源繁忙程度的指标，基于资源在给定时间间隔内主动执行工作的时间。对于提供存储的资源，利用率可能是指消耗的容量（例如，内存利用率）
饱和度：资源已将工作排队无法服务的程度。
瓶颈：在系统性能中，瓶颈是限制系统性能的资源。识别和消除系统性瓶颈是系统性能的一项关键活动。
工作负载：系统的输入或应用的负载就是工作负载。对于数据库，工作负载由客户端发送的数据库查询和命令组成。
缓存：一个快速存储区域，可以复制或缓冲有限数量的数据，以避免直接与较慢的存储层通信，从而提高性能。出于经济原因，缓存通常小于较慢的层。
词汇表包含更多术语，以供参考（如果需要）。

# 2.2 模式
以下简单模型说明了系统性能的一些基本原理。

# 2.3 被测系统
被测系统 （SUT） 的性能如图 2.1 所示。
请务必注意，扰动（干扰）可能会影响结果，包括由计划的系统活动、系统的其他用户和其他工作负载引起的结果。扰动的来源可能并不明显，可能需要仔细研究系统性能才能确定它。这在某些云环境中可能特别困难，因为可能无法从来宾 SUT 中观察到物理主机系统上的其他活动（由来宾租户）、

现代环境的另一个困难是，它们可能由为输入工作负载提供服务的多个网络组件组成，包括负载均衡器、代理服务器、Web 服务器、缓存服务器、应用程序服务器、数据库服务器和存储系统。仅仅绘制环境图的行为可能有助于揭示以前被忽视的扰动来源。环境也可以建模为排队系统网络，用于分析研究

# #2.2.2 响应系统

一些组件和资源可以建模为排队系统，以便根据模型预测它们在不同情况下的性能。磁盘通常建模为排队系统，它可以预测响应时间在负载下如何降低。图 2.2 显示了一个简单的排队系统

# 2.3 概念

以下是系统性能的重要概念，是本章和本书其余部分的假定知识。在后面章节的 Architecture 部分中介绍特定于实现的详细信息之前，这些主题以通用方式进行描述

# #2.3.1 延迟

对于某些环境，延迟是性能的唯一关注点。对于其他人来说，它是分析的前一两个关键指标，还有吞吐量。作为延迟的一个示例，图 2.3 显示了网络传输，例如 HTTP GET 请求，时间分为延迟和数据传输部分

延迟是在执行作之前等待所花费的时间。在此示例中，该作是传输数据的网络服务请求。在执行此作之前，系统必须等待建立网络连接，这是此作的延迟。响应时间跨越此延迟和作时间。

由于可以从不同的位置测量延迟，因此它通常与测量目标一起表示。例如，网站的加载时间可能由从不同位置测量的三个不同时间组成：DNS 延迟、TCP 连接延迟，然后是 TCP 数据转移时间。DNS 延迟是指整个 DNS作。TCP 连接延迟仅指初始化（TCP 握手）。

在更高级别上，所有这些，包括 TCP 数据传输时间，都可以被视为其他事物的延迟。例如，从用户点击网站链接到结果页面完全加载的时间可以称为延迟，其中包括浏览器通过网络获取网页并呈现它的时间。由于单个词 “latency” 可能很大，因此最好包含限定词来解释它所衡量的内容：请求延迟、TCP 连接延迟等。

由于延迟是基于时间的指标，因此可以进行各种计算。性能问题可以使用延迟进行量化，然后进行排名，因为它们使用相同的单位 （时间） 表示。还可以通过考虑何时可以减少或消除延迟来计算预测的加速比。例如，使用 IOPS 指标无法准确执行这些作。

表2.1中列出了数量级的时间数量级及其缩写，以供参考。

如果可能，将其他指标类型转换为延迟或时间可以进行比较。如果您必须在 100 个网络 I/O 或 50 个磁盘 I/O 之间进行选择，您如何知道哪个性能更好？这是一个复杂的问题，涉及许多因素：网络跃点、网络功丢弃和重新传输的速率、I/O 大小、随机或顺序 I/O、磁盘类型等。但是，如果您比较 100 毫秒的总网络 I/O 和 50 毫秒的总磁盘 I/O，差异就很明显了

# #2.3.2 时间尺度
虽然时间可以通过数字进行比较，但对时间有直觉，并从不同来源获得对延迟的合理预期也会有所帮助。系统组件在截然不同的时间尺度（数量级）上运行，以至于很难掌握这些差异有多大。表 2.2 中提供了 delay 示例，从 3.5 GHz 处理器的 CPU 寄存器访问开始。为了演示我们正在使用的时间尺度的差异，该表显示了每个作可能花费的平均时间，缩放到一个假想的系统，其中 CPU 周期（在现实生活中为 0.3 ns（大约是十亿分之一秒的三分之一））需要一整秒。

如您所见，CPU 周期的时间尺度很小。光传播 0.5 m 所需的时间，也许是你的眼睛到这个页面的距离，大约是 1.7 ns。在同一时间内，现代 CPU 可能已经执行了 5 个 CPU 周期并处理了多条指令

有关 CPU 周期和延迟的更多信息，请参见第 6 章 “CPU”，有关磁盘 I/O 延迟的信息，请参见第 9 章 “磁盘”。包含的 Internet 延迟来自第 10 章 网络，其中有更多示例

# #2.3.3 权衡
您应该了解一些常见的性能权衡。图 2.4 显示了好/快/便宜的“二选一”权衡，以及为 IT 项目调整的术语。

许多 IT 项目选择按时且成本低廉，而性能则留待以后修复。当早期决策抑制提高性能时，例如选择和填充次优存储体系结构、使用实现效率低下的编程语言或作系统，或者选择缺乏全面性能分析工具的组件，则此选择可能会成为问题。

性能调优中常见的权衡是 CPU 和内存之间的权衡，因为内存可用于缓存结果，从而降低 CPU 使用率。在具有大量 CPU 的现代系统上，交易方式可能相反：CPU 时间可能用于压缩数据以减少内存使用

可调参数通常伴随着权衡。以下是几个示例：
文件系统记录大小（或块大小）：接近应用程序 I/O 大小的小记录大小对于随机 I/O 工作负载的性能会更好，并且可以在应用程序运行时更有效地使用文件系统缓存。较大的记录大小将改进流式处理工作负载，包括文件系统备份。
网络缓冲区大小：较小的缓冲区大小将减少每个连接的内存开销，从而有助于系统扩展。较大的大小将提高网络吞吐量。

在对系统进行更改时，请寻找这样的权衡

# #2.3.4 优化工作
在最靠近执行工作的位置进行性能优化时，效果最有效。对于由应用程序驱动的工作负载，这意味着在应用程序本身内。表 2.3 显示了一个具有调优可能性的示例软件堆栈。

通过在应用程序级别进行优化，您可以消除或减少数据库查询，并将性能提高一大倍（例如，20 倍）。降低到存储设备级别可能会消除或改进存储 I/O，但在执行更高级别的 OS 堆栈代码时已经缴纳了税款，因此这可能仅按百分比（例如，20%）提高最终应用程序性能。

在应用程序级别找到较大的性能优势还有另一个原因。当今的许多环境都以快速部署特性和功能为目标，推动软件每周或每天对生产环境进行更改。因此，应用程序开发和测试往往侧重于正确性，在生产部署之前几乎没有时间进行性能测量或优化。这些活动在性能出现问题时进行

虽然应用程序可以是最有效的优化级别，但它不一定是进行观察的最有效级别。从它们在 CPU 上花费的时间或它们执行的文件系统和磁盘 I/O 中，可以最好地理解慢速查询。这些可以从作系统工具中观察到

在许多环境（尤其是云计算）中，应用程序级别处于不断开发状态，每周或每天将软件更改推送到生产环境中。随着应用程序代码的更改，通常会发现巨大的性能优势，包括回归修复。在这些环境中，很容易忽视作系统的优化和作系统的可观察性。请记住，作系统性能分析还可以识别应用程序级问题，而不仅仅是作系统级问题，在某些情况下，这比单独从应用程序识别更容易。

# #2.3.5 适当的级别
不同的组织和环境对性能的要求不同。您可能已经加入了一个组织，在那里，分析比您以前见过的要深入得多，甚至知道这是可能的。或者，您可能会发现，在您的新工作场所中，您认为的基本分析被认为是高级的，并且以前从未进行过（好消息：唾手可得的果实！

这并不一定意味着有些组织做得对，有些组织做得错。它取决于性能专业知识的投资回报率 （ROI）。拥有大型数据中心或大型云环境的组织可能会聘请一个性能工程师团队来分析所有内容，包括内核内部和 CPU 性能计数器，并经常使用各种跟踪工具。他们还可以正式对性能进行建模，并为未来增长做出准确的预测。对于每年在计算上花费数百万的环境，很容易证明雇用这样一个性能团队是合理的，因为他们找到的胜利就是 ROI。计算支出适中的小型初创公司可能只会进行肤浅的检查，相信第三方监控解决方案会检查其性能并提供警报。

然而，正如第 1 章所述，系统性能不仅与成本有关：还与最终用户体验有关。初创公司可能会发现有必要投资于性能工程以改善网站或应用程序延迟。这里的投资回报率不一定是成本的降低，而是让客户比旧客户更满意。

最极端的环境包括证券交易所和高频交易者，在这些环境中，性能和延迟至关重要，可能需要付出大量的努力和费用。例如，纽约和伦敦交易所之间的跨大西洋电缆计划耗资 3 亿美元，以减少 6 毫秒的传输延迟 [Williams 11]

在进行性能分析时，适当性水平也会在决定何时停止分析时发挥作用。

# #2.3.6 合适停止分析
每当进行性能分析时，一个挑战是知道何时停止。有这么多工具，也有很多东西需要检查！

当我教表演课时（就像我最近又开始做的那样），我可以给我的学生一个有三个原因的表演问题，并发现一些学生在找到一个原因后停止，另一些学生在找到两个原因后停止，而另一些学生则找到三个原因。一些学生继续前进，试图找到导致性能问题的更多原因。谁做对了？在找到所有三个原因后说您应该停止可能很容易，但对于现实生活中的问题，您不知道原因的数量。

以下是您可以考虑停止分析的三种情况，并附有一些个人示例

当您解释了大部分性能问题时。Java 应用程序消耗的 CPU 是原来的三倍。我发现的第一个问题是异常堆栈消耗 CPU 的问题之一。然后，我量化了这些堆栈中的时间，发现它们仅占总 CPU 占用空间的 12%。如果这个数字接近 66%，我就可以停止分析——这 3 倍的减速就被考虑了。但在这种情况下，在 12% 时，我需要继续寻找

当潜在 ROI 低于分析成本时。我处理的一些性能问题每年可以带来数千万美元的胜利。对于这些，我可以证明花费数月自己的时间（工程成本）进行分析是合理的。其他性能胜利，例如对于微型微服务，可能以数百美元来衡量：甚至不值得一个小时的工程时间来分析它们。例外情况可能包括当我没有更好的公司时间时（这在实践中从未发生过），或者我怀疑这可能是以后更大问题的金丝雀，因此值得在问题发展之前进行调试。

当其他地方有更大的 ROI 时。即使前两种情况没有得到满足，其他地方也可能有更大的 ROI 优先。

如果您是一名全职性能工程师，那么根据潜在投资回报率确定不同问题分析的优先级可能是一项日常任务。

# #2.3.7 推荐时间点
由于增加了更多用户、更新的硬件以及更新的软件或固件，环境的性能特征会随着时间的推移而变化。当前受 10 Gbit/s 网络基础设施限制的环境在升级到 100 Gbits/s 后可能会开始遇到磁盘或 CPU 性能瓶颈

性能建议（尤其是可调参数的值）仅在特定时间点有效。性能专家在一周内提供的最佳建议可能在一周后在软件或硬件升级后或添加更多用户后失效。在某些情况下，通过在 Internet 上搜索找到的可调参数值可以快速获胜。如果它们不适合您的系统或工作负载，曾经适合但现在不适用，或者仅适合作为软件错误的临时解决方法，并在以后的软件升级中正确修复，则它们也会降低性能。这类似于突袭别人的药柜，服用可能不适合您的药物，可能已经过期，或者应该只短期服用

浏览此类建议只是为了查看哪些可调参数存在以及过去需要更改哪些参数可能很有用。然后，您的任务是查看是否以及如何针对您的系统和工作负载调整这些。但是，如果其他人之前不需要调整该参数，或者已经调整了该参数但尚未在任何地方分享他们的经验，则您可能仍然会错过该参数。

更改可调参数时，将它们存储在具有详细历史记录的版本控制系统中可能会有所帮助。（在使用配置管理工具（如 Puppet、Salt、Chef 等）时，您可能已经执行了类似的作。这样，以后就可以检查更改 tunables 的时间和原因。

# #2.3.8 负载与架构
由于运行应用程序的软件配置和硬件（其体系结构和实现）存在问题，应用程序可能会性能不佳。但是，应用程序也可能仅仅由于应用的负载过多而性能不佳，从而导致排队和长时间延迟。负载和架构如图 2.5 所示

如果对架构的分析显示工作排队，但工作的形式没有问题，则问题可能是应用了太多负载。在云计算环境中，这是可以按需引入更多服务器实例来处理工作的点。
 
例如，体系结构问题可能是单线程应用程序在 CPU 上繁忙，当其他 CPU 可用且空闲时，请求排队。在这种情况下，性能为受应用程序的单线程体系结构的限制。体系结构的另一个问题可能是争夺单个锁的多线程程序，这样只有一个线程可以向前推进，而其他线程可以等待。

负载问题可能是多线程应用程序在所有可用 CPU 上都处于繁忙状态，请求仍在排队。在这种情况下，性能受到可用 CPU 容量的限制，或者换句话说，由于负载超出 CPU 的处理能力

# #2.3.9 可拓展性
系统在负载增加下的性能是其可扩展性。图 2.6 显示了系统负载增加时的典型吞吐量配置文件。

在一段时间内，观察到线性可扩展性。然后到达一个点，用虚线标记，对资源的争用开始降低吞吐量。这个点可以被描述为拐点，因为它是两个函数之间的边界。超过此点后，随着对资源的争用增加，吞吐量配置文件将偏离线性可扩展性。最终，增加争用和连贯性的开销会导致完成的工作量减少，而吞吐量减少。

当组件达到 100% 利用率时，可能会出现此点：饱和点。当组件接近 100% 利用率并且排队开始频繁且重要时，也可能发生这种情况

可能显示此配置文件的示例系统是执行繁重计算的应用程序，其中添加了更多负载作为附加线程。当 CPU 接近 100% 利用率时，响应时间会随着 CPU 调度程序延迟的增加而开始下降。在达到峰值性能后，在 100% 利用率时，吞吐量会随着添加更多线程而开始下降，从而导致更多的文本切换，从而消耗 CPU 资源并导致完成的实际工作减少。

如果将 x 轴上的“load”替换为 CPU 内核等资源，则可以看到相同的曲线。有关此主题的更多信息，请参见部分 2.6， 建模

非线性可扩展性的性能下降，以平均响应时间或延迟而言，如图 2.7 所示 [Cockcroft 95]

当然，较高的响应时间是坏事。当系统开始将内存页移动到磁盘以释放主内存时，内存负载可能会出现“快速”降级配置文件。CPU 负载可能会出现“慢速”降级配置文件。

另一个 “快速” 配置文件示例是磁盘 I/O。随着负载（以及由此产生的磁盘利用率）的增加，I/O 更有可能排在其他 I/O 之后。空闲旋转（非固态）磁盘的响应时间约为 1 毫秒，但当负载增加时，响应时间可能接近 10 毫秒。这在第 2.6.5 节 排队理论的 M/D/1 和 60% 利用率下进行了建模，磁盘性能在第 9 章 磁盘中介绍。

如果应用程序在资源不可用时开始返回错误，而不是将工作排队，则可能会出现响应时间的线性可扩展性。例如，Web 服务器可能会返回 503 “Service Unavailable” 而不是将请求添加到队列中，以便可以以一致的响应时间执行所服务的请求。

# #2.3.10 指标
性能指标是由系统、应用程序或测量相关活动的其他工具生成的选定统计数据。它们被研究用于性能分析和监控，无论是在命令行上以数字方式还是使用可视化方式以图形方式。

常见的系统性能指标类型包括：

■ 吞吐量：每秒作数或数据量 
■ IOPS：每秒 I/O作数 
■ 利用率：资源的繁忙程度（以百分比表示） 
■ 延迟：作时间（以平均值或百分位数表示）

吞吐量的使用情况取决于其上下文。数据库吞吐量通常是每秒查询或请求（作）的度量。网络吞吐量是每秒位数或字节数（卷）的度量。IOPS 是仅针对 I/O作（读取和写入）的吞吐量度量。同样，上下文很重要，定义可能会有所不同。

# 开销
性能指标不是免费的;在某些时候，必须花费 CPU 周期来收集和存储它们。这会导致开销，从而对测量目标的性能产生负面影响。这称为观察者效应。（它经常与海森堡的不确定性原理相混淆，海森堡的不确定性原理描述了可以知道物理属性对（例如位置和动量）的精度极限。

# 事件
您可能会假设软件供应商提供的指标经过精心挑选、无错误且提供完整的可见性。实际上，指标可能令人困惑、复杂、不可靠、不准确，甚至完全错误（由于错误）。有时，某个指标在一个软件版本中是正确的，但未更新以反映新代码和代码路径的添加。

有关指标问题的更多信息，请参阅第 4 章 “可观测性工具”， 部分 4.6， 观察可观测性。

# #2.3.11 利用

术语利用通常用于作系统，以描述设备使用情况，例如 CPU 和磁盘设备。利用率可以基于时间或基于容量

# 基于时间
基于时间的利用率在排队理论中正式定义。
例如，[Gunther 97]：服务器或资源繁忙的平均时间以及比率

U=B/T

其中 U = 利用率，B = 繁忙时间，T = 总时间

这也是作系统性能工具最容易获得的 “利用率”。磁盘监控工具 iostat（1） 将此度量 %b 称为 % busy，这个术语更好地表达了底层度量：B/T。

此利用率指标告诉我们组件的繁忙程度：当组件接近 100% 利用率时，当资源争用时，性能会严重下降。可以检查其他指标以确认并查看组件是否因此成为系统瓶颈。

某些组件可以并行为多个作提供服务。对于他们来说，在 100% 利用率时，性能可能不会下降太多，因为他们可以接受更多的工作。要理解这一点，请考虑建筑电梯。当它在楼层之间移动时，它可以被视为被利用，当它空闲等待时，它可能被视为被使用。但是，即使电梯在 100% 的时间里忙于响应呼叫，电梯也可能能够接受更多的乘客——也就是说，它的利用率为 100%。

100% 繁忙的磁盘也可能能够接受和处理更多工作，例如，通过增强磁盘缓存中的写入作，以便稍后完成。存储阵列经常以 100% 的利用率运行，因为某些磁盘在 100% 的时间内处于繁忙状态，但阵列有大量空闲磁盘，可以接受更多工作。

# 容量
IT 专业人员在容量规划的上下文中使用利用率的另一个定义 [Wong 97]：
系统或组件（如磁盘驱动器）能够提供一定量的吞吐量。在任何性能级别下，系统或组件都以其容量的一定比例工作。该比例称为利用率。

这根据容量而不是时间来定义利用率。这意味着利用率为 100% 的磁盘无法接受更多工作。对于基于时间的定义，100% 利用率仅意味着它在 100% 的时间里处于繁忙状态。

100% 繁忙并不意味着 100% 容量

以电梯为例，100% 容量可能意味着电梯处于其最大有效载荷能力，无法容纳更多乘客。

在理想情况下，我们将能够测量设备的这两种类型的利用率，例如，您将知道磁盘何时 100% 繁忙并且性能因争用而开始下降，以及何时处于 100% 容量且无法接受更多工作。不幸的是，这通常是不可能的。对于磁盘，它需要了解磁盘的板载控制器正在做什么并预测容量。磁盘当前不提供此信息。

在本书中，利用率通常是指基于时间的版本，您也可以将其称为非空闲时间。容量版本用于某些基于卷的指标，例如内存使用情况。

# #2.3.12 饱和
资源请求的工作量超过其处理能力的程度是饱和。饱和在 100% 利用率（基于容量）时开始出现，因为无法处理额外的工作并开始排队。如图 2.8 所示。

该图显示，随着负载的持续增加，饱和度在超过 100% 基于容量的利用率标记时呈线性增长。任何程度的饱和都是性能问题，因为等待时间（延迟）会花费在等待上。对于基于时间的利用率 （忙碌百分比），排队和因此的饱和度可能不会从 100% 利用率标记开始，具体取决于资源可以并行处理工作的程度。

# #2.3.13 分析
分析构建了可以研究和理解的目标图景。在计算性能领域，分析通常是通过以定时间隔对系统状态进行采样，然后研究样本集来执行的。
与前面涵盖的量度（包括 IOPS 和吞吐量）不同，使用采样提供了目标活动的粗略视图。
粗化程度取决于采样率作为性能分析的一个示例，通过频繁地对 CPU 指令指针或堆栈跟踪进行采样，以收集有关消耗 CPU 资源的代码路径的统计信息，可以合理地详细地了解 CPU 使用率。第 6 章 “CPU”中介绍了此主题。

# #2.3.14 缓存
缓存经常用于提高性能。缓存将较慢存储层的结果存储在较快的存储层中，以供参考。一个例子是在主内存 （RAM） 中缓存磁盘块。

可以使用多层缓存。CPU 通常对主内存（级别 1、2 和 3）使用多个硬件缓存，从非常快速但较小的缓存（级别 1）开始，然后存储大小和访问延迟都会增加。这是密度和延迟之间的经济权衡;选择级别和大小是为了在可用的片上空间中获得最佳性能。这些缓存在 第 6 章 CPU 中介绍。

系统中还有许多其他缓存，其中许多缓存是使用主内存进行存储的软件实现的。有关缓存层的列表，请参见第 3 章作系统， 第 3.2.11 节 缓存。

了解缓存性能的一个指标是每个缓存的命中率，即在缓存中找到所需数据的次数（命中数）与总访问量（命中未命中数）之比：

命中率 = 命中数 / （命中数未命中数）

比率越高越好，因为比率越高，反映从更快的媒体成功访问的数据越多。图 2.9 显示了提高缓存命中率的预期性能改进

98% 和 99% 之间的性能差异远大于 10% 和 11% 之间的性能差异。这是一个非线性配置文件，因为缓存命中和未命中之间的速度存在差异 - 两个存储层在起作用。差异越大，斜率越陡。

了解缓存性能的另一个指标是缓存未命中率，以每秒未命中数表示。这与每次未命中的性能损失成正比 （线性） ，并且更容易解释。

例如，工作负载 A 和 B 使用不同的算法执行相同的任务，并使用主内存缓存来避免从磁盘读取数据。工作负载 A 的缓存命中率为 90%，工作负载 B 的缓存命中率为 80%。仅此信息表明工作负载 A 的性能更好。如果工作负载 A 的未命中率为 200 / s，工作负载 B 为 20 / s ，该怎么办？从这些方面来看，工作负载 B 执行的磁盘读取次数减少了 10 倍，这可能比 A 更快地完成任务。可以肯定的是，每个工作负载的总运行时间可以计算为

运行时间 = （命中率 × 命中延迟）+（未命中率 × 未命中延迟）

此计算使用平均命中和未命中延迟，并假设工作是序列化的。

# 算法
缓存管理算法和策略确定在可用于缓存的有限空间中存储哪些内容。最近使用 （MRU） 是指缓存保留策略，它决定在缓存中保留哪些内容：最近使用的对象。最近最少使用 （LRU） 可以引用等效的缓存驱逐策略，用于决定在需要更多空间时要从缓存中删除哪些对象。此外，还有最常用 （MFU） 和最不常用 （LFU） 策略。您可能会遇到不常用 （NFU），这可能是 LRU 的廉价但不太彻底的版本

# 热缓存、冷缓存和暖缓存
这些词通常用于描述缓存的状态

冷：冷缓存为空，或填充了不需要的数据。冷缓存的命中率为零（或在开始预热时接近零）。
暖缓存：暖缓存是填充了有用数据但命中率不够高的缓存，无法被视为热缓存。
热缓存：热缓存中填充了经常请求的数据，并且具有较高的命中率，例如超过 99%。
Warmth：缓存温暖描述缓存的热度或冷度。提高缓存热度的 Activity 旨在提高缓存命中率的 Activity。

首次初始化缓存时，它们会开始冷缓存，然后随着时间的推移而预热。当高速缓存很大或下一级存储很慢（或两者兼而有之）时，高速缓存可能需要很长时间才能变为 popu lated 和 warm

例如，我在一个存储设备上工作，该设备有 128 GB 的 DRAM 作为文件系统缓存，600 GB 的闪存作为二级缓存，还有用于存储的旋转磁盘。对于随机读取工作负载，磁盘每秒提供大约 2000 次读取。对于 8 KB 的 I/O 大小，这意味着高速缓存的预热速率仅为 16 MB/s（2,000 × 8 KB）。当两个缓存都开始冷时，DRAM 缓存需要 2 个多小时才能预热，闪存缓存需要 10 多个小时才能预热。

# #2.3.15 可知与未知
在前言中介绍了已知-已知、已知-未知和未知-未知的概念对于性能领域很重要。细分如下，并附有系统性能分析的示例：

已知已知：这些是您知道的事情。您知道您应该检查性能指标，并且您知道其当前值。例如，您知道应该检查 CPU 利用率，并且您还知道该值平均为 10%。

已知未知：这些是你知道但不知道的事情。您知道可以检查指标或子系统是否存在，但尚未观察到它。例如，您知道可以使用性能分析来检查是什么导致 CPU 繁忙，但尚未这样做。

未知 - 未知：这些是您不知道的事情。例如，您可能不知道设备中断可能会成为 CPU 消耗者，因此您没有检查它们

性能是一个“你知道的越多，你不知道的就越多”的领域。您对系统了解得越多，您了解的未知数就越多，然后是您可以检查的已知未知数。。

# 2.4 各自
效果分析有两种常见的视角，每种视角都有不同的受众、量度和方法。它们是工作负载分析和资源分析。它们可以被认为是对作系统软件堆栈的自上而下或自下而上的分析，如图 2.10 所示

第 2.5 节 方法提供了应用每种方法的具体策略。这里将更详细地介绍这些观点。

# #2.4.1 资源分析
资源分析从分析系统资源开始：CPU、内存、磁盘、网络接口、总线和互连。它很可能由系统管理员（负责物理资源的人员）执行。活动包括

性能问题调查：查看特定类型的资源是否负责
容量规划：用于帮助调整新系统大小的信息，以及查看现有系统资源何时可能耗尽

此视角侧重于利用率，以确定资源何时达到或接近其限制。某些资源类型（如 CPU）具有现成的利用率指标。可以根据可用指标估计其他资源的利用率，例如，通过将每秒发送和接收兆位 （吞吐量） 与已知或预期的最大带宽进行比较来估计网络接口利用率。

最适合资源分析的指标包括

IOPS
吞吐量
利用率
饱和度

这些指标衡量资源被要求做什么，以及它对给定负载的利用率或饱和度。其他类型的指标（包括延迟）也可用于查看资源对给定工作负载的响应情况。

资源分析是一种常见的性能分析方法，部分归功于有关该主题的广泛可用的文档。此类文档侧重于作系统的 “stat” 工具：vmstat（8）、iostat（1）、mpstat（1）。当您阅读此类文档时，请务必了解这是一个视角，但不是唯一视角。

# #2.4.2 工作负载分析
工作负载分析（参见图 2.11）检查应用程序的性能：应用的工作负载以及应用程序的响应方式。它最常由应用程序开发人员和支持人员（负责应用程序软件和配置的人员）使用。

工作负载分析的目标是： 
■ 请求数：应用的工作负载 
■ 延迟：应用程序的响应时间
■ 完成度：查找错误

研究工作负载请求通常涉及检查和总结它们的属性：这是工作负载特征化的过程（在第 2.5 节 方法中有更详细的描述）。对于数据库，这些属性可能包括客户端主机、数据库名称、表和查询字符串。此数据可能有助于识别不必要的工作或不平衡的工作。即使系统很好地执行了其当前的工作负载 （低延迟），检查这些属性也可以确定减少或消除所应用工作的方法。请记住，最快的查询是您根本不执行的查询。

延迟 （响应时间） 是表示应用程序性能的最重要指标。对于 MySQL 数据库，它是查询延迟;对于 Apache，它是 HTTP 请求延迟;等等。在这些上下文中，术语 延迟 的含义与响应时间相同（有关上下文的更多信息，请参阅第 2.3.1 节 延迟）

工作负载分析的任务包括识别和确认问题（例如，查找超出可接受阈值的延迟），然后查找延迟的来源并确认在应用修复后延迟得到改善。请注意，起点是应用程序。调查延迟通常涉及更深入地了解应用程序、库和作系统（内核）。

通过研究与事件完成相关的特征（包括其错误状态），可以识别系统问题。虽然请求可能会快速完成，但它可能会以错误状态完成，从而导致请求被重试，从而累积延迟

最适合工作负载分析的指标包括： 
■ 吞吐量（每秒事务数） 
■ 延迟 这些指标衡量请求速率和最终性能。

# 2.5 方法论
当面对性能不佳且复杂的系统环境时，第一个挑战可能是知道从何处开始分析以及如何进行。正如我在第 1 章中所说，性能问题可能来自任何地方，包括软件、硬件和数据路径上的任何组件。方法可以通过显示从何处开始分析并建议要遵循的有效程序来帮助您处理这些复杂的系统。

本节介绍了许多用于系统性能和调优的性能方法和过程，其中一些是我开发的。这些方法可帮助初学者入门，并作为专家的提醒。一些反方法论也被包括在内。

为了帮助总结它们的作用，这些方法被分为不同的类型，例如观察分析和实验分析，如表 2.4 所示

性能监控、排队理论和容量规划将在本节的后面部分介绍。其他章节还在不同上下文中重新构建了其中一些方法，并为性能分析的特定目标提供了一些额外的方法。表 2.5 列出了这些其他方法。

以下部分从常用但较弱的比较方法开始，包括反方法。对于性能问题的分析，您应该尝试的第一个方法是问题陈述方法，然后再转向其他方法。

# #2.5.1 路灯反证法
这种方法实际上是缺乏一种深思熟虑的方法。用户通过选择熟悉的、在 Internet 上找到的或随机的可观测性工具来分析性能，以查看是否显示任何明显的内容。这种方法是偶然的，可能会忽略许多类型的问题。

可以以类似的试错方式尝试调整性能，将任何已知和熟悉的可调参数设置为不同的值，看看是否有帮助

即使此方法揭示了问题，它也可能会很慢，因为会发现并尝试与问题无关的工具或调整，只是因为它们很熟悉。因此，这种方法以一种称为路灯效应的观察偏差命名，由这个比喻说明：

一天晚上，一名警察看到一个醉汉在路灯下的地面上搜索，问他在找什么。醉汉说他丢了钥匙。警察也找不到他们，问道：“你确定你把他们丢在这里，在路灯下吗？“醉汉回答说：”没有，但这是光线最好的地方。

性能等效的将是查看 top（1），不是因为它有意义，而是因为用户不知道如何阅读其他工具。

此方法确实发现的问题可能是一个问题，但不是问题。其他方法对结果进行量化，以便更快地排除假阳性，并优先考虑更大的问题。

# #2.5.2 随机变化反方法
这是一种实验性的反方法论。用户随机猜测问题可能出在哪里，然后进行更改，直到问题消失。为了确定每次更改是否提高了性能，需要研究一个指标，例如应用程序运行时、作时间、延迟、作速率（每秒作数）或吞吐量（每秒字节数）。方法如下
1. 选择要更改的随机项目（例如，可调参数）。
2. 朝一个方向改变它。
3. 衡量绩效。
4. 向另一个方向改变它。
5. 衡量绩效。
6. 第 3 步或第 5 步的结果是否优于基线？如果是这样，请保留更改并返回步骤 1。

虽然此过程最终可能会发现适用于测试工作负载的优化，但它非常耗时，并且还可能导致从长远来看没有意义的优化。对于示例，应用程序更改可能会提高性能，因为它可以解决稍后修复的数据库或作系统错误。但是应用程序仍然会有那个不再有意义的调优，而且一开始没有人能正确理解。

另一个风险是，未正确理解的更改在高峰生产负载期间会导致更严重的问题，并且需要撤回更改。

# #2.5.3 Blame-Someone-Else 反方法
这种反方法遵循以下步骤： 
1. 找到您不负责的系统或环境组件。
2. 假设问题出在该组件上。
3. 将问题重定向到负责该组件的团队。
4. 当证明错误时，返回步骤 1。“也许是网络。您能否与网络团队核实他们是否丢弃了数据包或其他情况？

这种方法的用户不是调查性能问题，而是让他们成为别人的问题，这可能会浪费其他团队的资源，而事实证明这毕竟不是他们的问题。这种反方法可以通过缺乏导致假设的数据来识别。

为避免成为 blame-someone-else（责怪他人）的受害者，请向指控者索取屏幕截图，显示运行了哪些工具以及如何解释输出。您可以将这些屏幕截图和解释提供给其他人以获得第二意见

# #2.5.4 Ad Hoc Checklist 方法
逐步完成固定清单是支持专业人员在被要求检查和调整系统时使用的一种常用方法，通常是在短时间内。一个典型的场景包括在生产环境中部署新的服务器或应用程序，并且支持专业人员会花半天时间检查系统处于实际负载下的常见问题。这些清单是临时的，是根据该系统类型的近期经验和问题构建的。

这是一个示例清单条目
运行 iostat –x 1 并检查 r_await 列。如果在加载期间始终超过 10 （ms），则磁盘读取速度较慢或磁盘过载

一个清单可能由十几张这样的检查组成。
虽然这些核对表可以在最短的时间内提供最大的价值，但它们是时间点建议（请参阅 部分 2.3， 概念），需要经常刷新以保持最新状态。他们还倾向于关注存在可以轻松记录的已知修复程序的问题，例如可调参数的设置，但不关注源代码或环境的自定义修复。

如果您正在管理一个支持专业人员团队，则临时清单可能是确保每个人都知道如何检查常见问题的有效方法。可以编写一个清晰和规范性的清单，显示如何识别每个问题以及解决方法是什么。但请记住，此列表必须不断更新。

# #2.5.5 问题陈述
定义问题陈述是支持人员在首次响应问题时的一项例行任务。这是通过向客户询问以下问题来完成的：
1. 是什么让您认为存在性能问题？
2. 这个系统曾经表现良好吗？
3. 最近有什么变化？软件？硬件？负荷？
4. 问题可以用延迟或运行时来表示吗？
5. 问题是否影响其他人或应用程序（或者仅影响您）？
6. 环境如何？使用哪些软件和硬件？版本？配置？

仅仅提出和回答这些问题通常指向直接的原因和解决方案。因此，问题陈述已作为其自己的方法包含在此处，并且应该是您在处理新问题时使用的第一种方法

我通过电话单独使用问题陈述方法解决了性能问题，而无需登录任何服务器或查看任何指标。

# #2.5.6 科学方法
科学方法通过提出假设然后对其进行测试来研究未知。它可以归纳为以下步骤：
1. 问题 
2. 假设 
3. 预测 
4. 测试 
5. 分析

问题是性能问题陈述。由此，您可以假设性能不佳的原因可能是什么。然后，您构建一个检验，该检验可能是观察性的或实验性的，用于检验基于假设的预测。完成对收集的测试数据的分析

例如，您可能会发现，在迁移到主内存较少的系统后，应用程序性能会下降，并且您假设性能不佳的原因是文件系统缓存较小。您可以使用观察测试来测量两者的缓存未命中率系统，预测较小系统上的缓存未命中率会更高。一个实验测试是增加缓存大小（添加 RAM），预测性能会提高。另一个可能更简单的实验测试是人为地减小缓存大小（使用可调参数），预测性能会更差。

以下是一些更多示例

示例 （观察）
1. 问题：是什么导致数据库查询缓慢？
2. 假设：嘈杂的邻居（其他云计算租户）正在执行磁盘 I/O，与数据库磁盘 I/O 竞争（通过文件系统）。
3. 预测：如果在查询过程中测量文件系统 I/O 延迟，则表明文件系统是导致查询缓慢的原因。
4. 测试：将数据库文件系统延迟与查询延迟的比率进行跟踪，表明等待文件系统所花费的时间不到 5%。
5. 分析：文件系统和磁盘不负责慢查询。

尽管问题仍未解决，但已排除环境的一些主要组成部分。执行此调查的人员可以返回到步骤 2 并提出新的假设

示例（实验性）
1. 问题：为什么 HTTP 请求从主机 A 到主机 C 的时间比从主机 B 到主机 C 的时间长？
2. 假设：主机 A 和主机 B 位于不同的数据中心。
3. 预测：将主机 A 移动到与主机 B 相同的数据中心将解决问题。
4. 测试：移动主机 A 并测量性能。5. 分析：性能已固定 — 与假设一致。

如果问题没有解决，请在开始新的假设之前反转实验性更改（在本例中为将主机 A 移回去）——一次更改多个因素会更难确定哪个因素重要！

示例（实验性）
1. 问题：为什么文件系统性能会随着文件系统缓存大小的增加而下降？
2. 假设：较大的缓存存储更多的记录，并且管理较大的缓存比较小的缓存需要更多的计算。
3. 预测：使记录大小逐渐变小，从而导致使用更多记录来存储相同数量的数据，这将使性能逐渐变差。
4. 测试：使用逐渐变小的记录大小测试相同的工作负载。
5. 分析：结果以图形形式显示，并且与预测一致。现在对缓存管理例程执行向下钻取分析。

这是一个否定测试的示例 - 故意损害性能以了解有关目标系统的更多信息。

# #2.5.7 诊断周期
与科学方法类似的是诊断周期： 

假设 → 工具→数据 → 假设 

与科学方法一样，这种方法也通过数据的收集来刻意检验假设。该周期强调数据可以快速导致新的假设，该假设经过测试和优化，依此类推。这类似于医生进行一系列小测试来诊断患者，并根据每次测试的结果完善假设。这两种方法在理论和数据之间都有很好的平衡。尝试快速从假设 sis 转化为数据，以便及早发现并丢弃不良理论，并开发更好的理论

# #2.5.8 工具方法
面向工具的方法如下：
1. 列出可用的性能工具（可选，安装或购买更多）。
2. 对于每个工具，列出它提供的有用指标。
3. 对于每个指标，列出可能的解释方法。

其结果是一个规范性的清单，显示要运行哪个工具、要读取哪些指标以及如何解释它们。虽然这可能相当有效，但它完全依赖于可用（或已知）工具，这些工具可能会提供不完整的系统视图，类似于路灯反方法。更糟糕的是，用户没有意识到他们有一个不完整的视图，并且可能仍然不知道。需要自定义工具的问题（例如，动态跟踪）可能永远无法识别和解决。

在实践中，工具方法确实可以识别某些资源瓶颈、错误和其他类型的问题，尽管它可能无法有效地做到这一点。

当有大量工具和指标可用时，迭代它们可能非常耗时。当多个工具似乎具有相同的功能并且您花费额外的时间来尝试了解每个工具的优缺点时，情况会变得更糟。在某些情况下，例如文件系统微基准测试工具，有十几种工具可供选择，而您可能只需要一种。

# #2.5.9 USE方法
在性能调查的早期，应使用利用率、饱和度和错误 （USE） 方法来识别系统瓶颈 [Gregg 13b]。它是一种侧重于系统资源的方法，可以概括为：

对于每个资源，请检查 utilization（利用）、saturation（饱和度）和 errors（错误）。

这些术语定义如下：
■ 资源：所有物理服务器功能组件（CPU、总线等）。如果指标有意义，还可以检查一些软件资源。
■ 利用率：在设定的时间间隔内，资源忙于处理工作的时间百分比。在忙碌时，资源可能仍能够接受更多工作;它不能这样做的程度由饱和度来确定。
■ 饱和度：资源无法服务的额外工作的程度，通常在队列中等待。另一个术语是压力。
■ Errors：错误事件的计数。

对于某些资源类型（包括主内存），利用率是所用资源的容量。这与基于时间的定义不同，前面在 Section 2.3.11， Utilization.一旦容量资源达到 100% 利用率，就无法接受更多工作，并且资源要么将工作排队（饱和），要么返回错误，这些错误也可以使用 USE 方法识别

应该调查错误，因为它们会降低性能，但当故障模式可恢复时，可能不会立即注意到它们。这包括失败并重试的作，以及在冗余设备池中失败的设备。

与 tools 方法相比，USE 方法涉及迭代系统资源而不是工具。这可以帮助您创建要询问的问题的完整列表，然后您才搜索回答这些问题的工具。即使找不到回答某些问题的工具，知道这些问题没有答案对性能分析师来说也非常有用：它们现在是“已知的未知数”。

USE 方法还将分析定向到有限数量的关键指标，以便尽快检查所有系统资源。在此之后，如果未发现问题，则可以使用其他方法。

# 程序
USE 方法如图 2.12 中的流程图所示。首先检查错误，因为它们通常很容易解释（它们通常是客观的指标，而不是主观的指标），并且在调查其他指标之前排除错误可以节省时间。其次检查 Saturation，因为它比 utilization 更快地解释：任何级别的饱和度都可能是一个问题。

此方法可识别可能成为系统瓶颈的问题。不幸的是，一个系统可能遇到不止一个性能问题，因此您首先发现的可能是一个问题，但不是问题。每个发现都可以使用进一步的方法进行研究，然后根据需要返回到 USE 方法以迭代更多资源。

# 表达指标
USE 方法指标通常表示如下：
■ 利用率：以时间间隔内的百分比表示（例如，“一个 CPU 以 90% 的利用率运行”） 
■ 饱和度：作为等待队列长度（例如，“CPU 的平均运行队列长度为 4”） 
■ 错误：报告的错误数（例如，“此磁盘驱动器有 50 个错误”）

尽管这似乎有悖常理，但短暂的高利用率爆发可能会导致饱和和性能问题，即使总体利用率在很长的时间间隔内较低。一些监控工具报告超过 5 分钟平均值的利用率。例如，CPU 利用率在每一秒之间可能会有很大差异，因此 5 分钟的平均值可能会掩盖 100% 利用率的短时间，因此会达到饱和

考虑高速公路上的收费广场。利用率可以定义为忙于为汽车提供服务的收费站数量。利用率为 100% 意味着您找不到空展位，必须在某人后面排队（饱和度）。如果我告诉你，这些摊位全天的利用率为 40%，你能告诉我那天是否有任何汽车在排队吗？他们可能在高峰时段这样做，当时利用率为 100%，但这在每日平均值中不可见。

# 资源列表
USE 方法的第一步是创建资源列表。尽量完整。以下是服务器硬件资源的通用列表以及具体示例： 
■ CPU：插槽、内核、硬件线程（虚拟 CPU） 
■ 主内存：DRAM 
■ 网络接口：以太网端口、Infiniband
■ 存储设备：磁盘、存储适配器 
■ 加速器：GPU、TPU、FPGA 等，如果使用 
■ 控制器：存储、网络 
■ 互连：CPU、内存、I/O

每个组件通常充当单个资源类型。例如，主内存是容量资源，网络接口是 I/O 资源（可能意味着 IOPS 或吞吐量）。某些组件可以表现为多种资源类型：例如，存储设备既是 I/O 资源又是容量资源。考虑所有可能导致性能瓶颈的类型。另请注意，I/O 资源可以作为排队系统进一步研究，该系统对这些请求进行排队，然后为这些请求提供服务。

某些物理组件，例如硬件缓存（例如 CPU 缓存），可以排除在检查清单之外。USE 方法对于在高利用率或饱和时性能下降并导致瓶颈的资源最有效，而缓存在高利用率下可以提高性能。这些可以使用其他方法进行检查。如果您不确定是否包含某个资源，请包含该资源，然后查看这些指标在实践中的运行情况。

# 功能框图
迭代资源的另一种方法是为系统查找或绘制功能框图，如图 2.13 所示。此类关系图还显示了关系，这在查找数据流中的瓶颈时非常有用。

CPU、内存以及 I/O 互连和总线经常被忽视。幸运的是，它们不是常见的系统瓶颈，因为它们通常旨在提供过多的吞吐量。不幸的是，如果是这样，问题可能很难解决。也许你可以升级主板，或者减少负载;例如，“Zero Copy” 软件技术可减轻 Memory Bus 负载。

要研究互连，请参见第 6 章 “CPU”， 部分 6.4.1， 硬件“中的”CPU 性能计数器”

# 指标
获得资源列表后，请考虑适合每个资源的指标类型：利用率、饱和度和错误。表 2.6 显示了一些示例资源和指标类型，以及可能的指标（通用作系统）。

这些指标可以是 averages per interval 或 counts。

对所有组合重复此作，并包含获取每个指标的说明。记下当前不可用的 met ric;这些是已知的未知数。您最终会得到一个包含大约 30 个指标的列表，其中一些指标难以衡量，而另一些指标则根本无法衡量。幸运的是，最常见的问题通常来自更简单的指标（例如，CPU 饱和度、内存容量饱和度、网络接口利用率、磁盘利用率），因此可以先检查这些指标。

表 2.7 中提供了一些更难的组合示例。

其中一些计数器可能无法从标准作系统工具中获得，并且可能需要使用动态跟踪或 CPU 性能监控计数器。

附录 A 是 Linux 系统的 USE 方法检查表示例，它使用 Linux 可观测性工具集迭代硬件资源的所有组合，并包含一些软件资源，例如下一节中描述的资源。

# 软件资源
一些软件资源可以进行类似的检查。这通常适用于软件的较小组件（而不是整个应用程序），例如：

■ 互斥锁：利用率可以定义为持有锁的时间，排队等待锁的线程的饱和。
■ 线程池：利用率可以定义为线程忙于处理工作的时间，饱和值由等待线程池服务的请求数定义。
■ 进程/线程容量：系统可能具有有限数量的进程或线程，其当前使用情况可以定义为利用率;等待分配可能是饱和的;错误是指分配失败（例如，“cannot fork”）。
■ 文件描述符容量：类似于进程/线程容量，但适用于文件描述符。

如果这些指标在您的情况下运行良好，请使用它们;否则，可以应用延迟分析等替代方法。

# 建议的解释
以下是解释量度类型的一些一般建议： 
■ 利用率：利用率为 100% 通常是瓶颈的标志（检查饱和度及其效果以确认）。利用率超过 60% 可能是一个问题，原因如下：根据间隔，它可以隐藏 100% 利用率的短暂突发。此外，某些资源（如硬盘（但不是 CPU））通常不能在作期间中断，即使对于优先级较高的工作也是如此。随着利用率的增加，排队延迟变得更加频繁和明显。请参阅 第 2.6.5 节， 排队理论 ，了解有关 60% 利用率的更多信息。
■ 饱和度：任何程度的饱和度（非零）都可能是一个问题。它可以衡量为等待队列的长度，也可以衡量为在队列上等待所花费的时间。
■ 错误：非零错误计数器值得调查，尤其是当它们在性能不佳的情况下增加时。

很容易解释负面情况：低利用率、无饱和度、无错误。这比听起来更有用 — 缩小调查范围可以帮助您在确定它可能不是资源问题后快速关注问题区域。这就是淘汰赛的过程

# 资源控制
在云计算和容器环境中，可能会实施软件资源控制来限制或限制共享一个系统的租户。这些可能会限制内存、CPU、磁盘 I/O 和网络 I/O。例如，Linux 容器使用 cgroups 来限制资源使用。这些资源限制中的每一个都可以使用 USE 方法进行检查，类似于检查物理资源

例如，“内存容量利用率”可以是租户的内存使用情况与其内存上限。“内存容量饱和”可以通过限制施加的分配错误或为该租户进行交换来看到，即使主机系统没有遇到内存压力也是如此。这些限制将在第 11 章 云计算中讨论。

# 微服务
微服务架构存在与资源指标过多类似的问题：每个服务可能有太多指标，以至于检查所有指标都很费力，并且它们可能会忽略尚不存在指标的区域。USE 方法也可以通过微服务解决这些问题。例如，对于典型的 Netflix 微服务，USE 指标为：
■ 利用率：整个实例集群的平均 CPU 利用率。
■ 饱和度：近似值是第 99 个延迟百分位数与平均延迟之间的差值（假设第 99 个百分位数是饱和度驱动的）。
■ 错误：请求错误。
这三个指标已经使用 Atlas 云范围监控工具 [Harrington 14] 针对 Netflix 的每个微服务进行了检查。
有一种专为服务设计的类似方法：RED 方法。

# #2.5.10 RED 方法
此方法的重点是服务，通常是微服务架构中的云服务。它从用户的角度确定了监控运行状况的三个指标，可以概括为 [Wilkie 18]

对于每项服务，请检查请求速率、错误和持续时间

这些指标包括： 
■ 请求速率：每秒的服务请求数 
■ 错误数：失败的请求数 
■ 持续时间：请求完成的时间（除了平均值外，还要考虑分配统计信息，例如每百分位数：请参阅第 2.8 节 统计信息）

您的任务是绘制微服务架构图，并确保为每个服务监控这三个指标。（分布式跟踪工具可能会为您提供此类图表。其优点与 USE 方法相似：RED 方法快速、易于遵循且全面。

RED 方法由 Tom Wilkie 创建，他还使用 Grafana [Wilkie 18] 为带有仪表板的 Prometheus 开发了 USE 和 RED 方法指标的实现。这些方法是互补的：用于机器运行状况的 USE 方法和用于用户运行状况的 RED 方法。

包含请求速率在调查中提供了一个重要的早期线索：性能问题是负载还是架构问题（参见第 2.3.8 节 负载与架构）。如果请求速率一直稳定，但请求持续时间增加，则表明架构存在问题：服务本身。如果请求速率和持续时间都有所增加，则问题可能是应用的负载之一。这可以通过工作负载表征来进一步研究。

# #2.5.11 工作负载特征描述
工作负载特征描述是一种简单而有效的方法，用于识别一类问题：由于施加的负载而导致的问题。它侧重于系统的输入，而不是最终的性能。您的系统可能不存在架构、实现或配置问题，但遇到的负载超出了其合理处理能力

可以通过回答以下问题来描述工作负载的特征
■ 谁造成了负载？
■ 进程 ID、用户 ID、远程 IP 地址？
■ 为什么调用负载？
■ 代码路径、堆栈跟踪？
■ 负载特性是什么？
■ IOPS、吞吐量、方向（读/写）、类型？
■ 在适当的情况下包括方差（标准差）。
■ 负载如何随时间变化？有没有每日模式？

即使您对答案有强烈的期望，检查所有这些也可能很有用，因为您可能会感到惊讶。

请考虑以下场景：您的客户端是 Web 服务器池的数据库存在性能问题。您是否应该检查谁正在使用数据库的 IP 地址？根据配置，您已经希望它们是 Web 服务器。您仍然检查，发现整个 Internet 似乎都在向数据库施加负载，从而破坏了它们的性能。您实际上受到了拒绝服务 （DoS） 攻击！

最佳性能的胜利是消除不必要工作的结果。有时，不必要的工作是由应用程序故障引起的，例如，线程卡在循环中，从而产生不必要的 CPU 工作。它也可能是由错误的配置（例如，在高峰时段运行的系统范围备份）甚至是前面描述的 DoS 攻击引起的。描述工作负载的特征可以识别这些问题，并且通过维护或重新配置可以消除这些问题

如果无法消除已识别的工作负载，另一种方法可能是使用系统资源控制来限制它。例如，系统备份任务可能会通过消耗 CPU 资源来压缩备份，然后消耗网络资源来传输备份，从而干扰生产数据库。可以使用资源控制（如果系统支持）来限制此 CPU 和网络使用率，以便备份运行得更慢，而不会损害数据库。

除了识别问题外，工作负载特征还可以输入到仿真基准的设计中。如果工作负载度量是平均值，则理想情况下，您还将收集分布和变化的详细信息。这对于模拟预期的各种工作负载非常重要，而不是仅测试平均工作负载。有关平均值和变化（标准差）的更多信息，请参见第 2.8 节 统计 和第 12 章 基准测试。

工作负载分析还有助于通过识别前者来区分负载问题和架构问题。负载与架构在 第 2.3.8 节 负载与架构 中介绍

用于执行工作负载特征分析的特定工具和指标取决于目标。某些应用程序会记录客户端活动的详细日志，这些日志可以作为统计分析的来源。他们也可能已经提供客户使用情况的每日或每月报告，可以挖掘详细信息

# #2.5.12 向下钻取方法
向下钻取分析从高层次地检查问题开始，然后根据以前的发现缩小关注范围，丢弃看起来不有趣的领域，并更深入地挖掘有趣的领域。该过程可能涉及深入挖掘软件堆栈的更深层次，如有必要，还可以深入到硬件，以找到问题的根本原因
以下是系统性能的三阶段向下钻取分析方法 [McDougall 06a]： 
1. 监控：这用于持续记录一段时间内的高级统计数据，并在可能存在问题时识别或发出警报。
2. 识别：给定可疑问题，这会将调查范围缩小到特定的资源或感兴趣的领域，从而识别可能的瓶颈。
3. 分析：对特定系统区域进行进一步检查，以尝试找出根本原因并量化问题。

可以在公司范围内执行监控，并汇总所有服务器或云实例的结果。实现此目的的一项历史技术是简单网络监控协议 （SNMP），它可用于监控支持它的任何网络连接设备。现代监控系统使用导出器：在每个系统上运行的软件代理来收集和发布指标。生成的数据由监控系统记录，并由前端 GUI 可视化。这可能会揭示在短时间内使用命令行工具时可能会错过的长期模式。许多监控解决方案在怀疑问题时提供警报，促使分析进入下一阶段。

通过直接分析服务器并检查系统组件（CPU、磁盘、内存等）来执行识别。过去，它一直使用命令行工具（如 vmstat（8）、iostat（1） 和 mpstat（1））来执行。如今，有许多 GUI 控制面板公开相同的指标，以便更快地进行分析

分析工具包括基于追踪或剖析的分析工具，用于对可疑区域进行更深入的检查。这种更深入的分析可能涉及创建自定义工具和检查源代码（如果可用）。这是大多数深入研究发生的地方，根据需要剥离软件堆栈的层以找到根本原因。在 Linux 上执行此作的工具包括 strace（1）、perf（1）、BCC 工具、bpftrace 和 Ftrace。

作为这种三阶段方法的示例实施，以下是用于 Netflix 云的技术： 
1. 监控：Netflix Atlas：一个开源的云范围监控平台 [Harrington 14]。
2. 识别：Netflix perfdash（正式名称为 Netflix Vector）：一个用于分析带有仪表板的单个实例的 GUI，包括 USE 方法指标。
3. 分析：Netflix FlameCommander，用于生成不同类型的火焰图;以及命令行工具，包括基于 Ftrace 的工具、BCC 工具和 bpftrace。

作为我们在 Netflix 如何使用此序列的一个例子：Atlas 可以识别一个有问题的微服务，然后 perfdash 可以将问题缩小到一个资源，然后 FlameCommander显示了使用该资源的代码路径，然后可以使用 BCC 工具和自定义 bpftrace 工具对其进行检测。

# 五个为什么
在向下钻取分析阶段，您可以使用的另一种方法是五个为什么技术 [维基百科 20]：问自己“为什么”，然后回答问题，然后总共重复五次（或更多）。下面是一个示例过程：
1. 数据库的许多查询开始表现不佳。为什么？
2. 由于内存分页，它被磁盘 I/O 延迟。为什么？
3. 数据库内存使用量增长过大。为什么？
4. 分配器消耗的内存超过应有的内存。为什么？
5. 分配器存在内存碎片问题
这是一个真实示例，意外地导致了系统内存分配库中的修复。正是不断的质疑和深入研究核心问题导致了修复。

# #2.5.13 延迟分析
延迟分析检查完成作所花费的时间，然后将其分解为更小的组件，继续细分延迟最高的组件，以便识别和量化根本原因。与向下钻取分析类似，延迟分析可能会向下钻取软件堆栈的各个层，以查找延迟问题的根源。

分析可以从应用的工作负载开始，检查该工作负载在应用程序中的处理方式，然后向下钻取到作系统库、系统调用、内核和设备驱动程序。

例如，对 MySQL 查询延迟的分析可能涉及回答以下问题（此处给出了示例答案）：
1. 是否存在查询延迟问题？（是）
2. 查询时间主要花在 CPU 上还是在 CPU 外等待？（CPU 关闭）
3. 等待 CPU 超时的时间是多少？（文件系统 I/O）
4. 文件系统 I/O 时间是由于磁盘 I/O 还是锁争用造成的？（磁盘 I/O）
5. 磁盘 I/O 时间是否主要用于排队或为 I/O 提供服务？（维修）
6. 磁盘服务时间主要是 I/O 初始化还是数据传输？（数据传输）

对于此示例，该过程的每个步骤都提出了一个问题，该问题将延迟分为两个部分，然后继续分析更大的部分：延迟的二进制搜索（如果您愿意）。该过程如图 2.14 所示

识别出 A 或 B 中较慢的一方后，会进一步将其拆分为 A 或 B，然后进行分析，依此类推。

数据库查询的延迟分析是方法 R 的目标

# #2.5.14 R方法
方法 R 是为 Oracle 数据库开发的一种性能分析方法，专注于根据 Oracle 跟踪事件 [Millsap 03] 查找延迟的来源。它被描述为“一种基于响应时间的性能改进方法，可为您的业务带来最大的经济价值”，并侧重于识别和量化查询期间花费的时间。虽然这用于数据库的研究，但它的方法可以应用于任何系统，这里值得一提，作为一种可能的研究途径。

# #2.5.15 事件追踪
系统通过处理离散事件来运行。这些包括 CPU 指令、磁盘 I/O 和其他磁盘命令、网络数据包、系统调用、库调用、应用程序事务、数据库查询等。性能分析通常研究这些事件的摘要，例如每秒作数、每秒字节数或平均延迟。有时，摘要中会丢失重要的细节，单独检查事件时，可以最好地理解这些事件。

网络故障排除通常需要使用 tcpdump（8） 等工具进行逐个数据包的检查。此示例将数据包汇总为单行文本：

# tcpdump -ni eth4 -ttt

tcpdump（8） 可以根据需要打印不同数量的信息（参见第 10 章 网络）。

块设备层的存储设备 I/O 可以使用 biosnoop（8） 来跟踪（基于 BCC/BPF）：

这个 biosnoop（8） 输出包括 I/O 完成时间 （TIME（s））、启动进程细节 （COMM， PID）、磁盘设备 （DISK）、I/O 类型 （T）、大小 （BYTES） 和 I/O 持续时间 （LAT（ms））。有关此工具的更多信息，请参见第 9 章 “磁盘”

系统调用层是跟踪的另一个常见位置。在 Linux 上，可以使用 strace（1） 和 perf（1） 的 trace 子命令来跟踪它（参见第 5 章 应用程序）。这些工具还具有打印时间戳的选项。

执行事件跟踪时，请查找以下信息： 
■ 输入：事件请求的所有属性：类型、方向、大小等 
■ 时间：开始时间、结束时间、延迟（差异） 
■ 结果：错误状态、事件结果（例如，成功传输大小）

有时，可以通过检查请求或结果的事件属性来了解性能问题。事件时间戳对于分析延迟特别有用，通常可以通过使用事件跟踪工具来包含。前面的 tcpdump（8） 输出包括 delta 时间戳，使用 -ttt 测量数据包之间的时间。

对先前事件的研究提供了更多信息。异常的高延迟事件（称为延迟异常值）可能是由以前的事件引起的，而不是事件本身。例如，队列尾部的事件可能具有高延迟，但是由之前排队的事件引起的，而不是由其自身的属性引起的。可以从跟踪的事件中识别出这种情况。

# #2.5.16 基线统计
环境通常使用监视解决方案来记录服务器性能指标，并将其可视化为折线图，时间位于 x 轴上（请参见部分 2.9 监视）。这些折线图可以显示指标最近是否发生了变化，如果有，则显示它现在有何不同，只需检查折线图中的更改即可。有时会添加额外的行以包含更多历史数据，例如历史平均值或简单的历史时间范围，以便与当前范围进行比较。例如，许多 Netflix 仪表板会绘制一条额外的线来显示相同的时间范围，但针对上周，因此可以直接将星期二下午 3 点的行为与上周二下午 3 点的行为进行比较

这些方法适用于已监控的指标和 GUI 来可视化它们。但是，命令行中还有更多系统指标和详细信息可能无法监控。您可能面临不熟悉的系统统计信息，并想知道它们对于服务器来说是否“正常”，或者它们是否是问题的证据

这不是一个新问题，而且在使用折线图的监控解决方案广泛使用之前，就有一种方法可以解决这个问题。它是基线统计信息的集合。这可能涉及在系统处于“正常”负载下时收集所有系统指标，并将其记录在文本文件或数据库中以供以后参考。基准软件可以是运行可观测性工具并收集其他源（/proc 文件的 cat（1））的 shell 脚本。基线中可以包含分析器和跟踪工具，提供比监控产品通常记录的更多的细节（但要小心这些工具的开销，以免干扰生产）。可以定期（每天）以及系统或应用程序更改之前和之后收集这些基线，以便分析性能差异。

如果未收集基线且无法进行监控，则某些可观测性工具（基于内核计数器的工具）可以显示自启动以来的摘要平均值，以便与当前活动进行比较。这很粗糙，但总比没有好

# #2.5.17 静态性能调优
静态性能调优侧重于配置的体系结构的问题。其他方法侧重于施加负载的性能：动态性能 [Elling 00]。当系统处于静止状态且未施加负载时，可以执行静态性能分析。

对于静态性能分析和调整，请逐步检查系统的所有组件并检查以下内容： 
■ 组件有意义吗？（过时、动力不足等）
■ 该配置对预期的工作负载有意义吗？
■ 组件是否自动配置为预期工作负载的最佳状态？
■ 组件是否遇到了错误，使其现在处于 degraded 状态？

以下是使用静态性能调整可能发现的一些问题示例： 
■ 网络接口协商：选择 1 Gbits/s 而不是 10 Gbit/s 
■ RAID 池中的磁盘出现故障 
■ 使用的作系统、应用程序或固件的旧版本  
■ 文件系统几乎已满（可能导致性能问题） 
■ 与工作负载 I/O 大小相比，文件系统记录大小不匹配 
■ 应用程序使用成本高昂的调试模式意外启用 
■ 服务器意外配置为网络路由器（启用 IP 转发） 
■ 服务器配置为使用来自远程数据中心而不是本地的资源（例如身份验证）

幸运的是，这些类型的问题很容易检查;难的是记住去做

# #2.5.18 缓存优化
应用程序和作系统可能会使用多个缓存来提高从应用程序到磁盘的 I/O 性能。有关完整列表，请参见第 3 章作系统， 第 3.2.11 节 缓存。以下是调整每个缓存级别的通用策略：
1. 目标是在堆栈中缓存尽可能高，更靠近执行工作的位置，从而减少缓存命中的作开销。此位置还应具有更多可用元数据，可用于改进缓存保留策略。
2. 检查缓存是否已启用并正常工作。
3. 检查缓存命中/未命中率和未命中率。
4. 如果缓存大小是动态的，请检查其当前大小。
5. 优化工作负载的缓存。此任务取决于可用的缓存可调参数。
6. 优化缓存的工作负载。这样做包括减少不必要的缓存使用者，从而为目标工作负载释放更多空间。

注意双重缓存，例如，两个不同的缓存占用主内存并两次缓存相同的数据。

此外，还要考虑每个级别的高速缓存优化的整体性能提升。调整 CPU Level 1 缓存可以节省纳秒级，因为缓存未命中可能由 Level 2 提供。但是，提高 CPU Level 3 缓存可以避免 DRAM 访问速度大大降低，并带来更大的整体性能提升。（这些 CPU 缓存在第 6 章 “CPU”中介绍。）

# #2.5.19 微基准测试
微基准测试测试简单工作负载和人工工作负载的性能。这与宏观基准测试（或行业基准测试）不同，后者通常旨在测试真实世界和自然工作负载。宏观基准测试是通过运行工作负载模拟来执行的，并且执行和理解可能会变得复杂。

由于因素较少，微观基准测试的执行和理解就不那么复杂。一个常用的微基准测试是 Linux iperf（1），它执行 TCP 吞吐量测试：这可以通过在生产工作负载期间检查 TCP 计数器来识别外部网络瓶颈（否则很难发现）

微基准测试可以由应用工作负载并测量其性能的微基准测试工具执行，也可以使用仅应用工作负载的负载生成器工具，将性能测量留给其他可观察性工具（示例负载生成器请参见 第 12 章 基准测试， 第 12.2.2 节 模拟）。这两种方法都很好，但使用微基准测试工具并使用其他工具仔细检查性能可能是最安全的。

微基准测试的一些示例目标，包括测试的第二个维度，是： 
■ 系统调用时间：对于 fork（2）、execve（2）、open（2）、read（2）、close（2） 
■ 文件系统读取：从缓存文件中，将读取大小从 1 字节更改为 1 MB 
■ 网络吞吐量：在 TCP 端点之间传输数据，用于不同的套接字缓冲区大小

微基准测试通常会尽快执行目标作，并测量完成大量此类作的时间。然后可以计算平均时间（平均时间 = 运行时间/作计数）。

后面的章节包括特定的微观基准测试方法，列出了要测试的目标和属性。第 12 章 基准测试中更详细地介绍了基准测试的主题。

# #2.5.20 性能诅咒
这是一种优化方法，它显示了如何最好地提高性能，并按从最高到最低的顺序列出可作的项目。是的：
1. 不要这样做。
2. 做，但不要再做一次。
3. 少做。
4. 稍后再做。
5. 趁他们不注意的时候做。
6. 同时进行。
7. 做得更便宜。

以下是每种情况的一些示例： 
1. 不要这样做：消除不必要的工作。
2. 执行，但不要再执行：缓存。
3. 减少作：将刷新、轮询或更新调整为不太频繁。
4. 稍后再做：回写缓存。
5. 趁他们不注意的时候做： 将工作安排在非高峰时段进行。
6. 并发执行：从单线程切换到多线程。
7. 更便宜地做事：购买更快的硬件

这是我最喜欢的方法之一，我从 Netflix 的 Scott Emmons 那里学到了。他将其归功于 Craig Hanson 和 Pat Crain（尽管我还没有找到已发表的参考资料）。

# 2.6 建模
系统的分析建模可用于各种目的，特别是可扩展性分析：研究性能如何随着负载或资源的增加而扩展。资源可以是硬件（例如 CPU 内核）或软件（进程或线程）

分析建模可以被认为是第三种类型的性能评估活动，与生产系统的可观察性（“测量”）和实验测试（“模拟”）[Jain 91] 并列。当至少执行以下两项活动时，可以最好地理解性能：分析建模和模拟，或模拟和测量

如果分析是针对现有系统的，则可以从测量开始：表征负载和由此产生的性能。如果系统还没有生产负载，则可以使用通过测试工作负载模拟的实验分析，或者为了测试超出生产中看到的工作负载。分析建模可用于预测性能，并且可以基于测量或模拟的结果

可扩展性分析可能会显示，由于资源限制，性能会在特定点线性停止扩展。这称为拐点：当一个函数切换到另一个函数时，在本例中，从线性缩放变为争用。查找这些点是否存在以及位置，可以将调查定向到抑制可伸缩性的性能问题，以便在生产中遇到这些问题之前进行修复

有关这些步骤的更多信息，请参见第 2.5.11 节 工作负载特征化 和 第 2.5.19 节 微基准测试。

# #2.6.1 企业与云
虽然建模使我们能够模拟大型企业系统，而无需花费任何费用，但大型环境的性能通常很复杂，难以准确建模。

借助云计算，任何规模的环境都可以短期租用，即基准测试的长度。无需创建数学模型来预测性能，而是可以描述、模拟工作负载，然后在不同规模的云上进行测试。一些发现，例如拐点，可能是相同的，但现在将基于测量数据而不是理论模型，并且通过测试真实环境，您可能会发现模型中未包含的限制器。

# #2.6.2 视觉识别
当可以通过实验收集到足够的结果时，将它们绘制为交付的性能与缩放参数可能会揭示一种模式。

图 2.15 显示了线程数扩展时应用程序的吞吐量。在八个线程周围似乎有一个拐点，那里的斜率发生了变化。现在可以对此进行调查，例如，通过查看应用程序和系统配置中任何值 8 左右的设置。

在本例中，系统是一个八核系统，每个内核有两个硬件线程。为了进一步确认这与 CPU 内核数量有关，可以调查和比较少于和超过 8 个线程的 CPU 影响（例如，IPC;参见第 6 章 CPU）。或者，这可以通过在具有不同内核计数的系统上重复缩放测试并确认拐点按预期移动来实验研究。

有许多可伸缩性配置文件需要查找，这些配置文件可以在不使用正式模型的情况下直观地识别。这些如图 2.16 所示。

对于其中每个维度，x 轴是可伸缩性维度，y 轴是结果性能（吞吐量、每秒事务数等）。模式是：

■ 线性可扩展性：性能随着资源的扩展而成比例地提高。这可能不会永远持续下去，而是可能是另一种可伸缩性模式的早期阶段。
■ 争用：架构的某些组件是共享的，只能串行使用，对这些共享资源的争用开始降低扩展的有效性。
■ 一致性：维护数据一致性（包括更改传播）的税收开始超过扩展的好处。
■ 拐点：在可伸缩性点遇到一个改变可伸缩性配置文件的因素。
■ 可伸缩性上限：达到硬限制。这可能是设备瓶颈，例如总线或互连达到最大吞吐量，或者是软件施加的限制（系统资源控制）。

虽然视觉识别既简单又有效，但您可以使用数学模型了解有关系统可扩展性的更多信息。模型可能会以意想不到的方式偏离数据，这对于调查可能很有用：要么模型有问题，因此您对系统的理解也存在问题，要么问题在于系统的实际可扩展性。接下来的部分介绍了 Amdahl 的可伸缩性定律、通用可伸缩性定律和排队理论

# #2.6.3 阿姆达尔可扩展性定律

该定律以计算机架构师 Gene Amdahl [Amdahl 67] 的名字命名，对系统可扩展性进行建模，考虑了无法并行扩展的工作负载的串行组件。它可用于研究 CPU、线程、工作负载等的扩展。

Amdahl 的可扩展性定律在早期的可扩展性配置文件中显示为争用，它描述了对串行资源或工作负载组件的争用。它可以定义为 [Gunther 97]

C（N） = N/（1 α（N – 1））

相对容量为 C（N），N 是扩展维度，例如 CPU 计数或用户负载。α 参数（其中 0 <= α <= 1）表示串行度，是它与线性可扩展性的偏差。可以通过采取以下步骤来应用阿姆达尔可扩展性定律：
1. 通过观察现有系统或使用微基准测试或负载生成器进行实验，收集 N 范围的数据。
2. 进行回归分析以确定 Amdahl 参数 （α）;这可以使用统计软件完成，例如 gnuplot 或 R. 
3. 显示结果以供分析。收集的数据点可以与模型函数一起绘制，以预测缩放并揭示数据与模型之间的差异。这也可以使用 gnuplot 或 R 来完成。

以下是 Amdahl 的可扩展性定律回归分析的示例 gnuplot 代码，用于提供如何执行此步骤的含义：

inputN = 10                     # rows to include as model input
alpha = 0.1                     # starting point (seed)
amdahl(N) = N1 * N/(1 + alpha * (N - 1))
# regression analysis (non-linear least squares fitting)
fit amdahl(x) filename every ::1::inputN using 1:2 via alpha

在 R 中处理此代码需要类似数量的代码，包括用于非线性最小二乘拟合的 nls（） 函数来计算系数，然后在绘图期间使用这些系数。请参阅 Performance Scalability Models 工具包，请参阅 gnuplot 和 R [Gregg 14a] 中的完整代码。下一节显示了一个示例 Amdahl's Law of Scalability 函数。

# #2.6.4 通用可扩展性定律
通用可扩展性定律 （USL），以前称为超串行模型 [Gunther 97]，由 Neil Gunther 博士开发，包括相干延迟参数。这在前面被描述为 coherence scalability profile，其中包括争用的影响。

USL 可以定义为：
C(N) = N/(1 + α(N – 1) + βN(N – 1))

C（N）、N 和 α 与阿姆达尔的可扩展性定律相同。β 是相干参数。当 β == 0 时，这就变成了阿姆达尔可扩展性定律

USL 和 Amdahl 的可扩展性定律分析的示例如图 2.17 所示。

输入数据集具有高度的方差，因此很难直观地确定可扩展性配置文件。前 10 个数据点（绘制为圆圈）已提供给模型。此外，还绘制了另外 10 个数据点，绘制为十字形，用于检查模型预测与现实情况。
有关 USL 分析的更多信息，请参见 [Gunther 97] 和 [Gunther 07]。

# #2.6.5 排队理论
排队理论是对具有队列的系统进行数学研究，提供分析其队列长度、等待时间（延迟）和利用率（基于时间）的方法。计算中的许多组件（包括软件和硬件）都可以建模为排队系统。多个排队系统的建模称为排队网络。

本节总结了排队理论的作用，并提供了一个示例来帮助您理解该角色。这是一个很大的研究领域，在其他文本中详细介绍了 [Jain 91][Gunther 97]。

排队理论建立在数学和统计学的各个领域之上，包括概率分布、随机过程、Erlang 的 C 公式（Agner Krarup Erlang 发明了排队理论）和利特尔定律。

利特尔定律可以表示为
L = λW

它确定系统中的平均请求数 L，即平均到达速率 λ 乘以系统中的平均请求时间 W。这可以应用于队列，因此 L 是队列中的请求数，W 是队列中的平均等待时间。  

排队系统可用于回答各种问题，包括以下内容：
■ 如果负载增加一倍，平均响应时间是多少？
■ 添加额外的处理器后，对平均响应时间有什么影响？
■ 当负载翻倍时，系统能否提供低于 100 ms 的第 90 个百分位响应时间？

除了响应时间外，还可以研究其他因素，包括利用率、队列长度和常驻作业的数量。

一个简单的排队系统模型如图 2.18 所示。

它有一个处理队列中作业的服务中心。排队系统可以有多个并行处理工作的服务中心。在排队理论中，服务中心通常称为服务器。

排队系统可以按三个因素进行分类：
■ 到达过程：这描述了向排队系统发送请求的到达间隔时间，可以是随机的、固定的，也可以是泊松等过程（使用指数分布作为到达时间）。
■ 服务时间分配：描述服务中心的服务时间。它们可以是固定的 （确定性的）、指数的或其他分布类型。
■ 服务中心数量：一个或多个。
这些因子可以用 Kendall 的表示法来表示

# Kendall 的符号
此表示法为每个属性分配代码。它的形式是
A/S/M

这些是到达流程 （A）、服务时间分布 （S） 和服务中心数量 （m）。还有一种扩展形式的 Kendall 表示法，它包括更多因素：系统中的 buf fers 数量、人口规模和服务学科。

常用排队系统的例子是 
■ M/M/1：马尔可夫到达次数（指数分布的到达时间），马尔可夫服务时间（指数分布），一个服务中心 
■ M/M/c：与 M/M/1 相同，但多服务器 
■ M/G/1：马尔可夫到达，服务时间的一般分布（任何），一个服务中心
■ M/D/1：马尔可夫到达， 确定性服务次数（固定），通常采用一个服务中心 
M/G/1 来研究旋转硬盘的性能

M/D/1 和 60% 利用率
作为排队理论的一个简单示例，请考虑确定性地响应工作负载的磁盘（这是一种简化）。型号为 M/D/1

提出的问题是：磁盘的响应时间如何随着利用率的增加而变化？

排队理论允许计算 M/D/1 的响应时间

r = s（2 - ρ）/2（1 - ρ）

其中响应时间 r 是根据服务时间 S 和利用率 ρ 定义的。

对于 1 毫秒的服务时间和从 0 到 100% 的利用率，这种关系如图 2.19 所示。

利用率超过 60%，平均响应时间将翻倍。到 80%，它增加了两倍。由于磁盘 I/O 延迟通常是应用程序的边界资源，因此将平均延迟增加一倍或更高可能会对应用程序性能产生重大的负面影响。这就是为什么磁盘利用率在达到 100% 之前就成为一个问题的原因，因为它是一个排队系统，请求（通常）不能中断，必须等待轮到它们。这与 CPU 不同，例如，在 CPU 中，优先级较高的工作可以抢占

此图可以直观地回答前面的问题 — 当利用率相对于负载时，如果负载增加一倍，平均响应时间是多少？

这个模型很简单，在某些方面它显示了最好的情况。使用时间的变化会使平均响应时间更高（例如，使用 M/G/1 或 M/M/1）。还有一个响应时间的分布，如图 2.19 所示，因此第 90 个和第 99 个百分位的退化速度超过 60% 时要快得多。

与前面的 Amdahl 可伸缩性定律的 gnuplot 示例一样，展示一些实际代码可能具有说明性，以便了解可能涉及的内容。这次使用了 R 统计软件 [R Project 20]

 svc_ms <- 1                   # average disk I/O service time, ms
 util_min <- 0                 # range to plot
 util_max <- 100               # "
 ms_min <- 0                   # "
 ms_max <- 10                  # "
 # Plot mean response time vs utilization (M/D/1)
 plot(x <- c(util_min:util_max), svc_ms * (2 - x/100) / (2 * (1 - x/100)),
    type="l", lty=1, lwd=1,
    xlim=c(util_min, util_max), ylim=c(ms_min, ms_max),
    xlab="Utilization %", ylab="Mean Response Time (ms)")

前面的 M/D/1 方程已传递给 plot（） 函数。此代码的大部分内容指定了图形、线条属性和轴标签的限制

# 2.7 容量规划
容量规划检查系统处理负载的能力以及它如何随着负载的扩展而扩展。它可以通过多种方式执行，包括研究资源限制和因子分析（此处介绍）以及建模（如前所述）。本节还包括扩展解决方案，包括负载均衡器和分片。有关此主题的更多信息，请参阅 The Art of Capacity Planning [Allspaw 08]。

对于特定应用程序的容量规划，有一个量化的性能目标进行规划会有所帮助。确定这一点在第 5 章 应用程序 的前面讨论

# #2.7.1 资源限制
此方法是搜索将在负载下成为瓶颈的资源。对于容器，资源可能会遇到软件施加的限制，从而成为瓶颈。此方法的步骤是：
1. 测量服务器请求的速率，并随着时间的推移监控此速率。
2. 测量硬件和软件资源的使用情况。随着时间的推移监控此速率。
3. 根据使用的资源提供 Express 服务器请求。
4. 将服务器请求外推到每个资源的已知（或实验确定的）限制

首先确定服务器的角色及其服务的请求类型。例如，Web 服务器提供 HTTP 请求，网络文件系统 （NFS） 服务器提供 NFS 协议请求（作），数据库服务器提供查询请求（或命令请求，其中查询是子集）。

下一步是确定每个请求的系统资源消耗。对于现有系统，可以测量当前请求速率和资源利用率。然后，可以使用外推法来查看哪个资源将首先达到 100% 的利用率，以及请求速率是多少。

对于未来的系统，可以使用微基准测试或负载生成工具在测试环境中模拟预期请求，同时测量资源利用率。如果客户端负载足够，您或许可以实验方式找到限制

要监控的资源包括： 
■ 硬件：CPU 利用率、内存使用率、磁盘 IOPS、磁盘吞吐量、磁盘容量（使用量）、网络吞吐量 
■ 软件：虚拟内存使用率、进程/任务/线程、文件描述符

假设您正在查看当前执行 1000 个请求/秒的现有系统。最繁忙的资源是 16 个 CPU，平均利用率为 40%;您预测，一旦它们得到 100% 的利用率，它们将成为此工作负载的瓶颈。问题变成了：届时每秒请求数的速率是多少？

原文： CPU% per request = total CPU%/requests = 16 × 40%/1,000 = 0.64% CPU per request
每个请求的 CPU% = 总 CPU%/请求 = 16 × 40%/1000 = 每个请求的 0.64% CPU
原文： max requests/s = 100% × 16 CPUs/CPU% per request = 1,600 / 0.64 = 2,500 requests/s
最大请求数/秒 = 100% × 16 个 CPU/CPU/请求% = 1600 / 0.64 = 2500 个请求/秒

预测为 2500 个请求/秒，此时 CPU 将 100% 繁忙。这是对容量的粗略最佳情况估计，因为在请求达到该速率之前可能会遇到其他一些限制因素

此练习仅使用了一个数据点：应用程序吞吐量（每秒请求数）为 1,000，而设备利用率为 40%。如果启用了随时间推移的监控，则可以包含具有不同吞吐量和利用率的多个数据点，以提高估计。图 2.20 说明了处理这些并推断最大应用程序吞吐量的可视化方法。

2,500 个请求/秒够吗？要回答这个问题，需要了解峰值工作负载是什么，这体现在日常访问模式中。对于您随时间推移监控的现有系统，您可能已经知道峰值会是什么样子。

假设一个 Web 服务器每天处理 100,000 个网站点击。这听起来可能很多，但平均只有一个请求 - 并不多。但是，100,000 次网站点击中的大部分可能发生在新内容发布后的几秒钟内，因此峰值很重要。

# #2.7.2  因子分析
在购买和部署新系统时，通常可以更改许多因素以实现所需的性能。这些可能包括更改磁盘和 CPU 的数量、RAM 的数量、闪存设备的使用、RAID 配置、文件系统设置等。任务通常是实现最低成本所需的性能。

测试所有组合将确定哪个组合具有最佳性价比;但是，这很快就会失控：8 个二进制因子需要 256 次测试。

一种解决方案是测试一组有限的组合。以下是基于了解最大系统配置的方法：
1. 在所有因素都配置为最大值的情况下测试性能。
2. 逐个更改因子，测试性能（每个因子都应该下降）。
3. 根据测量结果，将性能下降百分比归因于每个因素，以及成本节省。
4. 从最高性能（和成本）开始，选择节省成本的因素，同时根据其综合性能下降保留每秒所需的请求。
5. 重新测试计算的配置以确认交付的性能。

对于八因素系统，此方法可能只需要十次测试。

例如，考虑新存储系统的容量规划，要求读取吞吐量为 1 GB/s，工作集大小为 200 GB。最大配置达到 2 GB/s，包括 4 个处理器、256 GB 的 DRAM、2 个双端口 10 GbE 网卡、巨型帧，并且未启用压缩或加密（激活成本很高）。切换到两个处理器后，性能会降低 30%，一个网卡会降低 25%，非巨型处理器会降低 35%，加密会降低 10%，压缩会降低 40%，DRAM 会降低 90%，因为工作负载不再需要完全缓存。考虑到这些性能下降及其已知的节省，现在可以计算出满足要求的最佳性价比系统;它可能是一个带有一个网卡的双处理器系统，它满足所需的吞吐量：估计值为 2 × （1 – 0.30） × （1 – 0.25） = 1.04 GB/s。然后，明智的做法是测试此配置，以防这些组件在一起使用时的性能与其预期性能不同。

# #2.7.3 扩展解决方案
满足更高的性能需求通常意味着更大的系统，这种策略称为垂直扩展。将负载分散到多个系统（通常由称为负载均衡器的系统前面，使它们看起来都是一个系统）称为水平扩展。

云计算通过构建在较小的虚拟化系统而不是整个系统之上，进一步实现了水平扩展。这在购买计算以处理所需负载时提供了更精细的粒度，并允许以小而有效的增量进行扩展。由于不需要初始大额购买，因此与企业大型机（包括支持合同承诺）不同，因此在项目的早期阶段不需要进行严格的容量规划。

有一些技术可以根据性能指标自动进行云扩展。为此，AWS 技术称为 Auto Scaling 组 （ASG）。可以创建自定义扩展策略，以根据使用情况指标增加和减少实例数量。如图 2.21 所示。

Netflix 通常使用以 60% 的 CPU 利用率为目标的 ASG，并将根据负载进行扩展和缩减以维持该目标。

容器编排系统还可以提供对自动扩展的支持。例如，Kubernetes 提供了水平 Pod 自动扩展器 （HPA），它可以根据 CPU 利用率或其他自定义指标 [Kubernetes 20a] 来扩展 Pod（容器）的数量。

对于数据库，一种常见的扩展策略是分片，其中数据被拆分为多个逻辑组件，每个组件都由自己的数据库（或冗余的数据库组）管理。例如，通过将客户名称拆分为按字母顺序排列的范围，可以将客户数据库拆分为多个部分。选择有效的分片键对于在数据库之间均匀分配负载至关重要。

# 2.8 统计学
充分了解如何使用统计数据及其限制非常重要。本节讨论使用统计数据（指标）和统计类型（包括平均值、标准差和百分位数）来量化性能问题。

# #2.8.1 量化性能增益
量化问题和修复问题的潜在性能改进可以对其进行比较和确定优先级。这项任务可以通过观察或实验来执行。

基于观察
要使用观察来量化性能问题，请执行以下作：
1. 选择一个可靠的指标。
2. 估计解决问题后的性能提升。

例如： 
■ 观察到的：应用程序请求需要 10 毫秒。
■ 观察到的：其中，9 毫秒是磁盘 I/O。
■ 建议：将应用程序配置为在内存中缓存 I/O，预期 DRAM 延迟约为 ~10 μs。
■ 估计增益：10 ms → 1.01 ms （10 ms - 9 ms 10 μs） = ~9x 增益。

正如 第 2.3 节 概念 中所介绍的，延迟（时间）非常适合于此，因为它可以直接在组件之间进行比较，这使得这样的计算成为可能

使用延迟时，请确保将其作为应用程序请求的同步组件进行测量。某些事件以异步方式发生，例如后台磁盘 I/O （写入刷新到磁盘），并且不会直接影响应用程序性能。

基于实验
要通过实验来量化性能问题，请执行以下作：
1. 应用修复程序。
2. 使用可靠指标前后进行量化。
例如： 
■ 观察到：应用程序事务延迟平均为 10 毫秒。
■ 实验：增加应用程序线程数以允许更多并发而不是排队。
■ 观察到：应用程序事务延迟平均为 2 毫秒。增益：10 ms → 2 ms = 5 倍。

如果在生产环境中尝试修复的成本很高，则此方法可能不合适！对于这种情况，应使用基于观察的

# #2.8.2 平均
平均值通过单个值表示数据集：集中趋势指数。最常用的平均值类型是算术平均值（或简称平均值），它是值的总和除以值计数。其他类型包括几何平均值和调和平均值。

几何平均数
几何平均值是相乘值的第 n 次方根（其中 n 是值的计数）。这在 [Jain 91] 中进行了描述，其中包括一个使用它进行网络性能分析的示例：如果单独测量内核网络堆栈每一层的性能改进，那么平均性能改进是多少？由于各层在同一个数据包上协同工作，因此性能改进具有“乘法”效应，可以用几何平均值来最好地概括。

调和平均数
调和平均值是值的计数除以它们的倒数之和。它更适合于取速率的平均值，例如，计算 800 MB 数据的平均传输速率，此时前 100 MB 将以 50 MB/s 的速度发送，其余 700 MB 将以 10 MB/s 的限制速率发送。使用谐波平均值，答案是 800/（100/50 + 700/10） = 11.1 MB/s。

一段时间内的平均值
对于性能，我们研究的许多指标都是一段时间内的平均值。CPU 永远不会“处于 50% 的利用率”;它已在某个间隔的 50% 内使用，可能是一秒、一分钟或一小时。在考虑平均值时检查间隔很重要。

例如，我遇到了一个问题，即客户遇到了由 CPU 饱和（调度程序延迟）引起的性能问题，即使他们的监控工具显示 CPU 利用率从未高于 80%。监控工具报告 5 分钟平均值，这掩盖了 CPU 利用率一次在几秒钟内达到 100% 的时间段

衰减平均值
衰减的平均值有时用于系统性能。一个例子是各种工具（包括 uptime（1））报告的系统“负载平均值”。

衰减的平均值仍会在某个时间间隔内进行测量，但最近的时间比更远的时间更重要。这减少了（抑制）平均值的短期波动。

有关此内容的更多信息，请参见第 6 章 CPU 的 第 6.6 节 可观测性工具中的负载平均值。

局限性
平均值是隐藏详细信息的汇总统计数据。我分析了许多偶尔磁盘 I/O 延迟异常值超过 100 毫秒的情况，而平均延迟接近 1 毫秒。为了更好地理解数据，您可以使用部分 2.8.3 标准差、百分位数、中位数（下一节）中介绍的其他统计数据，以及部分 2.10 可视化中介绍的可视化。

# #2.8.3 标准差 百分位数 中位数
标准差和百分位数（例如，第 99 个百分位数）是提供有关数据分布信息的统计技术。标准差是方差的度量，值越大表示与平均值 （平均值） 的方差越大。第 99 个百分位数显示分布中包括 99% 值的点。图 2.22 描绘了正态分布的这些值，以及最小值和最大值。

第 90 个、第 95 个、第 99 个和第 99.9 个百分位数用于请求延迟的性能监控，以量化总体中最慢的百分位数。这些也可以在服务级别协议 （SLA） 中指定，作为衡量大多数用户是否可以接受性能的一种方式

可以检查第 50 个百分位数（称为中位数）以显示大部分数据的位置。

# #2.8.4 变异系数
由于标准差是相对于平均值的，因此只有在同时考虑标准差和平均值时才能理解方差。仅 50 的标准差就告诉我们什么。这加上 200 的平均值告诉我们很多。

有一种方法可以将变异表示为单个指标：标准差与平均值的比率，称为变异系数（CoV 或 CV）。在此示例中，CV 为 25%。较低的 CV 意味着较小的方差。

作为单个量度的方差的另一个表达式是 z 值，即值与平均值的标准差数。

# #2.8.5 多模式分布
均值、标准差和百分位数存在问题，这在上一张图表中可能很明显：它们适用于类正态分布或单峰分布。系统性能通常是双峰的，对于快速代码路径返回低延迟，对于慢速代码路径返回高延迟，或者对于缓存命中返回低延迟，对于缓存未命中返回高延迟。也可能有两种以上的模式。

图 2.23 显示了读取和写入混合工作负载（包括随机和顺序 I/O）的磁盘 I/O 延迟分布。

这以直方图的形式表示，它显示两种模式。左侧的模式显示小于 1 毫秒的延迟，这是针对磁盘上的缓存命中。右侧峰值约为 7 毫秒，用于on-disk cache misses：随机读取。平均 （平均） I/O 延迟为 3.3 毫秒，绘制为垂直线。这个平均值不是集中趋势的指数（如前所述）;事实上，情况几乎恰恰相反。作为一个指标，这种分布的平均值具有严重的误导性。

然后是那名溺水身亡的男子，他穿越了一条平均深度为 6 英寸的溪流。——W. I. E. 盖茨

每次看到平均值用作性能指标（尤其是平均延迟）时，请问：分布情况如何？第 2.10 节 可视化 提供了另一个示例，并显示了不同的可视化和量度在显示此分布方面的有效性。

# #2.8.6 外升
另一个统计问题是存在异常值：极少量的极高或极低值似乎不符合预期的分布（单模态或多模态）

磁盘 I/O 延迟异常值就是一个例子 — 当大多数磁盘 I/O 介于 0 到 10 毫秒之间时，非常偶尔的磁盘 I/O 可能需要 1000 毫秒以上。像这样的延迟异常值可能会导致严重的性能问题，但除了最大值之外，很难从大多数指标类型中识别它们的存在。另一个示例是由基于 TCP 计时器的重新传输引起的网络 I/O 延迟异常值

对于正态分布，异常值的存在可能会使平均值略微偏移，但不会使中位数偏移一点（考虑这可能很有用）。标准差和第 99 个百分位数更有可能识别出异常值，但这仍然取决于它们的频率。

为了更好地了解多模态分布、异常值和其他复杂但常见的行为，请检查完整分布，例如使用直方图。有关执行此作的更多方法，请参阅 第 2.10 节 可视化 。

# 2.9 监控
系统性能监控记录一段时间内的性能统计数据（时间序列），以便将过去与现在进行比较，并识别基于时间的使用模式。这对于容量规划、量化增长和显示峰值使用情况非常有用。历史值还可以通过显示过去的“正常”范围和平均值来为了解性能指标的当前值提供上下文

# #2.9.1 基于时间的模式
图 2.24、2.25 和 2.26 显示了基于时间的模式的示例，它们绘制了 sys tem 在不同时间间隔内从云计算服务器读取的文件

这些图表显示了一种每日模式，在上午 8 点左右开始上升，中午后略有下降，然后在夜间衰减。长期图表显示，周末的活动较少。在 30 天图表中也可以看到几个短的峰值。

在他的 toric 数据中，通常可以看到包括图中所示的各种行为周期，包括： 
■ 每小时：应用程序环境可能每小时都会发生活动，例如监控和报告任务。这些作以 5 分钟或 10 分钟的周期执行也很常见。
■ 每日：可能存在与工作时间（上午 9 点至下午 5 点）一致的每日使用模式，如果服务器适用于多个时区，则可能会延长该模式。对于 Internet 服务器，当全球用户处于活动状态时，可能会遵循该模式。其他日常活动可能包括夜间日志轮换和备份。
■ 每周：除了每日模式外，还可能存在基于工作日和周末的每周模式。
■ 季度：财务报告按季度计划完成。
■ 每年：每年的负荷模式可能是由于学校时间表和假期造成的。

其他活动（例如在网站上发布新内容）和销售（美国的黑色星期五/网络星期一）可能会出现不规则的负载增加。负载的不规则下降可能是由于外部活动造成的，例如大面积停电或互联网中断，以及体育总决赛（每个人都在观看比赛而不是使用您的产品）。

# #2.9.2 监控产品
有许多第三方产品可用于系统性能监控。典型功能包括存档数据并将其呈现为基于浏览器的交互式图形，以及提供可配置的警报

其中一些通过在系统上运行代理（也称为导出器）来收集其统计信息来运行。这些代理要么执行作系统可观察性工具（例如 iostat（1） 或 sar（1））并解析输出的文本（被认为效率低下），要么直接从作系统库和内核接口中读取。监控产品支持一组自定义代理，用于从特定目标（Web 服务器、数据库和语言运行时）导出统计信息。

随着系统变得更加分散和云计算的使用量不断增长，您将更频繁地需要监控大量系统：数百、数千个或更多。这就是集中式监控产品特别有用的地方，它允许从一个界面监控整个环境。

举个具体的例子：Netflix 云由超过 200,000 个实例组成，并使用 Atlas 云范围的监控工具进行监控，该工具由 Netflix 定制构建，可在这种规模下运行，并且是开源的 [Harrington 14]。其他监控产品在第 4 章 可观测性工具， 第 4.2.4 节 监控中讨论。

# #2.9.3 摘要-自启动
如果尚未执行监控，请检查作系统是否至少提供了 summary-since-boot 值，这些值可用于与当前值进行比较。

# 2.10 可视化
可视化允许检查的数据比以文本形式轻松理解（有时甚至显示）的数据多。它们还支持模式识别和模式匹配。这可能是识别不同指标源之间相关性的有效方法，这可能很难以编程方式完成，但很容易直观地完成

# #2.10.1 折线图
折线图（也称为折线图）是一种众所周知的基本可视化效果。它通常用于检查一段时间内的性能指标，在 x 轴上显示时间的流逝。

图 2.27 是一个示例，显示了 20 秒期间的平均（平均）磁盘 I/O 延迟。这是在运行 MySQL 数据库的生产云服务器上测得的，其中磁盘 I/O 延迟被怀疑会导致查询缓慢。

此折线图显示相当一致的平均读取延迟约为 4 毫秒，这高于这些磁盘的预期。

可以绘制多条线，在同一组轴上显示相关数据。在此示例中，可以为每个磁盘绘制一条单独的线，显示它们是否表现出相似的性能。

还可以绘制统计值，从而提供有关数据分布的更多信息。图 2.28 显示了相同范围的磁盘 I/O 事件，并为每秒中位数、标准差和百分位数添加了线条。请注意，y 轴现在的范围比之前的折线图大得多（系数为 8）。

这说明了平均值高于预期的原因：分布包括延迟更高的 I/O。具体来说，1% 的 I/O 超过 20 毫秒，如第 99 个百分位所示。中位数还显示了预期的 I/O 延迟位置，约为 1 毫秒

# #2.10.2 散点图
图 2.29 显示了与散点图相同时间范围内的磁盘 I/O 事件，这使得所有数据都可以看到。每个磁盘 I/O 都绘制为一个点，其完成时间在 x 轴上，延迟在 y 轴上。

现在，可以完全理解高于预期的平均延迟的来源：有许多磁盘 I/O 的延迟为 10 毫秒、20 毫秒，甚至超过 50 毫秒。散点图显示了所有数据，揭示了这些异常值的存在。

许多 I/O 是亚毫秒级的，显示在靠近 x 轴的位置。这就是散点图的分辨率开始成为一个问题的地方，因为点重叠并且变得难以区分。随着数据的增加，情况会变得更糟：想象一下在一个散点图上绘制来自整个云的事件，涉及数百万个数据点：这些点可以合并并成为“油漆墙”。另一个问题是必须收集和处理的数据量：每个 I/O 的 x 和 y 坐标

# #2.10.3 热图
热图（更恰当地称为列量化）可以通过将 x 和 y 范围量化为称为桶的组来解决散点图可扩展性问题。这些像素显示为大像素，并根据该 x 和 y 范围内的事件数进行着色。这种量化还解决了散点图视觉密度限制，允许热图以相同的方式显示来自单个系统或数千个系统的数据。热图以前用于位置，例如磁盘偏移量（例如，TazTool [McDougall 06a]）;我发明了它们在计算延迟、利用率和其他指标方面的用途。延迟热图最初包含在 2008 年发布的 Sun Microsystems ZFS Storage 设备的 Analytics 中 [Gregg 10a][Gregg 10b]，现在在 Grafana [Grafana 20] 等性能监控产品中很常见

与前面绘制的数据集相同的数据集如图 2.30 所示为热图

高延迟异常值可以识别为热图中较高的数据块，通常是浅色的，因为它们跨越的 I/O 很少（通常是单个 I/O）。大量数据中的模式开始出现，而散点图可能无法看到这些模式。

此磁盘 I/O 跟踪的完整秒数范围（之前未显示）如图 2.31 热图所示。

尽管跨越了 9 倍的范围，但可视化仍然非常可读。在大部分范围内都可以看到双峰分布，一些 I/O 以接近零的延迟返回（可能是磁盘缓存命中），而其他 I/O 的延迟略小于 1 毫秒（可能是磁盘缓存未命中）

本书后面还有其他热图示例，包括第 6 章 CPU， 第 6.7 节 可视化;第 8 章 文件系统， 第 8.6.18 节 可视化;以及第 9 章 磁盘， 第 9.7.3 节 延迟热图。我的网站还提供了延迟、利用率和亚秒级偏移热图 [Gregg 15b] 的示例

# #2.10.4 时间线图表
时间线图表将一组活动显示为时间线上的条形。这些通常用于前端性能分析（Web 浏览器），其中它们也称为瀑布图，并显示网络请求的时间。图 2.32 显示了 Firefox Web 浏览器的一个示例。

在图 2.32 中，第一个网络请求被高亮显示：除了将其持续时间显示为 hor izontal 条外，该持续时间的组成部分也显示为彩色条。右侧面板中也解释了这些内容：第一个请求最慢的组件是 “Waiting”，它正在等待来自服务器的 HTTP 响应。请求 2 到 6 在第一个请求开始接收数据后开始，并且可能依赖于该数据。如果图表中包含显式依赖关系箭头，则它将成为甘特图的一种类型。

对于后端性能分析（服务器），使用类似的图表来显示线程或 CPU 的时间线。示例软件包括 KernelShark [KernelShark 20] 和 Trace Compass [Eclipse 20]。有关 KernelShark 屏幕截图示例，请参见第 14 章 Ftrace， 第 14.11.5 节 KernelShark。Trace Compass 还绘制显示依赖关系的箭头，其中一个线程唤醒了另一个线程。

# #2.10.5 表面图
这是三维的表示形式，渲染为三维表面。当第三维值不会经常从一个点到另一个点发生剧烈变化时，它的效果最佳，从而产生类似于连绵起伏的丘陵的表面。曲面图通常渲染为线框模型。

图 2.33 显示了每个 CPU 利用率的线框表面图。它包含来自许多服务器的每秒 60 秒值（这是从跨越 300 多台物理服务器和 5,312 个 CPU 的数据中心的图像中裁剪出来的）[Gregg 11b]

每个服务器的表示方式是将其 16 个 CPU 绘制为表面上的行，将每秒 60 次的利用率测量值绘制为列，然后将表面的高度设置为利用率值。颜色 （Color） 也被设置为反映利用率值。如果需要，可以使用 hue 和 saturation 将数据的第四和第五维度添加到可视化中。（如果有足够的分辨率，可以使用模式来表示第六维。

然后，这些 16 × 60 个服务器矩形将作为棋盘映射到整个图面上。即使没有标记，也可以在图像中清楚地看到一些服务器矩形。一个在右侧显示为高原的模型表明其 CPU 几乎始终处于 100%。

网格线的使用突出了海拔的细微变化。可以看到一些微弱的线条，这表示单个 CPU 持续以低利用率（几个百分点）运行

# #2.10.6 可视化工具
Unix 性能分析历来侧重于基于文本的工具的使用，部分原因是图形支持有限。此类工具可以在登录会话中快速执行并实时报告数据。可视化的访问更加耗时，并且通常需要一个跟踪和报告周期。在处理紧急性能问题时，您访问指标的速度可能至关重要。

现代可视化工具提供系统性能的实时视图，可从浏览器和移动设备访问。有许多产品可以做到这一点，包括许多可以监控您的整个云的产品。第 1 章 导言， 第 1.7.1 节 计数器、统计数据和度量值 包括此类产品 Grafana 的示例屏幕截图，其他监控产品在第 4 章 可观测性工具， 第 4.2.4 节 监控中进行了讨论。

# 2.11 练习
1. 回答以下有关关键性能术语的问题： 
■ 什么是 IOPS？什么是利用率？
■ 什么是饱和度？
■ 什么是延迟？
■ 什么是微基准测试？

2. 选择五种方法用于您的（或假设的）环境。选择可以进行的顺序，并解释选择每个的原因。

3. 总结使用平均延迟作为唯一性能指标时存在的问题。这些问题可以通过包括第 99 个百分位数来解决吗？

# 2.12 引用
 [Amdahl 67] Amdahl, G., “Validity of the Single Processor Approach to Achieving Large 
Scale Computing Capabilities,” AFIPS, 1967. 
 [Jain 91] Jain, R., The Art of Computer Systems Performance Analysis: Techniques for Experimental 
Design, Measurement, Simulation and Modeling, Wiley, 1991.
 [Cockcroft 95] Cockcroft, A., Sun Performance and Tuning, Prentice Hall, 1995. 
 [Gunther 97] Gunther, N., The Practical Performance Analyst, McGraw-Hill, 1997. 
 [Wong 97] Wong, B., Configuration and Capacity Planning for Solaris Servers, Prentice Hall, 1997. 
 [Elling 00] Elling, R., “Static Performance Tuning,” Sun Blueprints, 2000.
 [Millsap 03] Millsap, C., and J. Holt., Optimizing Oracle Performance, O’Reilly, 2003. 
 [McDougall 06a] McDougall, R., Mauro, J., and Gregg, B., Solaris Performance and Tools: 
DTrace and MDB Techniques for Solaris 10 and OpenSolaris, Prentice Hall, 2006.
 [Gunther 07] Gunther, N., Guerrilla Capacity Planning, Springer, 2007. 
 [Allspaw 08] Allspaw, J., The Art of Capacity Planning, O’Reilly, 2008.
 [Gregg 10a] Gregg, B., “Visualizing System Latency,” Communications of the ACM, July 2010.
 [Gregg 10b] Gregg, B., “Visualizations for Performance Analysis (and More),” USENIX LISA, 
https://www.usenix.org/legacy/events/lisa10/tech/#gregg, 2010.
 [Gregg 11b] Gregg, B., “Utilization Heat Maps,” http://www.brendangregg.com/HeatMaps/
 utilization.html, published 2011.
 [Williams 11] Williams, C., “The $300m Cable That Will Save Traders Milliseconds,” The 
Telegraph, https://www.telegraph.co.uk/technology/news/8753784/The-300m-cable-that-will
save-traders-milliseconds.html, 2011.
 [Gregg 13b] Gregg, B., “Thinking Methodically about Performance,” Communications of the 
ACM, February 2013.
 [Gregg 14a] Gregg, B., “Performance Scalability Models,” https://github.com/brendangregg/
 PerfModels, 2014.
 [Harrington 14] Harrington, B., and Rapoport, R., “Introducing Atlas: Netflix’s Primary 
Telemetry Platform,” Netflix Technology Blog, https://medium.com/netflix-techblog/ 
introducing-atlas-netflixs-primary-telemetry-platform-bd31f4d8ed9a, 2014.
 [Gregg 15b] Gregg, B., “Heatmaps,” http://www.brendangregg.com/heatmaps.html, 2015.
 [Wilkie 18] Wilkie, T., “The RED Method: Patterns for Instrumentation & Monitoring,” 
Grafana Labs, https://www.slideshare.net/grafana/the-red-method-how-to- monitoring-your
microservices, 2018.
 [Eclipse 20] Eclipse Foundation, “Trace Compass,” https://www.eclipse.org/tracecompass, 
accessed 2020.
 [Wikipedia 20] Wikipedia, “Five Whys,” https://en.wikipedia.org/wiki/Five_whys, accessed 
2020.
 [Grafana 20] Grafana Labs, “Heatmap,” https://grafana.com/docs/grafana/latest/features/
 panels/heatmap, accessed 2020.
 [KernelShark 20] “KernelShark,” https://www.kernelshark.org, accessed 2020.
 [Kubernetes 20a] Kubernetes, “Horizontal Pod Autoscaler,” https://kubernetes.io/docs/tasks/
 run-application/horizontal-pod-autoscale, accessed 2020.
 [R Project 20] R Project, “The R Project for Statistical Computing,” https://www.r-project.org, 
accessed 2020